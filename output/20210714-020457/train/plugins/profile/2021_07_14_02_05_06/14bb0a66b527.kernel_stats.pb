
Ü
 void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28°¤@…¸pH…ğqXbfunctional_1/conv2d_1/Conv2Dh
İ
 void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28ğ¢@…¨pH…ÈpXbfunctional_1/conv2d_21/Conv2Dh
ç
†void dgrad2d_grouped_direct_kernel<float, float, float, true, 0, 0, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)*28Èú@ˆ ½Hˆ¨½Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
x
ampere_sgemm_128x128_nt*28 ·@†Ğ›H‡Ğ›Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
w
ampere_sgemm_128x128_nt*28˜·@‡È›H†Ğ›Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
x
ampere_sgemm_128x128_nt*28ˆ·@‡¸›H‡Ğ›Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
x
ampere_sgemm_128x128_nt*28ø¶@‡¸›H†À›Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
•
6ampere_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1*28Œ …@ƒAHƒÈAXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
«
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28‹ @…Ğ€H†Ğ€Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
º
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28‰¨Ø@„ˆlH… lXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
•
6ampere_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1*28ˆğÌ@‚ğ2H‚˜4Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
•
6ampere_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1*28‰àÉ@‚À1Hƒğ2Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
J
redzone_checker*28ˆÀÂ@€ØH€øXbfunctional_1/conv2d_8/Conv2Dh4
J
redzone_checker*28‹¸Â@€ØH€øXbfunctional_1/conv2d_9/Conv2Dh4
K
redzone_checker*28… Â@€ØH€ğXbfunctional_1/conv2d_14/Conv2Dh4
J
redzone_checker*28‰ ½@€ĞH€èXbfunctional_1/conv2d_7/Conv2Dh2
J
redzone_checker*28Šğ»@€ØHøXbfunctional_1/conv2d_6/Conv2Dh2
K
redzone_checker*28‰ğ»@€ØH€€Xbfunctional_1/conv2d_11/Conv2Dh2
K
redzone_checker*28Œè»@€ĞHøXbfunctional_1/conv2d_18/Conv2Dh2
K
redzone_checker*28‡Ø»@€ØHøXbfunctional_1/conv2d_12/Conv2Dh2
K
redzone_checker*28‹À»@€ĞH€Xbfunctional_1/conv2d_17/Conv2Dh2
J
redzone_checker*28ˆ˜»@€ĞH€øXbfunctional_1/conv2d_3/Conv2Dh2
K
redzone_checker*28‹»@€ĞH€øXbfunctional_1/conv2d_20/Conv2Dh2
J
redzone_checker*28†ˆ»@€ĞHğXbfunctional_1/conv2d_2/Conv2Dh2
K
redzone_checker*28‡ğ³@€ØH€øXbfunctional_1/conv2d_15/Conv2Dh0
J
redzone_checker*28‰è³@€ØH€øXbfunctional_1/conv2d_5/Conv2Dh0
J
redzone_checker*28ˆ°³@€ØH€øXbfunctional_1/conv2d_4/Conv2Dh0
©
Évoid cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28‡Àª@ğ!H¨"Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
ñ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‡¸¨@èH€(Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
ñ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‡ ¨@€èH‚ø'Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‡¨@øH‚à'Xbfunctional_1/conv2d_20/Conv2Dh
Ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‡ø§@øH‚Ğ'Xbfunctional_1/conv2d_19/Conv2Dh
H
redzone_checker*28‰¨¦@€ĞHøXbfunctional_1/conv2d/Conv2Dh,
K
redzone_checker*28‰ ¥@€ĞHøXbfunctional_1/conv2d_21/Conv2Dh,
m
redzone_checker*28†€¥@€ØH€€Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh,
m
redzone_checker*28…€¥@€ØH€€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh,
J
redzone_checker*28‡ø¤@€ØHøXbfunctional_1/conv2d_1/Conv2Dh,
l
redzone_checker*28‰Ø¤@€ĞHøXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh,
m
redzone_checker*28†Ø¤@€ĞHøXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh,
l
redzone_checker*28‡Ğ¤@€ØHøXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh,
l
redzone_checker*28†Ğ¤@€ĞH€øXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh,
l
redzone_checker*28‡È¤@€ĞH€øXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh,
K
redzone_checker*28…À¤@€ĞH€øXbfunctional_1/conv2d_22/Conv2Dh,
m
redzone_checker*28ˆ°¤@€ØHøXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh,
m
redzone_checker*28†Ø@€ĞHøXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh*
m
redzone_checker*28‡¸@€ĞHøXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh*
l
redzone_checker*28†°@€ØH€øXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh*
m
redzone_checker*28„ @€ĞHøXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh*
l
redzone_checker*28‰ˆ@€ØH€øXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh*
l
redzone_checker*28ˆˆ@€ØHøXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh*
”
6ampere_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1*28†è›@‚ø2H‚Ğ4Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28†š@ƒğLHƒ MXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
©
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28ˆØ™@„àLH„øLXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
©
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28†ğ—@ƒøKHƒøKXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28†à–@€ØH€€Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh(
m
redzone_checker*28…Ø–@€ØH€Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh(
m
redzone_checker*28†¸–@€ØH€øXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh(
l
redzone_checker*28„ğ•@€ĞH€øXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh(
Ì
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28†Ğ@ƒÈEHƒˆKXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Ì
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28†ø‹@ƒğEHƒˆFXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28‚‡@€ØH€øXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh$
Ì
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28†à†@ƒ¨CHƒ¸CXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
K
redzone_checker*28„È†@€ØHğXbfunctional_1/conv2d_13/Conv2Dh$
m
redzone_checker*28ˆ†@€ĞHøXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh$
k
redzone_checker*28†€†@€ØHğXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh$
n
redzone_checker*28‡¸…@€ØHàXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh$
n
redzone_checker*28†°…@€ĞHèXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh$
n
redzone_checker*28†°…@€ĞHàXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh$
m
redzone_checker*28†°…@€ĞHàXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh$
m
redzone_checker*28‡ …@€ĞHàXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh$
m
redzone_checker*28… …@€ØH€àXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh$
m
redzone_checker*28……@€ØHàXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh$
n
redzone_checker*28ƒ…@€ØH€àXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh$
n
redzone_checker*28‡ø„@€ĞHàXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh$
n
redzone_checker*28†ø„@€ĞHàXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh$
m
redzone_checker*28…è„@€ĞHàXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh$
n
redzone_checker*28ˆĞ„@€ĞH€ğXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh$
Ì
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28†¨‚@ƒ°@HƒøAXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
K
redzone_checker*28…è€@ĞHøXbfunctional_1/conv2d_16/Conv2Dh"
Ì
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28†€@ƒø?Hƒ˜@Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
J
redzone_checker*28‡¨@€ØH€øXbfunctional_1/conv2d_10/Conv2Dh"
J
redzone_checker*28‰ @€ØHğXbfunctional_1/conv2d_19/Conv2Dh"

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28†ø~@‚˜H‚ 'Xbfunctional_1/conv2d_20/Conv2Dh

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28†Ø~@H 'Xbfunctional_1/conv2d_19/Conv2Dh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28…ˆz@‚Ğ(H‚à(Xbfunctional_1/conv2d_20/Conv2Dh
J
redzone_checker*28…àw@€ØH€ğXbfunctional_1/conv2d_23/Conv2Dh 
Á
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28„Ğw@ØH 'Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28‡¸w@€ØHøXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh 
l
redzone_checker*28„€w@€ĞHğXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh 
m
redzone_checker*28‡èv@ĞHğXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh 
l
redzone_checker*28„èv@€ĞH€ğXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh 
Á
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28…Ğu@ØH'Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28…t@‚€:Hƒ:Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28„Èp@ˆH Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
”
6ampere_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1*28ƒ€p@¨%H°%Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28…øo@‚ø7Hƒ€8Xbfunctional_1/conv2d_20/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28„ğo@€
H€Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_32x32_tn*28… o@ƒÀ7H‚à7Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_32x32_tn*28…˜o@‚È7HƒĞ7Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28†Èm@ˆ
HàXbfunctional_1/conv2d_17/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28„Àm@€ˆ
HØXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ñ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28„¸m@€
HÈXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28†¨m@€
HĞXbfunctional_1/conv2d_16/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1*28„øk@ğ#H$Xbfunctional_1/conv2d_20/Conv2Dh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28„Èj@‚˜5H‚°5Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28„Àj@ĞHĞXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28†¸i@€ØH€øXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28†ˆi@ƒÀ4HƒÈ4Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28…Ğh@€¨H˜Xbfunctional_1/conv2d_21/Conv2Dh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28…Èh@€ H˜Xbfunctional_1/conv2d_1/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28„Èh@€ H€˜Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28†°h@˜HXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
m
redzone_checker*28‡¸g@€ĞHàXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28† g@ƒÈ3HƒØ3Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
‘
6ampere_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1*28… g@°"H‚À"Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28…Ød@H Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28„d@‚ˆ2H‚ˆ2Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
¼
İvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28…Ğb@ğ H‚ğ Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
s
ampere_cgemm_32x64_tn*28„ˆb@‚€1H‚ˆ1Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28ƒèa@€ØH€øXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
l
redzone_checker*28„°a@€ØHøXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
l
redzone_checker*28„˜a@€ĞH€øXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
“
6ampere_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1*28…È`@‚ H  Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
”
6ampere_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1*28„À`@‚ H˜ Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
µ
ùvoid implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28„ˆ_@À	H‚€&Xbfunctional_1/conv2d_14/Conv2Dh
Ü
 void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28„Ğ\@°HÀXbfunctional_1/conv2d_22/Conv2Dh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28„à[@‚è-H‚ø-Xbfunctional_1/conv2d_20/Conv2Dh
l
redzone_checker*28…ÀZ@€ØH€Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28„ˆZ@ØHˆXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
m
redzone_checker*28†ØY@€ØHàXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28ƒøX@€ĞH€èXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28…àX@€ĞH€èXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28„àX@€ØH€àXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28„X@èH¨Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
œ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28„€X@àH Xbfunctional_1/conv2d_16/Conv2Dh
œ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28„øW@ØH Xbfunctional_1/conv2d_17/Conv2Dh
P
ampere_cgemm_32x32_tn*28„ĞV@‚è*H‚è+Xbfunctional_1/conv2d_20/Conv2Dh
P
ampere_cgemm_32x32_tn*28„ÈU@‚à*H‚è*Xbfunctional_1/conv2d_19/Conv2Dh
è
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params)*28ƒ°U@‚Ğ*Hà*Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28„àR@€ˆH Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params)*28ƒĞR@ƒĞRHƒĞRXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ƒ˜R@€ˆH‚Xbfunctional_1/conv2d_14/Conv2Dh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28„ğP@€ˆHXbfunctional_1/conv2d_13/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28„ğP@€ˆH˜Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
“
6ampere_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1*28ƒğP@ğH€Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28„ğN@ØHàXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
Á
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ƒèN@€ØHàXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28„ĞN@‚¨'H‚¨'Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28„ÀN@‚˜'H‚¨'Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28„ÀN@‚ 'H‚ 'Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28„¨N@‚'H‚˜'Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ƒ N@ˆ'H‚˜'Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28„˜N@‚ˆ'H‚'Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
ö
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ƒèL@€ØHèXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28ƒ¨L@¨$H‚€(Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ö
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28„ L@ØHàXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28‚€L@€€H€Xbfunctional_1/conv2d_19/Conv2Dh
µ
ùvoid implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28ƒ°J@àHèXbfunctional_1/conv2d_11/Conv2Dh
Ó
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ƒØI@ğH€Xbfunctional_1/conv2d_19/Conv2Dh
Ó
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ƒØI@€ğH€Xbfunctional_1/conv2d_20/Conv2Dh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28ƒ¨I@¸H¸Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
r
ampere_cgemm_64x32_tn*28„ˆH@‚ğ#H‚˜$Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28ƒğG@Ğ#H‚ $Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
r
ampere_cgemm_64x32_tn*28„ÈG@‚È#H‚€$Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
P
ampere_cgemm_32x32_tn*28‚¸G@È#Hğ#Xbfunctional_1/conv2d_16/Conv2Dh
P
ampere_cgemm_32x32_tn*28‚ˆE@À"HÈ"Xbfunctional_1/conv2d_17/Conv2Dh
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28„°D@ø	H Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ƒ°D@ø	H Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
»
ÿvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28‚èB@°!H¸!Xbfunctional_1/conv2d_20/Conv2Dh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‚B@€ˆ
H°Xbfunctional_1/conv2d_3/Conv2Dh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ƒĞA@€°H‚ğXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
¼
İvoid cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28ƒÈA@ƒÈAHƒÈAXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ƒ¨A@€
H¸Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‚˜A@€ˆ
H°Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ƒø@@€€
H°Xbfunctional_1/conv2d_18/Conv2Dh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚è@@€€H€¸Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
¿
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚ @@ HØXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28‚˜@@ˆ H Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_32x32_tn*28ƒ@@øH‚˜ Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
P
ampere_cgemm_32x32_tn*28‚@@€ H Xbfunctional_1/conv2d_21/Conv2Dh

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ƒˆ@@€ HèXbfunctional_1/conv2d_21/Conv2Dh

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚ˆ@@˜HèXbfunctional_1/conv2d_1/Conv2Dh
q
ampere_cgemm_32x32_tn*28‚€@@øHˆ Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28ƒğ?@ H¨Xbfunctional_1/conv2d_17/Conv2Dh
O
ampere_cgemm_32x32_tn*28ƒè?@‚ØH Xbfunctional_1/conv2d_1/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28ƒè?@‚ğHøXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ƒà?@˜HØXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28‚Ğ?@ĞH€ Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ƒ°?@øH Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
Ù
 void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28‚Ğ>@€¸
H¸
Xbfunctional_1/conv2d/Conv2Dh
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28„È>@‚ˆH‚ÀXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28„¸>@‚˜H‚ Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
s
ampere_cgemm_32x32_tn*28ƒ¸>@‚˜H Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
´
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28‚¨>@H˜Xbfunctional_1/conv2d_14/Conv2Dh
t
ampere_sgemm_128x128_nt*28ƒ>@ˆH‚ˆXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28ƒˆ=@‚ÀHÈXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28‚ø<@¸HÀXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
P
ampere_gcgemm_64x32_nt*28‚Ğ<@¨H¨Xbfunctional_1/conv2d_9/Conv2Dh
r
ampere_gcgemm_64x32_nt*28‚È<@ H¨Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
¿
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ƒ¸;@€ø	HàXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¿
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚°;@ø	H€àXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28„è:@‚¨H‚ÀXbfunctional_1/conv2d_9/Conv2Dh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28ƒĞ:@¨H‚¨Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28‚È:@ H¨Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28ƒà9@‚HĞXbfunctional_1/conv2d_17/Conv2Dh
s
ampere_sgemm_128x128_nt*28ƒˆ9@‚ÀHÈXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28ƒ€9@¸H‚ÈXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh

0ampere_scudnn_128x64_stridedB_splitK_small_nn_v1*28€9@øH€ˆXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28ƒè8@ĞH‚˜Xbfunctional_1/conv2d_19/Conv2Dh
P
ampere_gcgemm_32x32_nt*28‚¸8@€xH€˜Xbfunctional_1/conv2d_19/Conv2Dh2
P
ampere_gcgemm_32x32_nt*28ƒÈ7@€xH€˜Xbfunctional_1/conv2d_20/Conv2Dh2
¥
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28‚€7@ÀHÀXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28‚Ğ5@àHğXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28ƒ°5@ÀH‚ğXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
¨
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28‚è3@€XH€ Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh2
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28ƒ3@àHèXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28‚3@€àHèXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚è2@€ĞHàXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ö
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚à2@€ĞHàXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28‚°2@€ØHğXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28‚ 2@øH¨Xbfunctional_1/conv2d_17/Conv2Dh
Á
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚ø1@HèXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Ó
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚è1@€€HøXbfunctional_1/conv2d_16/Conv2Dh
Ó
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚à1@€€HğXbfunctional_1/conv2d_17/Conv2Dh
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚ 1@€H€ØXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚€1@€ğHØXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28ƒø0@ H°Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
¨
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28‚ø0@€`H€ Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh2

0ampere_scudnn_128x64_stridedB_splitK_small_nn_v1*28ƒà0@ H Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh

0ampere_scudnn_128x64_stridedB_splitK_small_nn_v1*28€à0@€ H€ Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
¿
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚Ğ0@¨H¨Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¿
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚È0@ H¨Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
P
ampere_cgemm_64x32_tn*28‚À0@ÈHøXbfunctional_1/conv2d_14/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28¸0@€ĞH€øXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params)*28‚°0@‚°0H‚°0Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
Á
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ƒ¨0@ˆH‚ Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‚0@€ØHøXbfunctional_1/conv2d_22/Conv2Dh
ñ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‚€0@€¸H€øXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
r
ampere_cgemm_64x32_tn*28‚¨/@ĞHØXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28‚ /@ĞHĞXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x32_tn*28‚/@ÀHĞXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
º
ÿvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28ƒø.@‚°HÈXbfunctional_1/conv2d_1/Conv2Dh
P
ampere_cgemm_64x32_tn*28‚Ğ.@˜H¸Xbfunctional_1/conv2d_13/Conv2Dh
»
ÿvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28‚¸.@˜H Xbfunctional_1/conv2d_21/Conv2Dh
r
ampere_gcgemm_32x32_nt*28 .@€pH€€Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh2
r
ampere_gcgemm_32x32_nt*28ø-@€hH€€Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh2
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ƒà-@€ˆHÈXbfunctional_1/conv2d_15/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28à-@€ˆH€ĞXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
›
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚Ø-@€ø	H€¨Xbfunctional_1/conv2d_3/Conv2Dh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ƒĞ-@€ˆHĞXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‚Ğ-@€ˆH€ÈXbfunctional_1/conv2d_5/Conv2Dh
s
ampere_cgemm_64x64_tn*28‚¸-@ÀHøXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28ƒø,@€˜H Xbfunctional_1/conv2d_15/Conv2Dh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28ø,@˜H€ Xbfunctional_1/conv2d_5/Conv2Dh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28‚ğ,@¸H¸Xbfunctional_1/conv2d_11/Conv2Dh
Á
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚è,@€ØHàXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
Ê
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‚Ø,@€xH€Xbfunctional_1/conv2d/Conv2Dh
s
ampere_cgemm_64x64_tn*28‚È,@ˆHÀXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
º
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28‚È,@ H¨Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28‚È,@ H¨Xbfunctional_1/conv2d_19/Conv2Dh
œ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚¨,@€ø	H Xbfunctional_1/conv2d_18/Conv2Dh
½
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚¨,@ø	H€˜Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28 ,@€ø	H˜Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28ƒà+@€¸HÀXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‚à+@€XHğXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
s
ampere_gcgemm_64x32_nt*28¸+@°H€¸Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚°+@€àH€Xbfunctional_1/conv2d_11/Conv2Dh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28‚¨+@€è
H€ğ
Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28‚ø*@€ˆH
Xbfunctional_1/conv2d_2/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28ø*@€¨H€¸Xbfunctional_1/conv2d_14/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28„ğ*@€ H¸Xbfunctional_1/conv2d_13/Conv2Dh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ğ*@€HH€€Xbfunctional_1/conv2d_19/Conv2Dh2
P
ampere_cgemm_64x32_tn*28‚à*@ HÀXbfunctional_1/conv2d_10/Conv2Dh

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚à*@€ĞHèXbfunctional_1/conv2d_22/Conv2Dh

0ampere_scudnn_128x64_stridedB_splitK_small_nn_v1*28à*@€ H Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ø*@€€H€
Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params)*28Ğ*@Ğ*HĞ*Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚È*@€PH€ˆXbfunctional_1/conv2d_20/Conv2Dh2
æ
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params)*28‚À*@‚À*H‚À*Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
¾
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚¸*@€ÀHàXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x64_16x10::Params)*28‚¸*@‚¸*H‚¸*Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ğ)@€ğHğXbfunctional_1/conv2d_21/Conv2Dh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28‚È)@€èHğXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚À)@€ø	H€¸Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
P
ampere_cgemm_64x32_tn*28‚¨)@¸HğXbfunctional_1/conv2d_11/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28˜)@€ØHèXbfunctional_1/conv2d_1/Conv2Dh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28ƒˆ)@ØHØXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28ƒ€)@ĞHØXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28ø(@€ĞH€ØXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
P
ampere_cgemm_32x32_tn*28‚à(@¨H¸Xbfunctional_1/conv2d_18/Conv2Dh
r
ampere_cgemm_32x32_tn*28‚À(@H°Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ô
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚¸(@€ H¨Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
O
ampere_cgemm_32x32_tn*28‚ (@HXbfunctional_1/conv2d_3/Conv2Dh
q
ampere_cgemm_32x32_tn*28˜(@€€H˜Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28‚ˆ(@€HˆXbfunctional_1/conv2d_20/Conv2Dh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28ğ'@ H€¨Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
¿
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚è'@€ø	H€€
Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€È'@€àH€èXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚À'@àHàXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28‚°'@ˆH˜Xbfunctional_1/conv2d_22/Conv2Dh

cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚°'@ØHØXbfunctional_1/conv2d_20/Conv2Dh
¿
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚°'@ØHØXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
Q
ampere_gcgemm_32x32_nt*28‚¨'@€H€ Xbfunctional_1/conv2d_16/Conv2Dh
›
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚¨'@ĞHØXbfunctional_1/conv2d/Conv2Dh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€¨'@€è	H€ğ	Xbfunctional_1/conv2d_16/Conv2Dh

cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚ '@ĞHĞXbfunctional_1/conv2d_19/Conv2Dh
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚ '@ĞHĞXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚ '@ĞHĞXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh

cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28 '@€ĞHĞXbfunctional_1/conv2d_1/Conv2Dh

cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚˜'@ÈHĞXbfunctional_1/conv2d_21/Conv2Dh
Q
ampere_gcgemm_32x32_nt*28‚ˆ'@€ˆH Xbfunctional_1/conv2d_17/Conv2Dh
ö
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚€'@ÀH€€Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
ö
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚ğ&@ÀH€ğXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
³
øvoid implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28‚è&@øHğXbfunctional_1/conv2d_9/Conv2Dh
š
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28‚ˆ&@€HˆXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
š
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28ˆ&@€H€ˆXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28‚è%@‚è%H‚è%Xbfunctional_1/conv2d_20/Conv2Dh
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28è%@€ HØXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
õ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€è%@€ĞH€¨Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
p
ampere_gcgemm_32x32_nt*28Ø%@€PHhXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh2
r
ampere_cgemm_64x32_tn*28Ğ%@àH€ğXb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
›
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€Ğ%@€ÀH€¨Xbfunctional_1/conv2d_14/Conv2Dh
P
ampere_cgemm_32x32_tn*28‚È%@àHèXbfunctional_1/conv2d_22/Conv2Dh
õ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚À%@€ĞHXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Ò
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€À%@€˜H€ÈXbfunctional_1/conv2d_1/Conv2Dh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28„¸%@€€H€ÈXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x32_tn*28‚¸%@ØHàXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Ó
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚¸%@€˜H€ÈXbfunctional_1/conv2d_21/Conv2Dh
›
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28‚¸%@€ÈH˜Xbfunctional_1/conv2d_13/Conv2Dh
N
ampere_gcgemm_32x32_nt*28¸%@€PH€hXbfunctional_1/conv2d_1/Conv2Dh2
q
ampere_gcgemm_32x32_nt*28€¸%@€PH€hXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh2
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸%@€€H€ÀXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
´
ùvoid implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28¨%@€¸H¸Xbfunctional_1/conv2d_7/Conv2Dh
µ
ùvoid implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28 %@°H€¸Xbfunctional_1/conv2d_12/Conv2Dh
O
ampere_gcgemm_32x32_nt*28€%@€PH€hXbfunctional_1/conv2d_21/Conv2Dh2
š
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28‚€%@ÀHÀXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
š
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28‚ø$@¸HÀXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚ $@€°HàXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28˜$@€ˆHˆXb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28˜$@€ˆHXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28€€$@€ğH€ˆXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28‚ø#@€ğHˆXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Ğ#@€èHèXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Ğ#@àH€ğXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1*28ƒÀ#@èHğXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28‚#@ÈHÈXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
µ
ùvoid implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28À"@€ H Xbfunctional_1/conv2d_13/Conv2Dh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€ "@€°H€¸Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
P
ampere_gcgemm_64x32_nt*28‚ø!@ğHˆXbfunctional_1/conv2d_8/Conv2Dh
s
ampere_gcgemm_64x32_nt*28‚ø!@øH€Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28‚è!@ğHøXb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
µ
ùvoid implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28ƒà!@˜H¨Xbfunctional_1/conv2d_10/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28‚à!@¸H¨Xbfunctional_1/conv2d_11/Conv2Dh
³
øvoid implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28‚Ø!@àHøXbfunctional_1/conv2d_9/Conv2Dh
r
ampere_gcgemm_64x32_nt*28‚À!@ÈHøXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
Q
ampere_gcgemm_64x32_nt*28!@€ÈHÈXbfunctional_1/conv2d_10/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28‚ø @¸HÀXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28ø @€ø
H€Xbfunctional_1/conv2d_17/Conv2Dh
ö
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28‚ğ @¸H¸Xbfunctional_1/conv2d_1/Conv2Dh
÷
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28ğ @€¸H¸Xbfunctional_1/conv2d_21/Conv2Dh
˜
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28ğ @€¸H¸Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
ô
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28è @€°H¸Xbfunctional_1/conv2d/Conv2Dh
÷
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28è @€°H¸Xbfunctional_1/conv2d_19/Conv2Dh
÷
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28è @€°H¸Xbfunctional_1/conv2d_20/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28è @°H€¸Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Ø @€ğ
Hø
Xbfunctional_1/conv2d_18/Conv2Dh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Ø @€ğ
H€ø
Xbfunctional_1/conv2d_3/Conv2Dh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Ğ @€¨H¨Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28‚À @ H Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
³
øvoid implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28° @€èH¨Xbfunctional_1/conv2d_8/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€° @€H€ Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€° @€8H€`Xbfunctional_1/conv2d_20/Conv2Dh2
½
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚¨ @€˜Hø	Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28‚¨ @H˜Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
R
ampere_sgemm_128x128_nn*28 @€ˆHˆXbfunctional_1/conv2d_17/Conv2Dh
½
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€ˆ @€¨H€àXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28‚€ @€8H€`Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh2
½
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28‚è@€¨HÈXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
„
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28‚à@€8H€`Xbfunctional_1/conv2d_1/Conv2Dh2
r
ampere_cgemm_32x32_tn*28‚Ø@èHğXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28À@€8H€`Xbfunctional_1/conv2d_21/Conv2Dh2
O
ampere_gcgemm_32x32_nt*28€À@€HH€`Xbfunctional_1/conv2d_22/Conv2Dh2
î=
=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28‚°@‚°H‚°Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ƒ¨@€@H`Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh2
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28‚à@€8H€`Xbfunctional_1/conv2d_19/Conv2Dh2
u
ampere_sgemm_128x128_nt*28€à@€ 
H€ 
Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Ø@¨H€°Xbfunctional_1/conv2d_16/Conv2Dh
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ğ@€¨H¨Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
î=
=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28‚À@ H Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Ø
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚¸@€@H€`Xbfunctional_1/conv2d_1/Conv2Dh2
u
ampere_sgemm_128x128_nt*28¸@€
H€˜
Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28¸@€
H€˜
Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28¸@€8H€`Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh2
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28¨@€8H€XXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh2
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28 @€8H€`Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh2
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ƒ˜@€@H€XXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh2
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ˆ@€ˆHø	Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚ø@€8HXXbfunctional_1/conv2d_21/Conv2Dh2
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28è@€8HXXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh2
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚È@€8H€XXbfunctional_1/conv2d_22/Conv2Dh2
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28À@€è	H€ğ	Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
t
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28°@€à	Hè	Xbfunctional_1/conv2d/Conv2Dh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28¨@ĞH€ØXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28¨@€ĞHØXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28 @€ĞHĞXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
ö
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28˜@€ğH€àXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28˜@ÈH€ĞXbfunctional_1/conv2d_8/Conv2Dh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚€@¸HÈXbfunctional_1/conv2d_11/Conv2Dh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28è@€°H¸Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28‚à@°H°Xbfunctional_1/conv2d_18/Conv2Dh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28È@€ H¨Xbfunctional_1/conv2d_3/Conv2Dh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚¸@˜H Xbfunctional_1/conv2d_10/Conv2Dh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28°@€˜H˜Xbfunctional_1/conv2d_14/Conv2Dh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28‚˜@ˆHXbfunctional_1/conv2d_13/Conv2Dh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€@ÈH€°Xbfunctional_1/conv2d_4/Conv2Dh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€@€ÀH€¨Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
‚
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ø@€8H€XXbfunctional_1/conv2d/Conv2Dh2
š
Şvoid precomputed_convolve_sgemm<float, 512, 6, 7, 4, 3, 5, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)*28è@èHèXbfunctional_1/conv2d_14/Conv2Dh
r
ampere_cgemm_64x32_tn*28‚à@ğHğXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
O
ampere_cgemm_32x32_tn*28à@€ØHˆXbfunctional_1/conv2d_2/Conv2Dh
q
ampere_cgemm_64x32_tn*28à@€ğHğXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
O
ampere_cgemm_64x32_tn*28Ø@àH€øXbfunctional_1/conv2d_5/Conv2Dh
P
ampere_cgemm_64x32_tn*28Ğ@àH€ğXbfunctional_1/conv2d_15/Conv2Dh
ó
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ğ@€ˆH€àXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
Ó
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28È@€˜HĞXbfunctional_1/conv2d_22/Conv2Dh
´
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28À@€àHàXbfunctional_1/conv2d_3/Conv2Dh
¢
Ævoid gemv2T_kernel_val<int, int, float2, float2, float2, 128, 16, 2, 2, false, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>, float2, float2)*28¸@ØH€àXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€¨@€ĞH€ØXbfunctional_1/conv2d_9/Conv2Dh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28 @€ĞHĞXbfunctional_1/conv2d_18/Conv2Dh
³
øvoid explicit_convolve_sgemm<float, int, 128, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28‚˜@ÈHĞXbfunctional_1/conv2d_9/Conv2Dh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚ˆ@ÀHÈXbfunctional_1/conv2d_10/Conv2Dh
Ó
ôvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28€@€H€Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
Ò
ôvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28‚ø@‚øH‚øXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
Ó
ôvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28ø@øHøXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
Ò
ôvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28ø@øHøXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
ö
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28è@€ĞH€èXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
€
¤void gemv2N_kernel<int, int, float, float, float, 128, 8, 4, 4, 1, false, cublasGemvParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28‚Ø@€èH€	Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28Ğ@ H€°Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Ğ@€ĞHØXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28È@€8HHXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh2
õ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€È@€ĞH€ØXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
Ö
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28À@€@H€PXbfunctional_1/conv2d/Conv2Dh2
ª
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€À@€ H€ Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
‘
3ampere_scudnn_128x64_stridedB_splitK_interior_nn_v1*28‚°@‚°H‚°Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¼
İvoid cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28°@°H°Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
q
ampere_gcgemm_32x32_nt*28€°@€@H€HXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh2
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28‚¨@€àHèXbfunctional_1/conv2d_14/Conv2Dh
¿
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚¨@˜HXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
ª
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28‚˜@ˆHXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28‚@€H€àXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
ô
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28‚€@€°H€ØXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28‚ø@€8HHXbfunctional_1/conv2d_22/Conv2Dh2
õ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28è@€¨H€ĞXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28‚à@èHøXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Ó
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28à@€ H€ØXbfunctional_1/conv2d_18/Conv2Dh
Ò
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ø@€ H€ĞXbfunctional_1/conv2d_3/Conv2Dh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ğ@ÀH€ÈXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Q
ampere_gcgemm_64x32_nt*28°@€H˜Xbfunctional_1/conv2d_15/Conv2Dh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28ƒ¨@¸H¸Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
s
ampere_gcgemm_64x32_nt*28¨@€H€˜Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
í
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28 @€ĞHĞXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
r
ampere_gcgemm_64x32_nt*28‚˜@€H€˜Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
P
ampere_gcgemm_64x32_nt*28˜@€H€˜Xbfunctional_1/conv2d_5/Conv2Dh
í
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28‚@ÈHÈXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
r
ampere_cgemm_64x64_tn*28‚ø@¨HĞXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28ø@øHøXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
î=
=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28ø@øHøXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ğ@€ˆH€àXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
s
ampere_cgemm_64x64_tn*28è@€¨HÀXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28è@¨H€ÀXbfunctional_1/conv2d_16/Conv2Dh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€Ğ@€ H€°Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
r
ampere_cgemm_64x64_tn*28È@€˜H°Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh

0ampere_scudnn_128x64_stridedB_splitK_small_nn_v1*28À@€H˜Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
Ú
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€¸@€H€˜Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°@€˜H€˜Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
P
ampere_gcgemm_32x32_nt*28‚¨@€˜H€¸Xbfunctional_1/conv2d_3/Conv2Dh
s
ampere_gcgemm_32x32_nt*28‚¨@€˜H€ÀXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
Q
ampere_gcgemm_32x32_nt*28¨@€˜H€°Xbfunctional_1/conv2d_18/Conv2Dh
r
ampere_gcgemm_32x32_nt*28¨@€H€¸Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28¨@€H˜Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
Á
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28¨@H€˜Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28¨@¨H¨Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28‚ @ˆH˜Xbfunctional_1/conv2d_15/Conv2Dh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ @€€H€àXbfunctional_1/conv2d_16/Conv2Dh
´
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28‚ğ@øHøXbfunctional_1/conv2d_5/Conv2Dh
¹
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28è@€ğHøXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
º
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28€è@€ğH€øXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ø@€ˆH€àXbfunctional_1/conv2d_17/Conv2Dh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€¸@€èH€ğXbfunctional_1/conv2d_4/Conv2Dh
¡
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28˜@˜H˜Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28˜@˜H˜Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€@€€H€èXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28‚€@€ĞHØXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
†
)ampere_scudnn_128x64_stridedB_small_nn_v1*28€@ĞH€ØXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Ø@€¨H°Xbfunctional_1/conv2d_12/Conv2Dh
´
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Ø@€¨H°Xbfunctional_1/conv2d_7/Conv2Dh
q
ampere_cgemm_32x32_tn*28È@˜H€°Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28¸@€øH¨Xbfunctional_1/conv2d_12/Conv2Dh
›
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28°@€H€˜Xbfunctional_1/conv2d_2/Conv2Dh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28¨@€øH˜Xbfunctional_1/conv2d_7/Conv2Dh
š
ávoid gemmk1_kernel<float2, 256, 5, true, false, false, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28¨@H€˜Xbfunctional_1/conv2d/Conv2Dh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€¨@€°H€ÀXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x32_tn*28‚ø@ø
H€Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
P
ampere_cgemm_64x32_tn*28ø@€ø
H€Xbfunctional_1/conv2d_12/Conv2Dh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28ğ@ğHğXbfunctional_1/conv2d_19/Conv2Dh
t
ampere_sgemm_128x128_nt*28à@€ğ
Hğ
Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28‚Ø@è
Hğ
Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
q
ampere_cgemm_64x32_tn*28€Ø@€Ø
H€€Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
O
ampere_cgemm_64x32_tn*28È@€à
Hè
Xbfunctional_1/conv2d_7/Conv2Dh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€ @€€H€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
¾
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€ @€¨H€¨Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
Q
ampere_sgemm_128x128_nn*28‚˜@È
HĞ
Xbfunctional_1/conv2d_3/Conv2Dh
R
ampere_sgemm_128x128_nn*28@€À
HĞ
Xbfunctional_1/conv2d_18/Conv2Dh
í=
=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28€@€H€Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
î=
=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28€€@€€H€€Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28è@èHèXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28€À@€ 
H€ 
Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€°@€
H€ 
Xbfunctional_1/conv2d_1/Conv2Dh
t
ampere_sgemm_128x128_nt*28 @€
H
Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28 @€
H
Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28 @ H Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€ @€
H€
Xbfunctional_1/conv2d_10/Conv2Dh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28˜@˜H˜Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28@€ˆ
Hˆ
Xbfunctional_1/conv2d_17/Conv2Dh
¢
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28@HXbfunctional_1/conv2d_14/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@€ˆ
H€ˆ
Xbfunctional_1/conv2d_22/Conv2Dh
õ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ˆ@€ÀHÈXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
¾
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€ˆ@€°H€ØXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ˆ@€€
H€ˆ
Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
›
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚€@€
H€
Xbfunctional_1/conv2d_3/Conv2Dh
ô
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€€@€°H€ĞXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
q
ampere_cgemm_64x32_tn*28‚ø@è	H
Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
œ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ø@ø	H€€
Xbfunctional_1/conv2d_18/Conv2Dh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28ø@øHøXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
œ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ø@€ø	H€€
Xbfunctional_1/conv2d_16/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ø@€ø	H€€
Xbfunctional_1/conv2d_21/Conv2Dh
›
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ğ@€ø	Hø	Xbfunctional_1/conv2d_2/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ğ@€ø	Hø	Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
q
ampere_gcgemm_32x32_nt*28€ğ@€xH€ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
œ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ğ@€ğ	H€€
Xbfunctional_1/conv2d_17/Conv2Dh
½
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28è@ğ	H€ø	Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ç
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€è@€àH€ˆXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28‚à@ğ	Hğ	Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
š
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28à@€ğ	Hğ	Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€à@€è	H€ø	Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ø@è	H€ğ	Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
½
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ø@€¨HÈXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
¼
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€Ø@€¨H€ÀXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
O
ampere_cgemm_64x32_tn*28‚È@à	Hè	Xbfunctional_1/conv2d_9/Conv2Dh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€È@€Ø	H€ğ	Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28°@€Ğ	Hà	Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
š
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28°@€¨H€°Xbfunctional_1/conv2d_5/Conv2Dh
›
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€°@€¨H€°Xbfunctional_1/conv2d_15/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28‚˜@È	HĞ	Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
´
ùvoid implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€˜@€°H€¸Xbfunctional_1/conv2d_6/Conv2Dh
š
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€@€È	H€È	Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28‚€@ H°Xbfunctional_1/conv2d_18/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28‚ø@€¨H¨Xbfunctional_1/conv2d_3/Conv2Dh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1*28è@€ H€¨Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1*28Ø@€˜H Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28‚Ğ@ 	H°	Xbfunctional_1/conv2d_21/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28‚È@ 	H¨	Xbfunctional_1/conv2d_12/Conv2Dh
s
ampere_gcgemm_64x32_nt*28‚È@ 	H¨	Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28È@€ 	H¨	Xbfunctional_1/conv2d_11/Conv2Dh
r
ampere_gcgemm_64x32_nt*28€È@€ 	H€¨	Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€È@€ 	H€¨	Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28‚À@ 	H 	Xbfunctional_1/conv2d/Conv2Dh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28À@€ 	H 	Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28À@€ 	H 	Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
P
ampere_gcgemm_64x32_nt*28€À@€ 	H€ 	Xbfunctional_1/conv2d_7/Conv2Dh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€À@€ 	H€ 	Xbfunctional_1/conv2d_1/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28¸@˜	H€ 	Xbfunctional_1/conv2d_9/Conv2Dh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28¸@˜	H€ 	Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€°@€˜	H€˜	Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€ğH€èXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28‚@ˆ	Hˆ	Xbfunctional_1/conv2d_20/Conv2Dh
O
ampere_cgemm_64x32_tn*28@€ˆ	Hˆ	Xbfunctional_1/conv2d_4/Conv2Dh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€è@€èH€àXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
¶
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€À@€€H€àXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28¸@¸H¸Xbfunctional_1/conv2d_17/Conv2Dh
q
ampere_cgemm_32x32_tn*28@€¸HØXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€@€ØH€àXbfunctional_1/conv2d_2/Conv2Dh
r
ampere_gcgemm_32x32_nt*28‚ˆ@€ˆH€˜Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ö
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28ˆ@€ÀHÈXbfunctional_1/conv2d_2/Conv2Dh
“
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€ˆ@€xH€ÈXbfunctional_1/conv2d_9/Conv2Dh
˜
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€@€ÀHÀXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ö
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€€@€ÀH€ÀXbfunctional_1/conv2d_3/Conv2Dh
÷
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28ø@¸H€ÀXbfunctional_1/conv2d_17/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28ø@¸H€ÀXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
÷
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€ø@€¸H€ÀXbfunctional_1/conv2d_18/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€ø@€¸H€ÀXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
÷
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28ğ@€¸H¸Xbfunctional_1/conv2d_16/Conv2Dh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€à@€°H€°Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
´
øvoid implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Ø@€ H¸Xbfunctional_1/conv2d_14/Conv2Dh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ø@€ĞH€ğXbfunctional_1/conv2d_13/Conv2Dh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ğ@€¨H¨Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
O
ampere_gcgemm_32x32_nt*28‚È@€hH€€Xbfunctional_1/conv2d_2/Conv2Dh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€À@€ØH€àXbfunctional_1/conv2d_14/Conv2Dh
u
ampere_sgemm_128x128_nt*28¸@¸H€ÀXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
»
ÿvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 2, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28¸@€˜H Xbfunctional_1/conv2d_22/Conv2Dh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28°@€˜H˜Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28°@€˜H˜Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28°@€˜H˜Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
™
Şvoid precomputed_convolve_sgemm<float, 512, 6, 8, 3, 3, 5, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)*28€°@€°H€°Xbfunctional_1/conv2d_9/Conv2Dh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28 @€HXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
Ú
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28˜@€ˆHXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
R
ampere_sgemm_128x128_nn*28€˜@€°H€¸Xbfunctional_1/conv2d_11/Conv2Dh
´
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28@€ˆHˆXbfunctional_1/conv2d_2/Conv2Dh
P
ampere_gcgemm_64x32_nt*28‚ˆ@€€H€ˆXbfunctional_1/conv2d_4/Conv2Dh
R
ampere_sgemm_128x128_nn*28€ˆ@€€H€ˆXbfunctional_1/conv2d_14/Conv2Dh
Q
ampere_sgemm_128x128_nn*28‚€@€H€Xbfunctional_1/conv2d_2/Conv2Dh

1ampere_scudnn_128x64_stridedB_splitK_medium_nn_v1*28€Ø@€ØH€ØXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€Ğ@€èH€èXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€Ğ@€HH€Xbfunctional_1/conv2d_3/Conv2Dh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28È@€HH€Xbfunctional_1/conv2d_18/Conv2Dh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È@€XH€Xbfunctional_1/conv2d_2/Conv2Dh
¨
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28À@€PH€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€À@€HH€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28‚°@€PH€Xbfunctional_1/conv2d_17/Conv2Dh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28¨@€PH€Xbfunctional_1/conv2d_16/Conv2Dh
Œ
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28€˜@€˜H€˜Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€àH€ğXbfunctional_1/conv2d_10/Conv2Dh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€˜@€ÈH€ˆXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Ó
ôvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28€˜@€˜H€˜Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28‚ˆ@€H€ˆXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€ˆ@€€H€ˆXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28‚€@€€H€Xbfunctional_1/conv2d_12/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€@€€H€Xbfunctional_1/conv2d_15/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€@€€H€Xbfunctional_1/conv2d_7/Conv2Dh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€@€àHàXb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€€H€
Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28ø@øHøXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
‘
Øvoid gemmk1_kernel<float, 256, 5, false, false, false, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>(cublasGemmk1Params<float, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float, biasType<cublasGemvTensorStridedBatched<float>::value_type, float>::type>)*28€ø@€¸H€ÀXbfunctional_1/conv2d/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28ğ@€øH€€Xbfunctional_1/conv2d_5/Conv2Dh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28ğ@€€Hğ	Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28è@°H€¸Xbfunctional_1/conv2d_7/Conv2Dh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€è@€ØH€àXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€è@€°H€¸Xbfunctional_1/conv2d_12/Conv2Dh

0ampere_scudnn_128x64_stridedB_splitK_small_nn_v1*28à@€ğHøXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
½
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€à@€°H€€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
æ
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ø@€¨H€°Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Ğ@€¨H¨Xbfunctional_1/conv2d_11/Conv2Dh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€Ğ@€ H€°Xbfunctional_1/conv2d_15/Conv2Dh
š
Şvoid precomputed_convolve_sgemm<float, 512, 6, 7, 4, 3, 5, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)*28È@ÈHÈXbfunctional_1/conv2d_13/Conv2Dh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€È@€˜H€°Xbfunctional_1/conv2d_5/Conv2Dh
Œ
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28À@ÀHÀXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x64_tn*28€À@€ H€ Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28¸@€HH€€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€HH€€Xbfunctional_1/conv2d_3/Conv2Dh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€HH€ˆXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€¨@€H€˜Xbfunctional_1/conv2d_2/Conv2Dh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€ @€H€Xbfunctional_1/conv2d_13/Conv2Dh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28˜@€HH€€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚@€HH€€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€HH€€Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€ˆ@€€H€ˆXbfunctional_1/conv2d_8/Conv2Dh
ª
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€@€€H€Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€@€HH€€Xbfunctional_1/conv2d_18/Conv2Dh
r
ampere_cgemm_64x64_tn*28€€@€øH€ˆXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Œ
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
‹
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28€€@€€H€€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
‹
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28€€@€€H€€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
¸
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28ø@€ĞH€ØXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ø@€øH€€Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6::Params)*28ğ@ğHğXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
˜
ávoid gemmk1_kernel<float2, 256, 5, false, false, true, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28ğ@€H(Xbfunctional_1/conv2d/Conv2Dh2
¸
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28è@€ÈHĞXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
ì
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€à@€ØH€ˆXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
Ò
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ø@€°H€ÀXbfunctional_1/conv2d_2/Conv2Dh
ì
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Ğ@€èHèXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
³
øvoid explicit_convolve_sgemm<float, int, 128, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28À@€àHàXbfunctional_1/conv2d_8/Conv2Dh
í
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28À@€àHàXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
¾
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28¸@€¨H€¸Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
¼
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28°@€ H€¸Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ì
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€°@€ØH€ØXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6::Params)*28€¨@€ĞH€ØXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_64x32_tn*28€ @€ÈH€ØXbfunctional_1/conv2d_6/Conv2Dh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€˜@€ÈH€ĞXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
q
ampere_cgemm_64x32_tn*28€€@€°H€ĞXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28‚è@€ H¨Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
´
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28è@€°H¸Xbfunctional_1/conv2d_4/Conv2Dh
¹
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28À@˜H€¨Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28€À@€ H€ Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28¨@€H˜Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ˆ@€°HØXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€€@€øH€ˆXbfunctional_1/conv2d_2/Conv2Dh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€H€àXbfunctional_1/conv2d_6/Conv2Dh
´
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28è@€ğHøXbfunctional_1/conv2d_6/Conv2Dh
Ä
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)*28€à@€àH€àXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ş
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚À@€€HàXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
é
«void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28€À@€ØH€èb!functional_1/concatenate_3/concath
‚
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€À@€ÀH€ÀXbfunctional_1/conv2d_19/Conv2Dh
q
ampere_cgemm_64x32_tn*28°@€ØHØXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¥
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€°@€°H€°Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
¤
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28 @ H Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Ä
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)*28˜@˜H˜Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ã
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)*28€˜@€˜H€˜Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1*28€@€ĞH€àXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ã
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)*28€@€H€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
P
ampere_gcgemm_64x32_nt*28€ø
@€¸H€ÀXbfunctional_1/conv2d_6/Conv2Dh
Q
ampere_sgemm_128x128_nn*28€ø
@€ĞH€ØXbfunctional_1/conv2d_9/Conv2Dh
O
ampere_cgemm_64x32_tn*28€è
@€°H€¸Xbfunctional_1/conv2d_8/Conv2Dh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28à
@€°H°Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28à
@€°H°Xbfunctional_1/conv2d_18/Conv2Dh
r
ampere_gcgemm_64x32_nt*28€à
@€°H€°Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
Ø
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€à
@€ÈH€ĞXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
‡
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€Ø
@€˜H€ÀXbfunctional_1/conv2d_13/Conv2Dh
¹
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28€Ğ
@€Ğ
H€Ğ
Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
í=
=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28€Ğ
@€Ğ
H€Ğ
Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
¨
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€Ğ
@€˜H€ÀXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
‡
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28È
@€˜H€ÀXbfunctional_1/conv2d_14/Conv2Dh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€È
@€ H€¨Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È
@€˜H€ÀXbfunctional_1/conv2d_4/Conv2Dh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È
@€˜H€ÀXbfunctional_1/conv2d_5/Conv2Dh
‡
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28À
@€˜H€¸Xbfunctional_1/conv2d_15/Conv2Dh
s
ampere_sgemm_128x128_nt*28€À
@€ÀH€ÀXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28€À
@€ H€ Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28¸
@€H¨Xbfunctional_1/conv2d_10/Conv2Dh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28¸
@€˜H¸Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ø
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸
@€@H€`Xbfunctional_1/conv2d_2/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28‚°
@˜H˜Xbfunctional_1/conv2d_14/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28¨
@H€˜Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28¨
@¨
H¨
Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28€¨
@€H€˜Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€¨
@€ H€€Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28 
@€HXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28‚˜
@ˆHXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28˜
@€H€
Xbfunctional_1/conv2d_19/Conv2Dh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€˜
@€ˆH€Xbfunctional_1/conv2d_3/Conv2Dh
š
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€˜
@€àH€°Xbfunctional_1/conv2d_4/Conv2Dh
½
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€˜
@€àH€°Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
µ
ùvoid implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€
@€€H€ˆXbfunctional_1/conv2d_23/Conv2Dh
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28ˆ
@ˆ
Hˆ
Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28ˆ
@ˆ
Hˆ
Xbfunctional_1/conv2d_18/Conv2Dh
Ë
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28ˆ
@ˆ
Hˆ
Xbfunctional_1/conv2d_3/Conv2Dh
½
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ˆ
@€€H€ˆXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ˆ
@€8H€XXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ˆ
@€ H€è	Xbfunctional_1/conv2d_20/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€
@€€H€Xbfunctional_1/conv2d_8/Conv2Dh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28€
@€
H€
Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€
@€€H€Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€€
@€€H€€Xbfunctional_1/conv2d_13/Conv2Dh
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28ø	@ø	Hø	Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ğ	@ğ	Hğ	bpgradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€ğ	@€xH€€Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ğ	@€€H€ÈXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28‚è	@€ˆH€ÀXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28è	@è	Hè	Xbfunctional_1/conv2d_11/Conv2Dh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€è	@€€H€ÈXbfunctional_1/conv2d_5/Conv2Dh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€è	@€è	H€è	Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
R
ampere_sgemm_128x128_nn*28à	@€ğHğXbfunctional_1/conv2d_15/Conv2Dh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28à	@€ˆH€ÀXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
Q
ampere_sgemm_128x128_nn*28€à	@€ğH€ğXbfunctional_1/conv2d_5/Conv2Dh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€à	@€à	H€à	bqgradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
s
ampere_sgemm_128x128_nt*28Ø	@èH€ğXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ø	@Ø	HØ	bpgradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh

1ampere_scudnn_128x64_stridedB_splitK_medium_nn_v1*28€Ø	@€Ø	H€Ø	Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh

1ampere_scudnn_128x64_stridedB_splitK_medium_nn_v1*28€Ø	@€Ø	H€Ø	Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€Ø	@€èH€ğXbfunctional_1/conv2d_2/Conv2Dh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ø	@€€H€ÀXbfunctional_1/conv2d_15/Conv2Dh
t
ampere_sgemm_128x128_nt*28Ğ	@€èHèXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€Ğ	@€àH€ğXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€È	@€àH€èXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€À	@€àH€àXbfunctional_1/conv2d_17/Conv2Dh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€À	@€àH€àXbfunctional_1/conv2d_18/Conv2Dh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€À	@€àH€àXbfunctional_1/conv2d_3/Conv2Dh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€À	@€€H€ÀXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€À	@€€H€ÀXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€¸	@€ØH€àXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€¸	@€ØH€àXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Œ
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28°	@°	H°	Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28¨	@ĞH€ØXbfunctional_1/conv2d_10/Conv2Dh
‹
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28€¨	@€¨	H€¨	Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh

1ampere_scudnn_128x64_stridedB_splitK_medium_nn_v1*28 	@ 	H 	Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
˜
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28‚˜	@ÈHĞXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
‹
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28˜	@˜	H˜	Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28˜	@€ˆHˆXbfunctional_1/conv2d_4/Conv2Dh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€	@€	H€	Xbfunctional_1/conv2d_16/Conv2Dh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28ˆ	@€ÀHÈXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
“
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28ˆ	@€HHøXbfunctional_1/conv2d_8/Conv2Dh
s
ampere_sgemm_128x128_nt*28€€	@€ÀH€ÀXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ü
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€€	@€ÀH€ÀXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28ğ@€øH€€Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28€ğ@€øH€€Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28à@€°H°Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€Ø@€ğH€øXbfunctional_1/conv2d_6/Conv2Dh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€Ø@€¨H€°Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28€Ğ@€ğH€ğXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
Ú
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€Ğ@€¨H€¨Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
™
Şvoid precomputed_convolve_sgemm<float, 512, 6, 8, 3, 3, 5, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)*28È@ÈHÈXbfunctional_1/conv2d_8/Conv2Dh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€À@€ĞH€ĞXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Ü
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€À@€ H€ Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€¸@€èH€èXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€¸@€ˆH€Xbfunctional_1/conv2d_7/Conv2Dh

1ampere_scudnn_128x64_stridedB_splitK_medium_nn_v1*28°@°H°Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
‡
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28°@€ˆHXbfunctional_1/conv2d_10/Conv2Dh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€°@€˜H€˜Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
‡
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€°@€ˆH€Xbfunctional_1/conv2d_11/Conv2Dh
¨
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€°@€ˆH€Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
¦
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€°@€˜H€˜Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
¥
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28¨@€H˜Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28 @€ˆHˆXbfunctional_1/conv2d_6/Conv2Dh
¦
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28 @€HXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
¥
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28 @€HXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b>gradient_tape/functional_1/leaky_re_lu/LeakyRelu/LeakyReluGradh
ê
Œvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x128_32x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x128_32x3::Params)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
‡
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ @€€H€Xbfunctional_1/conv2d_12/Conv2Dh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ @€ˆH€ˆXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
¦
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28‚˜@ˆHXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28˜@˜H˜bAgradient_tape/functional_1/leaky_re_lu_19/LeakyRelu/LeakyReluGradh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28˜@˜H˜bAgradient_tape/functional_1/leaky_re_lu_21/LeakyRelu/LeakyReluGradh
t
ampere_sgemm_128x128_nt*28€˜@€ØH€àXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28@HbAgradient_tape/functional_1/leaky_re_lu_20/LeakyRelu/LeakyReluGradh
Ò
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b@gradient_tape/functional_1/leaky_re_lu_1/LeakyRelu/LeakyReluGradh
à
Švoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€@€H€b9functional_1/up_sampling2d_3/resize/ResizeNearestNeighborh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€@€ĞHØXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
ş
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€€H€€Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh

Ävoid cudnn::pooling_bw_kernel_max<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€ø@€øH€øb<gradient_tape/functional_1/max_pooling2d/MaxPool/MaxPoolGradh
æ
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€ø@€øH€€Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ğ@ğH€ˆXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€è@€ğH€øXbfunctional_1/conv2d_6/Conv2Dh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28à@€ğHğXbfunctional_1/conv2d_12/Conv2Dh
è
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6::Params)*28à@àHàXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
ú
’void tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28à@àHàbKgradient_tape/functional_1/up_sampling2d_3/resize/ResizeNearestNeighborGradh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6::Params)*28€à@€àH€àXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Ø@èH€ğXbfunctional_1/conv2d_7/Conv2Dh
ì
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Ø@€èHğXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
‚
Ævoid gemv2T_kernel_val<int, int, float2, float2, float2, 128, 16, 2, 2, false, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>, float2, float2)*28€Ø@€ØH€€Xbfunctional_1/conv2d_23/Conv2Dh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Ğ@€èHèXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
ş
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ğ@€èH€èXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€È@€àH€èXbfunctional_1/conv2d_13/Conv2Dh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€È@€àH€èXbfunctional_1/conv2d_14/Conv2Dh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€È@€ĞH€øXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
Q
ampere_sgemm_128x128_nn*28À@€àHàXbfunctional_1/conv2d_4/Conv2Dh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€À@€àH€àXbfunctional_1/conv2d_4/Conv2Dh
’
ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28¸@¸H¸bAddN_5h
Ê
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€¸@€ØH€àXbfunctional_1/conv2d_15/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28°@€°HÀXbfunctional_1/conv2d_11/Conv2Dh
É
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28°@€ØHØXbfunctional_1/conv2d_4/Conv2Dh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28°@€ØHØXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Ê
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€°@€ØH€ØXbfunctional_1/conv2d_13/Conv2Dh
Ê
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€°@€ØH€ØXbfunctional_1/conv2d_14/Conv2Dh
ì
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€°@€ØH€ØXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€ØH€ØXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
É
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28¨@€ĞHØXbfunctional_1/conv2d_5/Conv2Dh
ë
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€¨@€ĞH€ØXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
¸
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€ø@€¨H€¨Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
¨
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ø@€¸H€ÀXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ğ@€¸H€¸Xbfunctional_1/conv2d_8/Conv2Dh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ğ@€¸H€¸Xbfunctional_1/conv2d_9/Conv2Dh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ğ@€¸H€¸Xbfunctional_1/conv2d_9/Conv2Dh
¸
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28è@€ H¨Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
·
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€è@€ H€¨Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28€à@€àH€àXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€Ø@€˜H€ Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
Ä
ivoid fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)*28€Ğ@€H€hXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh

¦
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È@€XH€xXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28€¸@€H€¨Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
¢
ivoid fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)*28€¸@€`H€pXbfunctional_1/conv2d_23/Conv2Dh
Q
ampere_sgemm_128x128_nn*28‚°@˜H˜Xbfunctional_1/conv2d_7/Conv2Dh
t
ampere_sgemm_128x128_nt*28°@H€ Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
Ü
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28°@€HXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
R
ampere_sgemm_128x128_nn*28€°@€˜H€˜Xbfunctional_1/conv2d_12/Conv2Dh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28¨@€øH˜Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
¡
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28¨@¨H¨Xbfunctional_1/conv2d_9/Conv2Dh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¨@€øH€˜Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
Ú
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¨@€€H€˜Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¨@€H€ˆXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€ @€ˆH€Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28˜@€HøXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Q
ampere_sgemm_128x128_nn*28€@€€H€ˆXbfunctional_1/conv2d_8/Conv2Dh
Ë
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€@€H€Xbfunctional_1/conv2d_2/Conv2Dh
ä
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€@€€H€Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28€ø@€øH€€Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¥
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€ğ@€ğH€ğXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Ø
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€è@€HH€xXbfunctional_1/conv2d_4/Conv2Dh
‚
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€è@€èH€èXbfunctional_1/conv2d_16/Conv2Dh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28à@€HÈXbfunctional_1/conv2d_16/Conv2Dh
s
ampere_sgemm_128x128_nt*28€Ø@€èH€ğXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€Ø@€H€àXbfunctional_1/conv2d_13/Conv2Dh
¤
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€Ø@€ØH€ØXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
é
«void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28€Ğ@€èH€èb!functional_1/concatenate_2/concath
¹
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28€Ğ@€ĞH€ĞXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
ş
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€È@€ÈH€Èb0gradient_tape/functional_1/concatenate_3/Slice_1h
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€È@€àH€èXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
ü
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28À@ÀHÀb.gradient_tape/functional_1/concatenate_3/Sliceh
÷
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€¸@€ØH€àXbfunctional_1/conv2d_22/Conv2Dh
¶
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€¸@€¸H€¸b$functional_1/leaky_re_lu_1/LeakyReluh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€¸@€¸H€¸b%functional_1/leaky_re_lu_20/LeakyReluh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€¸@€¸H€¸b%functional_1/leaky_re_lu_21/LeakyReluh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¸@€ØH€àXbfunctional_1/conv2d_2/Conv2Dh
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride::Params)*28€¸@€¸H€¸Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€°@€°H€°b"functional_1/leaky_re_lu/LeakyReluh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€°@€°H€°b%functional_1/leaky_re_lu_19/LeakyReluh
t
ampere_sgemm_128x128_nt*28€¨@€àH€èXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¨@€ĞH€ØXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€¨@€ H€ˆXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€ @€ĞH€ĞXbfunctional_1/conv2d_9/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€ĞH€ĞXbfunctional_1/conv2d_15/Conv2Dh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€ĞH€ĞXbfunctional_1/conv2d_5/Conv2Dh
Ë
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€ @€ H€ Xbfunctional_1/conv2d_7/Conv2Dh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ @€H€ˆXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
¨
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€ @€°H€ğXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
’
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€ @€ H€ bfunctional_1/conv2d_1/BiasAddh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28˜@H€€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28˜@€ÈHĞXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28˜@˜H˜bPfunctional_1/conv2d_19/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€˜@€ÈH€ĞXbfunctional_1/conv2d_6/Conv2Dh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€˜@€˜H€˜Xbfunctional_1/conv2d_12/Conv2Dh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€˜@€H€€Xbfunctional_1/conv2d_17/Conv2Dh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€˜@€˜H€˜bfunctional_1/conv2d/BiasAddh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€˜@€˜H€˜bfunctional_1/conv2d_19/BiasAddh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28@ÀH€ĞXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28@Hbfunctional_1/conv2d_21/BiasAddh

cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€@€ÀH€ĞXbfunctional_1/conv2d_22/Conv2Dh
‚
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€@€ÈH€ÈXbfunctional_1/conv2d_9/Conv2Dh
ç
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€ÈH€ÈXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€@€H€bfunctional_1/conv2d_20/BiasAddh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bMfunctional_1/conv2d/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
”
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bOfunctional_1/conv2d_1/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bPfunctional_1/conv2d_21/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
§
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bbgradient_tape/functional_1/concatenate_3/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ˆ@€ÀH€ÈXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ˆ@€ÀH€ÈXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ˆ@€ˆH€ˆXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ˆ@€ˆH€ˆXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
ı
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆb8AddN_5-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbPfunctional_1/conv2d_20/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbmgradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
´
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbogradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbngradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbqgradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbqgradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bpgradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€blgradient_tape/functional_1/max_pooling2d/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
æ
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€€@€€H€€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€€@€€H€€bpgradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€€@€€H€€bpgradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€€@€€H€€bpgradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ø@øHøbqgradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
è
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6::Params)*28€ø@€øH€øXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
Å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ø@€øH€øXbfunctional_1/conv2d_19/Conv2Dh
Å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ø@€øH€øXbfunctional_1/conv2d_20/Conv2Dh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ğ@€¸H€¸Xbfunctional_1/conv2d_14/Conv2Dh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ğ@€¸H€¸Xbfunctional_1/conv2d_4/Conv2Dh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ğ@€¸H€¸Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ğ@€¸H€¸Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28è@€°H¸Xbfunctional_1/conv2d_5/Conv2Dh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€è@€°H€¸Xbfunctional_1/conv2d_15/Conv2Dh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€è@€°H€¸Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€è@€°H€¸Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
¸
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28à@€°H°Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¨
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28à@€H€ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
š
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€Ø@€pH€ÀXbfunctional_1/conv2d/Conv2Dh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€Ğ@€¨H€¨Xbfunctional_1/conv2d_8/Conv2Dh
ô
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€È@€HH€xXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
¸
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€È@€ H€¨Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€¸@€˜H€ Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
ê
Œvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x128_32x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x128_32x3::Params)*28€¸@€¸H€¸Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
ë
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€¨@€H€˜Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ç
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€¨@€`H€ÈXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ bAgradient_tape/functional_1/leaky_re_lu_16/LeakyRelu/LeakyReluGradh
Ò
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b@gradient_tape/functional_1/leaky_re_lu_3/LeakyRelu/LeakyReluGradh
Ú
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€H€Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
·
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€ @€€H€Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
à
Švoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28˜@˜H˜b9functional_1/up_sampling2d_2/resize/ResizeNearestNeighborh
Q
ampere_sgemm_128x128_nn*28€˜@€ˆH€Xbfunctional_1/conv2d_6/Conv2Dh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€˜@€˜H€˜bAgradient_tape/functional_1/leaky_re_lu_17/LeakyRelu/LeakyReluGradh
Ò
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€˜@€˜H€˜b@gradient_tape/functional_1/leaky_re_lu_2/LeakyRelu/LeakyReluGradh
Ü
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€˜@€ˆH€Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€ˆH€Xbfunctional_1/conv2d_5/Conv2Dh
¥
Ævoid gemv2T_kernel_val<int, int, float2, float2, float2, 128, 16, 2, 2, false, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>, float2, float2)*28€˜@€°H€¸Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28@€°HàXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
ş
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€@€ˆH€ˆXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ˆ@€H€ˆXbfunctional_1/conv2d_15/Conv2Dh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ˆ@€ˆH€ˆbAgradient_tape/functional_1/leaky_re_lu_18/LeakyRelu/LeakyReluGradh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€€H€ˆXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€ˆ@€ˆH€ˆb8gradient_tape/functional_1/conv2d_20/BiasAdd/BiasAddGradh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€ˆ@€ˆH€ˆb8gradient_tape/functional_1/conv2d_21/BiasAdd/BiasAddGradh
¨
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€€@€€H€€Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€€H€€Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ø@€°H€ÈXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
ç
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ø@€°H€ÈXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
ú
’void tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€ø@€øH€øbKgradient_tape/functional_1/up_sampling2d_2/resize/ResizeNearestNeighborGradh
´
øvoid explicit_convolve_sgemm<float, int, 128, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28ğ@€øHøXbfunctional_1/conv2d_23/Conv2Dh
Ï
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€ğ@€`H€˜Xbfunctional_1/conv2d/Conv2Dh
’
ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€è@€èH€èbAddN_4h
¡
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€è@€èH€èXbfunctional_1/conv2d_8/Conv2Dh
¸
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€à@€ H€ Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€Ø@€˜H€ Xbfunctional_1/conv2d_11/Conv2Dh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ø@€èH€ğXbfunctional_1/conv2d_8/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€È@€˜H€˜Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€È@€0H€ÈXbfunctional_1/conv2d_10/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28À@€H˜Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
§
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€À@€ˆH€¸Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€À@€H€@Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh	
”
¹void cudnn::pooling_bw_kernel_max_nchw_fully_packed_large<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28€¸@€¸H€¸b>gradient_tape/functional_1/max_pooling2d_1/MaxPool/MaxPoolGradh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€¸@€H€˜Xbfunctional_1/conv2d_9/Conv2Dh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€¸@€H€˜Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€¸@€H€˜Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€°@€H€Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
å
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€°@€H€Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ä
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€°@€H€Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
¶
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28¨@€PH€ˆXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
š
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€¨@€ĞH€ØXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€€H€Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
Ğ
‘void pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€˜@€˜H€˜b"functional_1/max_pooling2d/MaxPoolh
‚
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€˜@€˜H€˜Xbfunctional_1/conv2d_13/Conv2Dh
Ù
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@€xH€Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€H€øXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
¥
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€@€H€Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€€@€ H€¨Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
¤
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
§
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28ø@øHøXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
é
«void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28€ø@€¸H€Àb!functional_1/concatenate_1/concath
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ø@€°H€ÈXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
Å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ø@€øH€øXbfunctional_1/conv2d_16/Conv2Dh
¨
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€ø@€øH€øXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
§
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€ø@€øH€øXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ğ@€ğH€ğb%functional_1/leaky_re_lu_17/LeakyReluh
ü
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ğ@€ğH€ğb.gradient_tape/functional_1/concatenate_2/Sliceh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ğ@€¨H€ÈXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
Ë
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€ğ@€ğH€ğXbfunctional_1/conv2d_6/Conv2Dh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ğ@€ H€ĞXbfunctional_1/conv2d_14/Conv2Dh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ğ@€ H€ĞXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28è@èHèb%functional_1/leaky_re_lu_16/LeakyReluh
¶
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28è@èHèb$functional_1/leaky_re_lu_2/LeakyReluh
Á
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€è@€°H€¸Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€è@€èH€èb%functional_1/leaky_re_lu_18/LeakyReluh
¶
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€è@€èH€èb$functional_1/leaky_re_lu_3/LeakyReluh
ş
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€è@€èH€èb0gradient_tape/functional_1/concatenate_2/Slice_1h
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride::Params)*28€è@€èH€èXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
Ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€è@€ H€ÈXbfunctional_1/conv2d_3/Conv2Dh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€è@€H€ĞXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€è@€H€ĞXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
Ò
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28à@€0H€€Xbfunctional_1/conv2d_23/Conv2Dh
‚
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€à@€°H€°Xbfunctional_1/conv2d_8/Conv2Dh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€à@€H€ÈXbfunctional_1/conv2d_18/Conv2Dh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€à@€°H€°Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€à@€àH€àbfunctional_1/conv2d_16/BiasAddh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ø@€¨H°Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ø@€¨H°Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
ƒ
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€Ø@€¨H€°Xbfunctional_1/conv2d_10/Conv2Dh
ƒ
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€Ø@€¨H€°Xbfunctional_1/conv2d_11/Conv2Dh
ç
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€Ø@€¨H€°Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
Å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€Ø@€¨H€°Xbfunctional_1/conv2d_13/Conv2Dh
Ø
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€Ğ@€ĞH€Ğb7gradient_tape/functional_1/conv2d_1/BiasAdd/BiasAddGradh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€Ğ@€¨H€¨Xbfunctional_1/conv2d_4/Conv2Dh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€Ğ@€¨H€¨Xbfunctional_1/conv2d_7/Conv2Dh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€Ğ@€¨H€¨Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
’
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€Ğ@€ĞH€Ğbfunctional_1/conv2d_3/BiasAddh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€Ğ@€ĞH€ĞbPfunctional_1/conv2d_17/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€Ğ@€ĞH€ĞbPfunctional_1/conv2d_18/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
”
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€Ğ@€ĞH€ĞbOfunctional_1/conv2d_2/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€Ğ@€ĞH€Ğbngradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
´
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€Ğ@€ĞH€Ğbogradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€Ğ@€ĞH€Ğbngradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28È@ÈHÈbfunctional_1/conv2d_17/BiasAddh
ı
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28È@ÈHÈb8AddN_4-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€È@€ÈH€Èb5gradient_tape/functional_1/conv2d/BiasAdd/BiasAddGradh
Ù
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€È@€ÈH€Èb8gradient_tape/functional_1/conv2d_19/BiasAdd/BiasAddGradh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€È@€ H€¨Xbfunctional_1/conv2d_12/Conv2Dh
Å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€È@€ÈH€ÈXbfunctional_1/conv2d_17/Conv2Dh
Å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€È@€ÈH€ÈXbfunctional_1/conv2d_18/Conv2Dh
Ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€È@€ÈH€ÈXbfunctional_1/conv2d_2/Conv2Dh
Ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€È@€ÈH€ÈXbfunctional_1/conv2d_3/Conv2Dh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€È@€ÈH€ÈXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
æ
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€È@€ÈH€ÈXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€È@€ÈH€Èbfunctional_1/conv2d_18/BiasAddh
’
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€È@€ÈH€Èbfunctional_1/conv2d_2/BiasAddh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€ÈbPfunctional_1/conv2d_16/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
”
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€ÈbOfunctional_1/conv2d_3/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
§
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€Èbbgradient_tape/functional_1/concatenate_2/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€Èbpgradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€Èbqgradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€Èbpgradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€Èbpgradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€Èbpgradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€Èbpgradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€È@€ÈH€Èbngradient_tape/functional_1/max_pooling2d_1/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
Ù
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€À@€ÀH€Àb8gradient_tape/functional_1/conv2d_20/BiasAdd/BiasAddGradh
Ù
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€À@€ÀH€Àb8gradient_tape/functional_1/conv2d_21/BiasAdd/BiasAddGradh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€À@€ H€ Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
¿
ávoid gemmk1_kernel<float2, 256, 5, true, false, false, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28€À@€ H€ Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€À@€ÀH€Àbpgradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28¸@˜H€ Xbfunctional_1/conv2d_6/Conv2Dh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€¸@€HH€XXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€¸@€˜H€ Xbfunctional_1/conv2d_7/Conv2Dh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€¸@€˜H€ Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸@€˜H€ Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸@€˜H€ Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸@€˜H€ Xbfunctional_1/conv2d_16/Conv2Dh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€¸@€¸H€¸bqgradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28°@€˜H˜Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€°@€˜H€˜Xbfunctional_1/conv2d_12/Conv2Dh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€°@€˜H€˜Xbfunctional_1/conv2d_22/Conv2Dh
Ú
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€°@€H€ Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€˜H€˜Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€˜H€˜Xbfunctional_1/conv2d_17/Conv2Dh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€˜H€˜Xbfunctional_1/conv2d_4/Conv2Dh
½
ávoid gemmk1_kernel<float2, 256, 5, false, false, true, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28€°@€ H€(Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€°@€°H€°bpgradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
¸
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€¨@€H€˜Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
·
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€¨@€H€˜Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
¥
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€¨@€¨H€¨Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ bAgradient_tape/functional_1/leaky_re_lu_13/LeakyRelu/LeakyReluGradh
³
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€ @€ H€ b<gradient_tape/functional_1/max_pooling2d/MaxPool/MaxPoolGradh
¸
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€ @€H€Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Ã
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€ @€H€Xbfunctional_1/conv2d_9/Conv2Dh
å
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€ @€H€Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
à
Švoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€ @€ H€ b9functional_1/up_sampling2d_1/resize/ResizeNearestNeighborh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28˜@˜H˜bAgradient_tape/functional_1/leaky_re_lu_14/LeakyRelu/LeakyReluGradh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28˜@hH€°Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
½
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€˜@€(H€8Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
Ò
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€˜@€˜H€˜b@gradient_tape/functional_1/leaky_re_lu_4/LeakyRelu/LeakyReluGradh
Ò
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€˜@€˜H€˜b@gradient_tape/functional_1/leaky_re_lu_5/LeakyRelu/LeakyReluGradh
Ã
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28@€ˆHˆXbfunctional_1/conv2d_8/Conv2Dh
˜
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€@€XH€`Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
Ù
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@€PH€`Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
ç
­void gemv2N_kernel<int, int, float2, float2, float2, 128, 1, 4, 4, 1, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>)*28€@€ H€(Xbfunctional_1/conv2d_23/Conv2Dh
ç
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€`H€°Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ú
’void tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€@€H€bKgradient_tape/functional_1/up_sampling2d_1/resize/ResizeNearestNeighborGradh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€ˆ@€€H€ˆXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ˆ@€ˆH€ˆbAgradient_tape/functional_1/leaky_re_lu_15/LeakyRelu/LeakyReluGradh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€ˆ@€PH€`Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
Ì
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ˆ@€ H€@Xbfunctional_1/conv2d_23/Conv2Dh
ó
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€@€0HPXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
·
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€€@€HH€`Xbfunctional_1/conv2d_9/Conv2Dh
½
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€€@€PH€XXbfunctional_1/conv2d_11/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€€@€PH€XXbfunctional_1/conv2d_8/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€PH€XXbfunctional_1/conv2d_9/Conv2Dh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€PH€XXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€€@€€H€€b8gradient_tape/functional_1/conv2d_16/BiasAdd/BiasAddGradh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€€@€€H€€b8gradient_tape/functional_1/conv2d_17/BiasAdd/BiasAddGradh
’
ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€ø@€øH€øbAddN_3h
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€ø@€xH€€Xbfunctional_1/conv2d_23/Conv2Dh
Ù
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ø@€HH€XXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€ø@€PH€XXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ø@€PH€XXbfunctional_1/conv2d_8/Conv2Dh
ï
“void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)*28€ø@€H€ Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€ø@€øH€øb8gradient_tape/functional_1/conv2d_18/BiasAdd/BiasAddGradh
¯
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€ø@€øH€øb7gradient_tape/functional_1/conv2d_2/BiasAdd/BiasAddGradh
¯
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€ø@€øH€øb7gradient_tape/functional_1/conv2d_3/BiasAdd/BiasAddGradh
î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ø@€ H€@Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Ú
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€ğ@€PH€PXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€ğ@€PH€PXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€ğ@€PH€PXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
Ú
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28è@€HHPXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28€è@€èH€èXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€è@€HH€PXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
‚
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€è@€èH€èXbfunctional_1/conv2d_10/Conv2Dh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28à@€HH€PXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
Ø
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€à@€HH€PXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€à@€HH€PXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€à@€0H€°Xbfunctional_1/conv2d_11/Conv2Dh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€à@€ H€ÀXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ò
‘void pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€à@€àH€àb$functional_1/max_pooling2d_1/MaxPoolh
÷
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€à@€àH€àb%Adam/Adam/update_18/ResourceApplyAdamh
¥
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€à@€àH€àXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
Ø
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ø@€8HPXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
õ
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€Ø@€hH€pXbfunctional_1/conv2d_23/Conv2Dh
•
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€Ø@€hH€pXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
à
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ø@€HH€HXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ø@€HH€HXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ğ@€ H°Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
å
«void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28€Ğ@€hH€hbfunctional_1/concatenate/concath
Í
“void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)*28€Ğ@€H€ Xbfunctional_1/conv2d_23/Conv2Dh
¤
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€Ğ@€hH€hXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
¤
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€Ğ@€hH€hXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€Ğ@€hH€hXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€Ğ@€ H€°Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€Ğ@€ H€°Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€Ğ@€hH€hXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
¤
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€Ğ@€ĞH€ĞXb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
ş
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€È@€ÈH€Èb0gradient_tape/functional_1/concatenate_1/Slice_1h

´void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€È@€ÈH€Èb>gradient_tape/functional_1/max_pooling2d_2/MaxPool/MaxPoolGradh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€È@€`H€hXbfunctional_1/conv2d_9/Conv2Dh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€È@€`H€hXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
Ø
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€È@€`H€hXbfunctional_1/conv2d_18/Conv2Dh
×
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€È@€`H€hXbfunctional_1/conv2d_3/Conv2Dh

Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€È@€`H€hXbfunctional_1/conv2d_12/Conv2Dh
¤
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€È@€`H€hXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
Ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€È@€H€°Xbfunctional_1/conv2d_2/Conv2Dh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€È@€`H€hXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€À@€ÀH€Àb%functional_1/leaky_re_lu_13/LeakyReluh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€À@€ÀH€Àb%functional_1/leaky_re_lu_14/LeakyReluh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€À@€ÀH€Àb%functional_1/leaky_re_lu_15/LeakyReluh
¶
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€À@€ÀH€Àb$functional_1/leaky_re_lu_4/LeakyReluh
¶
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€À@€ÀH€Àb$functional_1/leaky_re_lu_5/LeakyReluh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€À@€`H€`Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
€
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€À@€`H€`Xbfunctional_1/conv2d_7/Conv2Dh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€À@€`H€`Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
ü
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€¸@€¸H€¸b.gradient_tape/functional_1/concatenate_1/Sliceh
·
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¸@€XH€`Xbfunctional_1/conv2d_6/Conv2Dh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€¸@€¸H€¸bfunctional_1/conv2d_13/BiasAddh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€°@€XH€XXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
µ
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€°@€XH€XXbfunctional_1/conv2d/Conv2Dh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€°@€°H€°bPfunctional_1/conv2d_13/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€°@€°H€°bPfunctional_1/conv2d_14/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€°@€°H€°bPfunctional_1/conv2d_15/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
”
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€°@€°H€°bOfunctional_1/conv2d_4/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
”
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€°@€°H€°bOfunctional_1/conv2d_5/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€°@€°H€°bpgradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€°@€°H€°bngradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28¨@¨H¨bqgradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
Ù
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€¨@€¨H€¨b8gradient_tape/functional_1/conv2d_17/BiasAdd/BiasAddGradh
ã
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€¨@€PH€XXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
æ
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€¨@€¨H€¨Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€¨@€¨H€¨bfunctional_1/conv2d_14/BiasAddh
’
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€¨@€¨H€¨bfunctional_1/conv2d_4/BiasAddh
’
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€¨@€¨H€¨bfunctional_1/conv2d_5/BiasAddh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€¨@€¨H€¨bpgradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€¨@€¨H€¨bpgradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€¨@€¨H€¨bpgradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€¨@€¨H€¨bpgradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€¨@€¨H€¨bpgradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
´
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€¨@€¨H€¨bogradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€¨@€¨H€¨bngradient_tape/functional_1/max_pooling2d_2/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
š
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ @€ H€0Xbfunctional_1/conv2d_23/Conv2Dh
Ù
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€ @€ H€ b8gradient_tape/functional_1/conv2d_18/BiasAdd/BiasAddGradh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€ @€ H€8Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€ @€ H€8Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
ß
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€ @€PH€PXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ @€@H€`Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€ @€ H€ bfunctional_1/conv2d_15/BiasAddh
“
,void tensorflow::SetZero<float>(int, float*)*28€ @€ H€ bKgradient_tape/functional_1/up_sampling2d_3/resize/ResizeNearestNeighborGradh
ı
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ b8AddN_3-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
§
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bbgradient_tape/functional_1/concatenate_1/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
´
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bogradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28˜@HH€PXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
Ø
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28˜@€HHPXbfunctional_1/conv2d_20/Conv2Dh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€˜@€HH€PXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
·
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€˜@€0H€8Xbfunctional_1/conv2d_8/Conv2Dh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€˜@€HH€PXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€HH€PXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ø
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€HH€PXbfunctional_1/conv2d_19/Conv2Dh
ø
’void tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€˜@€˜H€˜bIgradient_tape/functional_1/up_sampling2d/resize/ResizeNearestNeighborGradh
Ş
Švoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€˜@€˜H€˜b7functional_1/up_sampling2d/resize/ResizeNearestNeighborh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€˜@€˜H€˜bqgradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
š
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b"functional_1/dropout/dropout/Mul_1h
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€@€HH€HXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€@€ H€(Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€@€HH€HXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Ù
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@€(H€8Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€@€HH€HXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€@€HH€HXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€@€HH€HXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€@€HH€HXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€@€HH€HXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€@€HH€HXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€@€HH€HXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€@€HH€HXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€@€HH€HXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
×
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€@€HH€HXbfunctional_1/conv2d_2/Conv2Dh
Ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€(H€hXbfunctional_1/conv2d_12/Conv2Dh
Â
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€@H€PXbfunctional_1/conv2d_9/Conv2Dh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€@H€PXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
¼
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ˆ@€H€(Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ˆ@€ˆH€ˆbAgradient_tape/functional_1/leaky_re_lu_12/LeakyRelu/LeakyReluGradh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ˆ@€ˆH€ˆbAgradient_tape/functional_1/leaky_re_lu_22/LeakyRelu/LeakyReluGradh
Ò
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ˆ@€ˆH€ˆb@gradient_tape/functional_1/leaky_re_lu_7/LeakyRelu/LeakyReluGradh
Ø
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ˆ@€(H€0Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€@H€HXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
Â
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ˆ@€(H€`Xbfunctional_1/conv2d_7/Conv2Dh
Ã
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ˆ@€@H€HXbfunctional_1/conv2d_10/Conv2Dh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€ˆ@€ˆH€ˆb8gradient_tape/functional_1/conv2d_14/BiasAdd/BiasAddGradh
¯
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€ˆ@€ˆH€ˆb7gradient_tape/functional_1/conv2d_5/BiasAdd/BiasAddGradh
·
ªvoid tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh

´void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€@€H€b>gradient_tape/functional_1/max_pooling2d_3/MaxPool/MaxPoolGradh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€@€@H@Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
¼
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€€@€@H€@Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€€@€€H€€bAgradient_tape/functional_1/leaky_re_lu_10/LeakyRelu/LeakyReluGradh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€€@€€H€€bAgradient_tape/functional_1/leaky_re_lu_11/LeakyRelu/LeakyReluGradh
Ò
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€€@€€H€€b@gradient_tape/functional_1/leaky_re_lu_6/LeakyRelu/LeakyReluGradh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€(H€0Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€@H€@Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€@H€@Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Õ
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€@H€@Xbfunctional_1/conv2d/Conv2Dh
×
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€@H€@Xbfunctional_1/conv2d_1/Conv2Dh
Ø
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€@H€@Xbfunctional_1/conv2d_21/Conv2Dh
Ø
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€@H€@Xbfunctional_1/conv2d_22/Conv2Dh
€
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€€@€@H€@Xbfunctional_1/conv2d_6/Conv2Dh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€€@€@H€@Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€€@€@H€@Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€€@€€H€€b8gradient_tape/functional_1/conv2d_13/BiasAdd/BiasAddGradh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€€@€€H€€b8gradient_tape/functional_1/conv2d_15/BiasAdd/BiasAddGradh
¯
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€€@€€H€€b7gradient_tape/functional_1/conv2d_4/BiasAdd/BiasAddGradh
÷
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€€@€€H€€b%Adam/Adam/update_16/ResourceApplyAdamh
·
ªvoid tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€€@€€H€€bpgradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¸
ªvoid tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 2, 1024, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€€@€€H€€bqgradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh

ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€x@€xH€xbAddN_2h
€
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€x@€8H€@Xbfunctional_1/conv2d_13/Conv2Dh
€
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€x@€8H€@Xbfunctional_1/conv2d_14/Conv2Dh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€x@€8H€@Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€x@€xH€xb%Adam/Adam/update_22/ResourceApplyAdamh
”
ªvoid tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 2, 1024, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€x@€xH€xbPfunctional_1/conv2d_22/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
÷
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€p@€pH€pb,gradient_tape/functional_1/concatenate/Sliceh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€p@€8H€8Xbfunctional_1/conv2d_11/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€p@€ H€(Xbfunctional_1/conv2d_12/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€p@€8H€8Xbfunctional_1/conv2d_8/Conv2Dh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€p@€ H€(Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€p@€8H€8Xbfunctional_1/conv2d_12/Conv2Dh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€p@€8H€8Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€p@€8H€8Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¢
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€p@€pH€pXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
¥
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€p@€pH€pXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28h@€0H8Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
»
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€h@€0H€8Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
ù
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€h@€hH€hb.gradient_tape/functional_1/concatenate/Slice_1h
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€h@€H€ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€h@€H€(Xbfunctional_1/conv2d_7/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€h@€(H€@Xbfunctional_1/conv2d_6/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€h@€0H€8Xbfunctional_1/conv2d_8/Conv2Dh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€h@€0H€8Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Ï
‘void pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€h@€hH€hb$functional_1/max_pooling2d_2/MaxPoolh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€h@€hH€hXbfunctional_1/conv2d_9/Conv2Dh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€h@€hH€hXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€h@€hH€hXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€`@€`H€`b%functional_1/leaky_re_lu_12/LeakyReluh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€`@€`H€`b%functional_1/leaky_re_lu_22/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€`@€`H€`b$functional_1/leaky_re_lu_6/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€`@€`H€`b$functional_1/leaky_re_lu_7/LeakyReluh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€`@€H€(Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€`@€0H€0Xbfunctional_1/conv2d_7/Conv2Dh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€`@€0H€0Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
Å
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€`@€0H€0Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€`@€(H€8Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh

,void tensorflow::SetZero<float>(int, float*)*28€`@€`H€`bKgradient_tape/functional_1/up_sampling2d_2/resize/ResizeNearestNeighborGradh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€`@€`H€`bqgradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28X@€HXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28X@XHXb%functional_1/leaky_re_lu_10/LeakyReluh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€X@€H€ Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€X@€H€Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
¼
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€X@€H€ Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
¥
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€X@€XH€Xb0gradient_tape/functional_1/dropout/dropout/Mul_1h
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€X@€XH€Xb%functional_1/leaky_re_lu_11/LeakyReluh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€X@€H€ Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€X@€H€ Xbfunctional_1/conv2d_6/Conv2Dh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€X@€H€ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€X@€XH€Xb8gradient_tape/functional_1/conv2d_12/BiasAdd/BiasAddGradh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€X@€XH€Xbpgradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€P@€H€Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
™
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€P@€(H€(Xbfunctional_1/conv2d_23/Conv2Dh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€P@€PH€Pb8gradient_tape/functional_1/conv2d_14/BiasAdd/BiasAddGradh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€P@€PH€Pb8gradient_tape/functional_1/conv2d_15/BiasAdd/BiasAddGradh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€P@€H€ Xbfunctional_1/conv2d_14/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€P@€H€ Xbfunctional_1/conv2d_18/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€P@€H€ Xbfunctional_1/conv2d_5/Conv2Dh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€P@€H€ Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€P@€H€ Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
€
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€P@€(H€(Xbfunctional_1/conv2d_15/Conv2Dh

Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€P@€(H€(Xbfunctional_1/conv2d_5/Conv2Dh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€P@€PH€Pb8gradient_tape/functional_1/conv2d_10/BiasAdd/BiasAddGradh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€P@€PH€Pb8gradient_tape/functional_1/conv2d_11/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€P@€PH€Pb7gradient_tape/functional_1/conv2d_6/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€P@€PH€Pb7gradient_tape/functional_1/conv2d_7/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€P@€PH€Pb7gradient_tape/functional_1/conv2d_8/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€P@€PH€Pb7gradient_tape/functional_1/conv2d_9/BiasAdd/BiasAddGradh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€P@€PH€Pbfunctional_1/conv2d_22/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€P@€PH€Pbfunctional_1/conv2d_7/BiasAddh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€P@€PH€Pbpgradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¦
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€H@€H€Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€H@€H€Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€H@€H€Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€H@€H€Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
“
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€H@€HH€Hbgradient_tape/huber_loss/Mul_2h
û
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€H@€HH€Hbhuber_loss/Addh
Ì
Õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€H@€HH€Hb]functional_1/dropout/dropout/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Casth
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_1/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_15/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_17/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_2/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_20/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_21/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_22/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_3/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_4/Conv2Dh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€H@€ H€(Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€H@€HH€HXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€H@€HH€Hbfunctional_1/conv2d_12/BiasAddh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€H@€HH€Hb%Adam/Adam/update_14/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€H@€HH€Hb%Adam/Adam/update_20/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€H@€HH€Hb%Adam/Adam/update_24/ResourceApplyAdamh
Á
îvoid tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)*28€H@€HH€Hb9functional_1/dropout/dropout/random_uniform/RandomUniformh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€H@€HH€HbPfunctional_1/conv2d_12/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€H@€HH€Hbogradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€H@€HH€Hbogradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¤
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€H@€HH€Hbbgradient_tape/functional_1/dropout/dropout/Mul_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28@@€HXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28@@@H@bpgradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@@€H€Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@@€H€Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@@€H€Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@@€H€Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@@€H€Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
«
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@@€H€Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@@€H€Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@@€H€Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@@€H€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
‹
ávoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@@€@H€@bhuber_loss/Sub_1h
ƒ
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@@€@H€@bl2_normalize_1h
ú
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@@€@H€@bmul_1h
Ü
¡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_sign_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_sign_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@@€@H€@b!gradient_tape/huber_loss/Abs/Signh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€@@€ H€ Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€@@€H€Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
³
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@@€H€Xbfunctional_1/conv2d/Conv2Dh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@@€H€Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€@@€ H€ Xbfunctional_1/conv2d_14/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€@@€ H€ Xbfunctional_1/conv2d_6/Conv2Dh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€@@€ H€ Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€@@€ H€ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh

Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€@@€ H€ Xbfunctional_1/conv2d_4/Conv2Dh
Â
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@@€@H€@Xbfunctional_1/conv2d_11/Conv2Dh
Â
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@@€@H€@Xbfunctional_1/conv2d_12/Conv2Dh
Á
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@@€@H€@Xbfunctional_1/conv2d_6/Conv2Dh
Á
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@@€@H€@Xbfunctional_1/conv2d_7/Conv2Dh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€@@€@H€@b8gradient_tape/functional_1/conv2d_22/BiasAdd/BiasAddGradh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€@@€@H€@bfunctional_1/conv2d_6/BiasAddh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xbfunctional_1/conv2d_11/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xbfunctional_1/conv2d_8/Conv2Dh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@@€@H€@bPfunctional_1/conv2d_10/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@@€@H€@bOfunctional_1/conv2d_7/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
¢
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@@€@H€@b`gradient_tape/functional_1/concatenate/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@@€@H€@bpgradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@@€@H€@bpgradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@@€@H€@bogradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*288@8H8bPfunctional_1/conv2d_11/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€8@€H€Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€8@€H€Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€8@€H€Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€8@€H€Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€8@€H€Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
¸
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€8@€8H€8b)functional_1/dropout/dropout/GreaterEqualh
¥
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8b0gradient_tape/functional_1/dropout_1/dropout/Mulh
 
Ùvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_tanh_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_tanh_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8b-gradient_tape/functional_1/conv2d_23/TanhGradh
Ç
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€8@€8H€8b functional_1/dropout/dropout/Mulh
·
‡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€8@€8H€8bl2_normalize_1/Maximumh

ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8bAddN_1h
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8b@gradient_tape/functional_1/leaky_re_lu_8/LeakyRelu/LeakyReluGradh
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8b@gradient_tape/functional_1/leaky_re_lu_9/LeakyRelu/LeakyReluGradh
Ê
ƒvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 3ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 3ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€8@€8H€8b-gradient_tape/huber_loss/weighted_loss/Tile_1h
æ

«
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<bool const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<bool const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8b!gradient_tape/huber_loss/SelectV2h
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_15/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_18/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_20/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_3/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_5/Conv2Dh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
 
hvoid fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)*28€8@€H€ Xbfunctional_1/conv2d_23/Conv2Dh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€8@€8H€8b8gradient_tape/functional_1/conv2d_23/BiasAdd/BiasAddGradh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€8@€8H€8bfunctional_1/conv2d_10/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€8@€8H€8bfunctional_1/conv2d_11/BiasAddh

,void tensorflow::SetZero<float>(int, float*)*28€8@€8H€8bKgradient_tape/functional_1/up_sampling2d_1/resize/ResizeNearestNeighborGradh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€8@€8H€8b%Adam/Adam/update_12/ResourceApplyAdamh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€8@€8H€8Xbfunctional_1/conv2d_7/Conv2Dh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€8@€8H€8bOfunctional_1/conv2d_6/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€8@€8H€8bpgradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
°
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€8@€8H€8bngradient_tape/functional_1/max_pooling2d_3/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*280@€HXbfunctional_1/conv2d_22/Conv2Dh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€0@€H€Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€0@€H€Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€0@€H€Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
ş
ávoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€0@€0H€0bsubh
™
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€0@€0H€0b$functional_1/dropout_1/dropout/Mul_1h
¹
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€0@€0H€0bhuber_loss/Mul_1h
Ã
•void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€0@€0H€0bl2_normalize_1/Rsqrth
¹
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d_1/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d_17/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d_2/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d_21/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d_4/Conv2Dh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€0@€0H€0Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€0@€H€Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€0@€0H€0Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Ï
‘void pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€0@€0H€0b$functional_1/max_pooling2d_3/MaxPoolh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€0@€0H€0b%Adam/Adam/update_28/ResourceApplyAdamh
Ã
îvoid tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)*28€0@€0H€0b;functional_1/dropout_1/dropout/random_uniform/RandomUniformh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xbfunctional_1/conv2d_12/Conv2Dh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
ß
«void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned char, 256, 32, 32, false>(unsigned char const*, tensorflow::functor::Dimension<3>, unsigned char*)*28€0@€0H€0b™gradient_tape/functional_1/dropout/dropout/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_bool_Mul-1-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
•
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€(@€(H€(b gradient_tape/huber_loss/Abs/mulh

Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€(@€(H€(bl2_normalizeh
Õ
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€(@€(H€(b.gradient_tape/functional_1/dropout/dropout/Mulh
Ë
‘void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_quotient_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_quotient_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€(@€(H€(b gradient_tape/huber_loss/truedivh
Ä
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€(@€(H€(bl2_normalize/Squareh

Õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€(@€(H€(b!functional_1/dropout/dropout/Casth
İ	
¿	void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€(@€(H€(bAddNh
“
ôvoid cub::DeviceReduceKernel<cub::DeviceReducePolicy<float, int, tensorflow::functor::Sum<float> >::Policy600, float*, float*, int, tensorflow::functor::Sum<float> >(float*, float*, int, cub::GridEvenShare<int>, tensorflow::functor::Sum<float>)*28€(@€(H€(bSum_2h
Å
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€(@€(H€(Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
ë
«void tensorflow::(anonymous namespace)::DynamicStitchKernel<int>(int, int, tensorflow::GpuDeviceArrayStruct<int, 8>, tensorflow::GpuDeviceArrayStruct<int const*, 8>, int*)*28€(@€(H€(b&gradient_tape/huber_loss/DynamicStitchh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€(@€(H€(bfunctional_1/conv2d_23/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€(@€(H€(bfunctional_1/conv2d_8/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€(@€(H€(bfunctional_1/conv2d_9/BiasAddh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€(@€(H€(b%Adam/Adam/update_10/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€(@€(H€(b%Adam/Adam/update_26/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€(@€(H€(b%Adam/Adam/update_30/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€(@€(H€(b%Adam/Adam/update_32/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€(@€(H€(b%Adam/Adam/update_38/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€(@€(H€(b$Adam/Adam/update_4/ResourceApplyAdamh
õ
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€(@€(H€(b8gradient_tape/functional_1/conv2d_11/BiasAdd/BiasAddGradh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xbfunctional_1/conv2d_10/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xbfunctional_1/conv2d_14/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xbfunctional_1/conv2d_6/Conv2Dh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bOfunctional_1/conv2d_8/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bOfunctional_1/conv2d_9/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bogradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
›
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€ @€ H€ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
º
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ b+functional_1/dropout_1/dropout/GreaterEqualh
«
ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::less_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::less_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ b"gradient_tape/huber_loss/LessEqualh
É
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ b"functional_1/dropout_1/dropout/Mulh
Ù
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ b2gradient_tape/functional_1/dropout_1/dropout/Mul_1h
Ñ
›void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_opposite_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_opposite_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ bgradient_tape/huber_loss/Negh
Å
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ bgradient_tape/huber_loss/Mulh
Á
•void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ bl2_normalize/Rsqrth
Æ
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ bl2_normalize_1/Squareh
È
“void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ bfunctional_1/conv2d_23/Tanhh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b$functional_1/leaky_re_lu_8/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b$functional_1/leaky_re_lu_9/LeakyReluh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€ @€ H€ b8gradient_tape/functional_1/conv2d_22/BiasAdd/BiasAddGradh
Å
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
Å
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Ä
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
Ä
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
ã
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh

,void tensorflow::SetZero<float>(int, float*)*28€ @€ H€ bIgradient_tape/functional_1/up_sampling2d/resize/ResizeNearestNeighborGradh
ñ
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b"Adam/Adam/update/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_11/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_15/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_19/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b$Adam/Adam/update_2/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_25/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_29/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_31/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_34/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_35/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_36/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_37/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_40/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_41/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_42/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_44/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_45/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_46/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_47/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b$Adam/Adam/update_6/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b$Adam/Adam/update_7/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b$Adam/Adam/update_8/ResourceApplyAdamh
õ
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€ @€ H€ b8gradient_tape/functional_1/conv2d_12/BiasAdd/BiasAddGradh
ô
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€ @€ H€ b7gradient_tape/functional_1/conv2d_9/BiasAdd/BiasAddGradh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_13/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_15/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_17/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_18/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_2/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_20/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_3/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_5/Conv2Dh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bogradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bogradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
Ø
üvoid xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
×
üvoid xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
×
üvoid xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28@Hb%Adam/Adam/update_23/ResourceApplyAdamh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
›
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
›
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
›
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@€H€Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@€H€Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@€H€Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@€H€Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
å
Ávoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_boolean_and_op, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_boolean_and_op, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b
LogicalAndh
ë
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bdiv_no_nan_1h
ı
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bhuber_loss/weighted_loss/valueh
÷
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b
Adam/Pow_1h
ø
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bMulh
Ğ
“void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b#gradient_tape/huber_loss/zeros_likeh
®
‘void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_abs_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_abs_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bAbsh
µ
‡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bl2_normalize/Maximumh
³
‡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_min_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_min_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bhuber_loss/Minimumh
è
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b7huber_loss/ArithmeticOptimizer/ReplaceMulWithSquare_Mulh
’
Õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b#functional_1/dropout_1/dropout/Casth
ó
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bCast_2h
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_2h
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_3h
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_4h

ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long, long long>, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long, long long>, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAdam/addh
Â
‹void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAdam/Adam/AssignAddVariableOph
“
ôvoid cub::DeviceReduceKernel<cub::DeviceReducePolicy<float, int, tensorflow::functor::Sum<float> >::Policy600, float*, float*, int, tensorflow::functor::Sum<float> >(float*, float*, int, cub::GridEvenShare<int>, tensorflow::functor::Sum<float>)*28€@€H€bSum_4h
ª
ôvoid cub::DeviceReduceKernel<cub::DeviceReducePolicy<float, int, tensorflow::functor::Sum<float> >::Policy600, float*, float*, int, tensorflow::functor::Sum<float> >(float*, float*, int, cub::GridEvenShare<int>, tensorflow::functor::Sum<float>)*28€@€H€bhuber_loss/weighted_loss/Sumh
¨
òvoid cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, int, tensorflow::functor::Sum<float> >::Policy600, float*, float*, int, tensorflow::functor::Sum<float>, float>(float*, float*, int, tensorflow::functor::Sum<float>, float)*28€@€H€bhuber_loss/weighted_loss/Sumh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€@€H€b8gradient_tape/functional_1/conv2d_23/BiasAdd/BiasAddGradh
‹
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*28€@€H€Xbfunctional_1/conv2d_14/Conv2Dh
Š
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*28€@€H€Xbfunctional_1/conv2d_8/Conv2Dh
ã
ˆvoid nchwToNhwcKernel<float, float, float, true, true, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
ã
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b$Adam/Adam/update_1/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_13/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_17/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_21/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_27/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b$Adam/Adam/update_3/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_33/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_39/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_43/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b$Adam/Adam/update_5/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b$Adam/Adam/update_9/ResourceApplyAdamh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_12/BiasAdd/BiasAddGradh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_14/BiasAdd/BiasAddGradh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_15/BiasAdd/BiasAddGradh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_18/BiasAdd/BiasAddGradh
÷
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b7gradient_tape/functional_1/conv2d_8/BiasAdd/BiasAddGradh
÷
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b7gradient_tape/functional_1/conv2d_9/BiasAdd/BiasAddGradh
ƒ
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b7gradient_tape/functional_1/conv2d_1/BiasAdd/BiasAddGradh
„
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_20/BiasAdd/BiasAddGradh
„
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_21/BiasAdd/BiasAddGradh
„
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_22/BiasAdd/BiasAddGradh
„
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_23/BiasAdd/BiasAddGradh
ô
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b7gradient_tape/functional_1/conv2d_8/BiasAdd/BiasAddGradh
»
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_1/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_16/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_19/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_21/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_22/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_23/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_4/Conv2Dh
Ş
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Ø
üvoid xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28€@€H€Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
Ø
üvoid xmma_new::gemm::split_k_kernel<xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4> >(xmma_new::implicit_gemm::wgrad_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_a_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Col, 128, 16> >, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_b_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, false, xmma_new::implicit_gemm::wgrad_indexed::Gmem_tile_base_b<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false, 16, xmma_new::Row, 128, 16> >, false, 4>::Params)*28€@€H€Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@€H€Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@€H€Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@€H€Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@€H€Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
é
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b
div_no_nanh
ë
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bdiv_no_nan_2h
–
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b7gradient_tape/huber_loss/weighted_loss/value/div_no_nanh
õ
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAdam/Powh
ñ
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bCasth
ó
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bCast_1h
Š
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bgradient_tape/huber_loss/Casth
—
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b*huber_loss/weighted_loss/num_elements/Casth
‚
ßvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b	Adam/Casth

ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOph
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_1h
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_5h
º
‹void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_6h
‘
òvoid cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, int, tensorflow::functor::Sum<float> >::Policy600, float*, float*, int, tensorflow::functor::Sum<float>, float>(float*, float*, int, tensorflow::functor::Sum<float>, float)*28€@€H€bSum_2h
‘
òvoid cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, int, tensorflow::functor::Sum<float> >::Policy600, float*, float*, int, tensorflow::functor::Sum<float>, float>(float*, float*, int, tensorflow::functor::Sum<float>, float)*28€@€H€bSum_4h
‹
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*28€@€H€Xbfunctional_1/conv2d_13/Conv2Dh
Š
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*28€@€H€Xbfunctional_1/conv2d_9/Conv2Dh
×
ûvoid nchwAddPaddingKernel<float, float, float, true, (cudnnKernelDataType_t)0>(int, int, int, int, int, int, int, int, float const*, float*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€@€H€Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_11/BiasAdd/BiasAddGradh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_17/BiasAdd/BiasAddGradh

²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b5gradient_tape/functional_1/conv2d/BiasAdd/BiasAddGradh
„
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_19/BiasAdd/BiasAddGradh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh