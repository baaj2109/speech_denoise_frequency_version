
Ç
çvoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28şŸ×@€øbHÿÇdXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
Æ
çvoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ÿ§µ@€°3Hÿ×3Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
Ç
çvoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ÿ×³@€˜3H€°3Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
Æ
çvoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28şÇ¥@ÿß0Hÿ1Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
Ç
çvoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28€È¤@€Ğ0H€ğ0Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
Ä
çvoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ş‡¡@€ˆ0Hÿ§0Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
Ç
çvoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28€@€°/H€Ø/Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
J
redzone_checker*28ÿ‡»@€ĞH€ÈXbfunctional_1/conv2d_5/Conv2Dh2
J
redzone_checker*28€Øº@€ĞH€ğXbfunctional_1/conv2d_2/Conv2Dh2
J
redzone_checker*28€¸º@€ĞH€ğXbfunctional_1/conv2d_3/Conv2Dh2
J
redzone_checker*28ÿ×¹@€ĞH€ğXbfunctional_1/conv2d_8/Conv2Dh2
J
redzone_checker*28€Ğ¹@€ĞH€ğXbfunctional_1/conv2d_7/Conv2Dh2
J
redzone_checker*28ÿÏ¹@€ĞH€èXbfunctional_1/conv2d_4/Conv2Dh2
J
redzone_checker*28€È¹@€ĞH€èXbfunctional_1/conv2d_6/Conv2Dh2
K
redzone_checker*28ÿÇ¹@€ĞH€ğXbfunctional_1/conv2d_18/Conv2Dh2
K
redzone_checker*28€À¹@€ĞH€ğXbfunctional_1/conv2d_12/Conv2Dh2
K
redzone_checker*28€À¹@€ĞH€ğXbfunctional_1/conv2d_20/Conv2Dh2
K
redzone_checker*28ÿ·¹@€ĞH€ğXbfunctional_1/conv2d_17/Conv2Dh2
J
redzone_checker*28ÿ·¹@€ĞH€èXbfunctional_1/conv2d_9/Conv2Dh2
K
redzone_checker*28ş¯¹@ÿÏH€ğXbfunctional_1/conv2d_14/Conv2Dh2
K
redzone_checker*28ÿ§¹@ÿÏH€ğXbfunctional_1/conv2d_11/Conv2Dh2
K
redzone_checker*28şß¸@€ĞH€èXbfunctional_1/conv2d_15/Conv2Dh2
J
redzone_checker*28€¥@€ĞH€øXbfunctional_1/conv2d_1/Conv2Dh,
l
redzone_checker*28€À¤@€ĞH€ğXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh,
l
redzone_checker*28€ ¤@€ĞH€ğXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh,
H
redzone_checker*28€¤@€ĞH€øXbfunctional_1/conv2d/Conv2Dh,
m
redzone_checker*28ÿ‡¤@€ĞH€ğXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh,
l
redzone_checker*28€€¤@€ĞH€ğXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh,
K
redzone_checker*28€à£@€ĞH€ğXbfunctional_1/conv2d_21/Conv2Dh,
l
redzone_checker*28€Ø£@€ĞH€ğXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh,
m
redzone_checker*28€ £@€ĞH€èXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh,
m
redzone_checker*28€˜£@€ĞH€èXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh,
K
redzone_checker*28€ğ¢@€ĞH€èXbfunctional_1/conv2d_22/Conv2Dh,
m
redzone_checker*28€ğ¢@€ĞH€èXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh,
l
redzone_checker*28ÿ·@ÿ×H€øXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh*
m
redzone_checker*28ÿÏœ@€ĞH€ğXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh*
m
redzone_checker*28€¸œ@€ĞH€ğXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh*
l
redzone_checker*28ÿ·œ@ÿ×H€ğXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh*
m
redzone_checker*28€°œ@€ĞH€ğXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh*
l
redzone_checker*28€ˆœ@€ØH€èXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh*
Æ
çvoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ÿç—@€˜H€ÀXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28ÿÇ•@€ØH€ğXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh(
m
redzone_checker*28€˜•@€ĞH€ğXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh(
l
redzone_checker*28€€•@€ØH€ğXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh(
l
redzone_checker*28ÿ×”@ÿ×H€ğXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh(
m
redzone_checker*28€ø…@€ØH€ğXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh$
m
redzone_checker*28ÿÏ…@€ĞH€èXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh$
n
redzone_checker*28ÿŸ…@€ĞH€èXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh$
n
redzone_checker*28ÿç„@€ĞH€èXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh$
Ü
 void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28€˜ƒ@€èH€ğXbfunctional_1/conv2d_1/Conv2Dh
İ
 void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28€˜ƒ@€èH€ğXbfunctional_1/conv2d_21/Conv2Dh
J
redzone_checker*28€À@€ØH€øXbfunctional_1/conv2d_16/Conv2Dh"
J
redzone_checker*28€Ğ~@€ĞH€ğXbfunctional_1/conv2d_19/Conv2Dh"
J
redzone_checker*28€ˆ~@€ĞH€èXbfunctional_1/conv2d_10/Conv2Dh"
J
redzone_checker*28€€~@€ĞH€ğXbfunctional_1/conv2d_13/Conv2Dh"
l
redzone_checker*28€àw@€ØH€ğXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh 
l
redzone_checker*28€Àw@€ØH€ğXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh 
m
redzone_checker*28ÿ¿w@ÿ×H€ğXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh 
m
redzone_checker*28€˜w@€ØH€ğXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh 
l
redzone_checker*28ÿ‡w@€ØH€ğXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh 
l
redzone_checker*28ÿ×v@€ĞH€èXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh 
J
redzone_checker*28€Èv@€ĞH€èXbfunctional_1/conv2d_23/Conv2Dh 
m
redzone_checker*28€ğu@€ĞH€àXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh 
l
redzone_checker*28€Àh@€ØH€ğXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
l
redzone_checker*28€ğg@€ØH€àXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28€Èg@€ØH€àXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28ÿÇg@ÿ×H€àXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
j
redzone_checker*28€˜g@€ĞH€ğXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28€˜g@€ĞH€àXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28€ˆg@€ĞH€ØXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28€€g@€ĞH€ØXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28€€g@€ĞH€ØXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28€a@€ĞH€øXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
l
redzone_checker*28€€a@€ĞH€ğXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
l
redzone_checker*28€¸`@€ĞH€èXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28€¸Z@€H€˜Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28€èY@€ØH€ğXb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
u
ampere_sgemm_128x128_nt*28€ØY@€ğH€øXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28€ØY@€ğH€øXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28€Y@€ØH€àXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28€€Y@€ĞH€èXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28ÿÿX@€ØH€èXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28€ĞX@€ĞH€ğXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28ÿŸX@ÿÏH€àXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
ä
†void dgrad2d_grouped_direct_kernel<float, float, float, true, 0, 0, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)*28ÿ‡R@ÿÿ(H€ˆ)Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ÿ¿H@€ğHÿ·Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ÿ÷G@€€H€¸Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€àG@€ØH€¸Xbfunctional_1/conv2d_20/Conv2Dh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ØG@€ØH€ÀXbfunctional_1/conv2d_19/Conv2Dh

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€è?@€ØH€ Xbfunctional_1/conv2d_19/Conv2Dh

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÿÏ?@€ØH€Xbfunctional_1/conv2d_20/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€=@€ˆH€ØXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ˆ=@€èH€àXbfunctional_1/conv2d_17/Conv2Dh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€€=@€èH€èXbfunctional_1/conv2d_16/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€è<@€ğH€ØXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
P
ampere_cgemm_32x32_tn*28€°<@€˜H€˜Xbfunctional_1/conv2d_19/Conv2Dh
P
ampere_cgemm_32x32_tn*28€°<@€H€ Xbfunctional_1/conv2d_20/Conv2Dh
u
ampere_sgemm_128x128_nt*28€è;@€ğH€øXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€À;@€PH€ÀXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€È:@€PH€¨Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ :@€H€Xbfunctional_1/conv2d_9/Conv2Dh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¨9@€€H€ØXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€è8@€øH€àXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ 8@€€H€Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
œ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÿŸ8@€ğH€˜Xbfunctional_1/conv2d_16/Conv2Dh
œ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ˆ8@€ğH€˜Xbfunctional_1/conv2d_17/Conv2Dh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ˆ8@€pH€˜Xbfunctional_1/conv2d_13/Conv2Dh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ˆ8@€hH€Xbfunctional_1/conv2d_14/Conv2Dh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ÿÿ7@€XH€˜Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ğ7@€XH€Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€¨5@€¸H€ğXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
P
ampere_gcgemm_64x32_nt*28€è4@€°H€¸Xbfunctional_1/conv2d_9/Conv2Dh
r
ampere_gcgemm_64x32_nt*28€è4@€°H€¸Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€Ø4@€H€˜Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°4@€€H€˜Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°4@€€H€˜Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€ğ3@€ÈH€¨Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€è2@€°H€¸Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€È1@€àH€èXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
¿
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÿ¿0@€˜Hÿ§Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
Á
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÿ·0@ÿ‡H€°Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
¿
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°0@€˜H€˜Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Á
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€0@€€H€Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€ˆ0@€€H€ˆXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€ğ/@€ğH€€Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€È)@€àH€èXbfunctional_1/conv2d_20/Conv2Dh
O
ampere_gcgemm_32x32_nt*28€è(@€`H€pXbfunctional_1/conv2d_19/Conv2Dh2
O
ampere_gcgemm_32x32_nt*28€Ø(@€`H€pXbfunctional_1/conv2d_20/Conv2Dh2
s
ampere_cgemm_32x32_tn*28€(@€°H€°Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€ğ'@€èH€ˆXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ğ'@€àH€¨Xbfunctional_1/conv2d_21/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€è'@€àH€ Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€à'@€àH€˜Xbfunctional_1/conv2d_1/Conv2Dh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€à'@€àH€˜Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_32x32_tn*28€¸'@€ØH€àXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_32x32_tn*28€¸'@€ØH€àXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
¼
İvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€à&@€à&H€à&Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
š
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€ğ%@€øH€øXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
š
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€à%@€ğH€ğXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Ó
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€ø$@€€H€€Xbfunctional_1/conv2d_20/Conv2Dh
q
ampere_cgemm_32x32_tn*28€à$@€°H€°Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
š
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€à$@€°H€°Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
š
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€Ğ$@€¨H€¨Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_32x32_tn*28€È$@€ H€¨Xbfunctional_1/conv2d_1/Conv2Dh
r
ampere_cgemm_32x32_tn*28€È$@€ H€¨Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
P
ampere_cgemm_32x32_tn*28€À$@€˜H€¨Xbfunctional_1/conv2d_21/Conv2Dh
P
ampere_cgemm_32x32_tn*28€€$@€€H€€Xbfunctional_1/conv2d_22/Conv2Dh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€"@€èH€ğXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
s
ampere_gcgemm_64x32_nt*28€è!@€H€°Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Ó
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ÿç!@€øH€øXbfunctional_1/conv2d_19/Conv2Dh
s
ampere_gcgemm_64x32_nt*28€Ø!@€H€¨Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
P
ampere_cgemm_32x32_tn*28€!@€ÀH€ĞXbfunctional_1/conv2d_17/Conv2Dh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€!@€ĞH€ĞXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
P
ampere_cgemm_32x32_tn*28€ˆ!@€ÀH€ÈXbfunctional_1/conv2d_16/Conv2Dh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€È @€èH€°Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
¿
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¸ @€øH€ Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
Î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€¸ @€èH€°Xbfunctional_1/conv2d_18/Conv2Dh

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€° @€øH€ Xbfunctional_1/conv2d_21/Conv2Dh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¨ @€øH€˜Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€¨ @€èH€°Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€  @€øH€ Xbfunctional_1/conv2d_1/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28€˜ @€ğH€˜Xbfunctional_1/conv2d_14/Conv2Dh
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€˜ @€ĞH€ÀXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ÿ— @€èH€°Xbfunctional_1/conv2d_3/Conv2Dh
r
ampere_cgemm_64x32_tn*28€ @€ˆH€ˆXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
q
ampere_gcgemm_32x32_nt*28€ˆ @€HH€`Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh2
Û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ @€€H€€Xbfunctional_1/conv2d_11/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28€€ @€ğH€Xbfunctional_1/conv2d_13/Conv2Dh
¼
İvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€€ @€€ H€€ Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
P
ampere_cgemm_64x32_tn*28€ğ@€àH€Xbfunctional_1/conv2d_10/Conv2Dh
P
ampere_cgemm_64x32_tn*28€è@€ğH€øXbfunctional_1/conv2d_11/Conv2Dh
r
ampere_cgemm_64x32_tn*28€è@€ğH€øXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€à@€PH€¸Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x32_tn*28€Ğ@€àH€ğXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x32_tn*28€È@€ĞH€øXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ÿÇ@€PH€°Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28ÿ—@ÿÇH€ĞXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
q
ampere_gcgemm_32x32_nt*28€@€HH€XXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh2
¼
İvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€Ğ@€ĞH€ĞXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
P
ampere_cgemm_64x32_tn*28€È@€ H€¨Xbfunctional_1/conv2d_14/Conv2Dh
P
ampere_cgemm_64x32_tn*28€À@€˜H€¨Xbfunctional_1/conv2d_13/Conv2Dh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€À@€ÈH€øXbfunctional_1/conv2d_8/Conv2Dh
»
ÿvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28€¸@€˜H€ Xbfunctional_1/conv2d_20/Conv2Dh
r
ampere_cgemm_64x32_tn*28€@€ˆH€ˆXb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€€H€ˆXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x32_tn*28€€@€øH€ˆXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Q
ampere_gcgemm_32x32_nt*28€ğ@€ÀH€àXbfunctional_1/conv2d_16/Conv2Dh
Q
ampere_gcgemm_32x32_nt*28€ğ@€ÈH€àXbfunctional_1/conv2d_17/Conv2Dh
N
ampere_gcgemm_32x32_nt*28€à@€HH€PXbfunctional_1/conv2d_1/Conv2Dh2
Ó
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ø@€èH€€Xbfunctional_1/conv2d_16/Conv2Dh
Ó
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€È@€àH€€Xbfunctional_1/conv2d_17/Conv2Dh
O
ampere_gcgemm_32x32_nt*28ÿ¯@€HH€PXbfunctional_1/conv2d_21/Conv2Dh2
p
ampere_gcgemm_32x32_nt*28€¨@€HH€PXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh2
q
ampere_gcgemm_32x32_nt*28€¨@€HH€PXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh2
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€¨@€ĞH€€Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
O
ampere_gcgemm_32x32_nt*28€ˆ@€HH€PXbfunctional_1/conv2d_22/Conv2Dh2
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€ÀH€ÀXbfunctional_1/conv2d_11/Conv2Dh
s
ampere_sgemm_128x128_nt*28€ø@€¸H€ÀXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28€à@€¨H€¸Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
Ì
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€Ğ@€XH€ĞXbfunctional_1/conv2d_5/Conv2Dh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€È@€XH€ÈXbfunctional_1/conv2d_15/Conv2Dh
î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€È@€XH€ÈXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
›
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¸@€€H€ Xbfunctional_1/conv2d_3/Conv2Dh
½
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¸@€€H€ Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸@€˜H€ Xbfunctional_1/conv2d_10/Conv2Dh
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°@€€H€˜Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
P
ampere_gcgemm_64x32_nt*28€¨@€H€˜Xbfunctional_1/conv2d_8/Conv2Dh
œ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¨@€€H€Xbfunctional_1/conv2d_18/Conv2Dh
s
ampere_cgemm_64x64_tn*28€ @€H€Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
s
ampere_cgemm_64x64_tn*28€˜@€ˆH€Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
s
ampere_gcgemm_64x32_nt*28€˜@€ˆH€Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€˜@€XH€ĞXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28€@€ˆH€ˆXb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
õ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€à@€ÈH€¨Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
r
ampere_gcgemm_64x32_nt*28€Ø@€àH€øXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
›
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€Ğ@€¸H€°Xbfunctional_1/conv2d_14/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28€È@€àH€èXbfunctional_1/conv2d_11/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28€¸@€ØH€àXbfunctional_1/conv2d_10/Conv2Dh
õ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€¸@€ÈH€˜Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
›
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€ @€¸H€˜Xbfunctional_1/conv2d_13/Conv2Dh
¼
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€@€`H€èXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ÿÿ@€¸HÿÇXbfunctional_1/conv2d_10/Conv2Dh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€Ğ@€¨H€°Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
¼
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€Ğ@€hH€ÀXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
ª
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€À@€ H€ Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
r
ampere_cgemm_32x32_tn*28€¸@€˜H€ Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€8H€PXbfunctional_1/conv2d_19/Conv2Dh2
ª
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€@€ˆH€ˆXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
s
ampere_gcgemm_64x32_nt*28ÿ÷@€°H€ÀXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28€è@€°H€ÀXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€è@€8H€PXbfunctional_1/conv2d_20/Conv2Dh2
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€À@€8H€PXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh2
í
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€¸@€ØH€àXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
í
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€ @€ĞH€ĞXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€8H€HXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh2
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ˆ@€8H€HXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh2
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€8H€HXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh2
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ø@€0H€HXbfunctional_1/conv2d_19/Conv2Dh2
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€è@€8H€HXbfunctional_1/conv2d_22/Conv2Dh2
ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€è@€8H€HXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh2
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€è@€8H€HXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh2
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€à@€8H€HXbfunctional_1/conv2d_21/Conv2Dh2
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€à@€°H€°Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€à@€¨H€¸Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
´
ùvoid implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€È@€˜H€˜Xbfunctional_1/conv2d_9/Conv2Dh
¿
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¸@€˜H€ Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€¸@€8H€HXbfunctional_1/conv2d_20/Conv2Dh2
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€¸@€8H€HXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh2
q
ampere_gcgemm_32x32_nt*28€°@€8H€@Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh2
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°@€˜H€˜Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
„
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€°@€8H€HXbfunctional_1/conv2d_1/Conv2Dh2
Ø
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€8H€HXbfunctional_1/conv2d_1/Conv2Dh2
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¨@€H€˜Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
Á
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¨@€H€˜Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28ÿ§@€ˆH€Xbfunctional_1/conv2d_20/Conv2Dh

0ampere_scudnn_128x32_stridedB_splitK_small_nn_v1*28€ @€ˆH€Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ @€8H€HXbfunctional_1/conv2d_21/Conv2Dh2
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€@€8H€HXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh2
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€@€8H€HXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh2
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€è@€ğH€øXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
‚
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€à@€0H€HXbfunctional_1/conv2d/Conv2Dh2
t
ampere_sgemm_128x128_nt*28€Ğ@€èH€èXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28€È@€èH€ğXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28€¸@€èH€èXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€¸@€ØH€àXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28ÿ·@ÿßH€ğXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
Á
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°@€€H€ØXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€¨@€ĞH€ØXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28€ @€àH€àXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
Á
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ @€øH€ØXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€ğ@€ĞH€ĞXbfunctional_1/conv2d_11/Conv2Dh
Ü
 void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28€à@€àH€èXbfunctional_1/conv2d_22/Conv2Dh
´
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€È@€ H€¨Xbfunctional_1/conv2d_17/Conv2Dh
Ë
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€°@€˜H€˜Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh

0ampere_scudnn_128x32_stridedB_splitK_small_nn_v1*28€¨@€¸H€¸Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€¨@€H€˜Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh

0ampere_scudnn_128x32_stridedB_splitK_small_nn_v1*28€ @€°H€¸Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€ğ@€ğ
H€€Xbfunctional_1/conv2d_20/Conv2Dh
º
ÿvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28€°@€Ğ
H€à
Xbfunctional_1/conv2d_1/Conv2Dh
´
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€¨@€Ğ
H€Ø
Xbfunctional_1/conv2d_11/Conv2Dh
»
ÿvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28€¨@€Ğ
H€Ø
Xbfunctional_1/conv2d_21/Conv2Dh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€ @€Ğ
H€Ğ
Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€ @€¸
H€è
Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28ÿ—@ÿÇ
H€Ğ
Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€€@€ H€ Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€ø@€¸
H€À
Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
¼
İvoid cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€°@€°H€°Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€˜@€€
H€˜
Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
¼
İvoid cudnn::cnn::wgrad_alg1_engine<float, 512, 6, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€ø@€øH€øXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€Ğ@€à	H€ğ	Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
š
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€È@€à	H€è	Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€ @€Ğ	H€Ğ	Xbfunctional_1/conv2d_19/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€@€È	H€È	Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
š
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€€@€À	H€À	Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh

0ampere_scudnn_128x32_stridedB_splitK_small_nn_v1*28€ø@€¨H€¨Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
r
ampere_gcgemm_64x32_nt*28€è@€ H€¸Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
P
ampere_gcgemm_64x32_nt*28€à@€ H€¸Xbfunctional_1/conv2d_5/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28€Ø@€ H€¸Xbfunctional_1/conv2d_15/Conv2Dh
s
ampere_gcgemm_64x32_nt*28€Ğ@€ H€¸Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ó
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ÿÇ@€ĞH€ˆXbfunctional_1/conv2d_21/Conv2Dh
q
ampere_gcgemm_32x32_nt*28€À@€xH€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€°@€H€ Xbfunctional_1/conv2d_2/Conv2Dh
ğ
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€°@€PH€øXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh	
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ @€(H€8Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh2
î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€˜@€hH€ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
r
ampere_gcgemm_32x32_nt*28€@€xH€ˆXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€@€(H€8Xbfunctional_1/conv2d_22/Conv2Dh2
¢
Ævoid gemv2T_kernel_val<int, int, float2, float2, float2, 128, 16, 2, 2, false, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>, float2, float2)*28€ˆ@€øH€	Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_64x32_tn*28€ø@€ĞH€¨	Xbfunctional_1/conv2d_9/Conv2Dh
ô
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€ğ@€ØH€ Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
P
ampere_gcgemm_32x32_nt*28€è@€pH€ˆXbfunctional_1/conv2d_18/Conv2Dh
Ò
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ÿ×@€ØHÿ—Xbfunctional_1/conv2d_1/Conv2Dh
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ğ@€ĞH€˜Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ğ@€PH€èXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
O
ampere_cgemm_32x32_tn*28€À@€àH€àXbfunctional_1/conv2d_3/Conv2Dh
q
ampere_cgemm_32x32_tn*28€¸@€ØH€àXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
q
ampere_cgemm_64x32_tn*28€¸@€ØH€àXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
q
ampere_cgemm_64x32_tn*28€°@€ØH€ØXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
O
ampere_gcgemm_32x32_nt*28€°@€hH€€Xbfunctional_1/conv2d_3/Conv2Dh
O
ampere_cgemm_64x32_tn*28€¨@€ĞH€ØXbfunctional_1/conv2d_5/Conv2Dh
P
ampere_cgemm_32x32_tn*28€ @€ĞH€ĞXbfunctional_1/conv2d_18/Conv2Dh
P
ampere_cgemm_64x32_tn*28€ @€ĞH€ĞXbfunctional_1/conv2d_15/Conv2Dh
r
ampere_cgemm_32x32_tn*28€˜@€ÈH€ĞXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x32_tn*28€@€ÀH€ĞXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€PH€ Xbfunctional_1/conv2d_7/Conv2Dh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€è@€PH€˜Xbfunctional_1/conv2d_12/Conv2Dh
µ
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€à@€0H€ˆXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
O
ampere_cgemm_64x32_tn*28€Ø@€ H€¸Xbfunctional_1/conv2d_7/Conv2Dh
P
ampere_cgemm_64x32_tn*28€À@€ H€ Xbfunctional_1/conv2d_12/Conv2Dh
q
ampere_cgemm_64x32_tn*28€À@€˜H€¨Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
“
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€À@€0H€ğXbfunctional_1/conv2d_9/Conv2Dh
r
ampere_cgemm_64x32_tn*28ÿ¿@€˜Hÿ§Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
½
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°@€€H€˜Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
R
ampere_sgemm_128x128_nn*28€¨@€H€˜Xbfunctional_1/conv2d_17/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÿ§@ÿH€˜Xbfunctional_1/conv2d_20/Conv2Dh
q
ampere_cgemm_32x32_tn*28€ˆ@€€H€ˆXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ô
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€è@€ÈH€¨Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Á
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€è@€øH€€Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
õ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€à@€ÈH€¨Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€à@€ğH€€Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€à@€ H€ Xbfunctional_1/conv2d_14/Conv2Dh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€à@€øH€øXbfunctional_1/conv2d_19/Conv2Dh
Ò
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ø@€ÈH€ Xbfunctional_1/conv2d_3/Conv2Dh
ö
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ğ@€àH€ˆXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
Ó
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€È@€ÈH€ Xbfunctional_1/conv2d_18/Conv2Dh
ö
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€À@€ØH€ˆXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€¸@€ØH€àXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°@€ØH€ØXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
Ù
 void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28€¨@€˜H€˜Xbfunctional_1/conv2d/Conv2Dh
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ @€ÈH€ØXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Ì
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ @€(H€¸Xbfunctional_1/conv2d_4/Conv2Dh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€˜@€€H€ˆXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€˜@€0H€¨Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
r
ampere_gcgemm_64x32_nt*28€@€ÈH€ÈXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
Q
ampere_gcgemm_64x32_nt*28€ˆ@€ÀH€ÈXbfunctional_1/conv2d_12/Conv2Dh
P
ampere_gcgemm_64x32_nt*28€ˆ@€ÀH€ÈXbfunctional_1/conv2d_7/Conv2Dh
s
ampere_gcgemm_64x32_nt*28€€@€ÀH€ÀXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x64_tn*28€ğ@€¸H€¸Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€à@€°H€°Xbfunctional_1/conv2d_12/Conv2Dh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€à@€°H€°Xbfunctional_1/conv2d_7/Conv2Dh
r
ampere_cgemm_64x64_tn*28€Ø@€¨H€°Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
s
ampere_cgemm_64x64_tn*28€Ğ@€¨H€¨Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
æ
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ğ@€¨H€¨Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
»
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28ÿÏ@€`H€ÈXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
›
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€È@€ˆH€˜Xbfunctional_1/conv2d_2/Conv2Dh
¼
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€È@€`H€ÀXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
p
ampere_gcgemm_32x32_nt*28€°@€`H€pXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
³
øvoid explicit_convolve_sgemm<float, int, 128, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€°@€˜H€˜Xbfunctional_1/conv2d_9/Conv2Dh
š
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€°@€`H€°Xbfunctional_1/conv2d_15/Conv2Dh
™
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€¨@€hH€°Xbfunctional_1/conv2d_5/Conv2Dh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€˜@€ˆH€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€˜@€ÀH€ÈXbfunctional_1/conv2d_10/Conv2Dh
t
ampere_sgemm_128x128_nt*28€ˆ@€€H€ˆXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€ˆ@€€H€ˆXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
ª
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€€@€€H€€Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ø@€øH€€Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28ÿï@ÿÏH€ĞXbfunctional_1/conv2d_17/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€Ø@€ÈH€ÈXbfunctional_1/conv2d_20/Conv2Dh
ì
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ø@€èH€ğXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
r
ampere_gcgemm_32x32_nt*28€Ğ@€ØH€àXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€Ğ@€àH€ğXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
í
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ğ@€èH€èXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
Ö
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ğ@€ H€0Xbfunctional_1/conv2d/Conv2Dh2
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€È@€àH€èXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
À
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€@€8H€øXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ÿÏ@€XH€øXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€À@€ H€ Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°@€˜H€˜Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
Í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€°@€@H€€Xbfunctional_1/conv2d_22/Conv2Dh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€˜@€¸H€¸Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€@€ˆH€ˆXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€ˆ@€€H€ˆXbfunctional_1/conv2d_12/Conv2Dh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€€@€€H€€Xbfunctional_1/conv2d_7/Conv2Dh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€€@€€H€€Xbfunctional_1/conv2d_8/Conv2Dh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€ø@€øH€€Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€ø@€øH€€Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
¿
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€è@€€H€øXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
ˆ>
©=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<128, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<128, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<128, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<128, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<128, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<128, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<128, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<128, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28€è@€èH€èXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
¿
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€à@€€H€ğXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€à@€èH€ˆXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
´
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€à@€ğH€ğXbfunctional_1/conv2d_18/Conv2Dh
³
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€à@€ğH€ğXbfunctional_1/conv2d_3/Conv2Dh
P
ampere_gcgemm_64x32_nt*28€À@€°H€ÀXbfunctional_1/conv2d_4/Conv2Dh
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€¸@€ØH€àXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
s
ampere_sgemm_128x128_nt*28€°@€ØH€ØXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€¨@€ĞH€ØXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh

cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ @€ĞH€€Xbfunctional_1/conv2d_22/Conv2Dh
t
ampere_sgemm_128x128_nt*28€˜@€ÈH€ĞXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€˜@€ÈH€ĞXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
R
ampere_sgemm_128x128_nn*28€ˆ@€ÀH€ÈXbfunctional_1/conv2d_18/Conv2Dh
½
Şvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€ˆ@€ˆH€ˆXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
¼
Şvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€ˆ@€ˆH€ˆXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
¼
Şvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
í
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€€@€HH€¸Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€ø
@€¸H€ÀXbfunctional_1/conv2d_17/Conv2Dh
Q
ampere_sgemm_128x128_nn*28€ğ
@€°H€ÀXbfunctional_1/conv2d_3/Conv2Dh
´
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€ğ
@€¸H€¸Xbfunctional_1/conv2d_12/Conv2Dh
³
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€è
@€°H€¸Xbfunctional_1/conv2d_7/Conv2Dh
N
ampere_gcgemm_32x32_nt*28ÿç
@€HH€XXbfunctional_1/conv2d_2/Conv2Dh
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ø
@€ĞH€àXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_32x32_tn*28€Ğ
@€¨H€¨Xbfunctional_1/conv2d_2/Conv2Dh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€Ğ
@€ H€°Xbfunctional_1/conv2d_19/Conv2Dh
ö
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€È
@€ĞH€ØXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
Ê
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28€È
@€ H€¨Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ê
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€È
@€@H€øXbfunctional_1/conv2d/Conv2Dh
s
ampere_sgemm_128x128_nt*28€À
@€ H€ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€ 
@€H€Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ 
@€@H€PXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€˜
@€ÀH€ÈXbfunctional_1/conv2d_13/Conv2Dh
q
ampere_cgemm_64x32_tn*28€
@€ˆH€ˆXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
º
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28€ˆ
@€€H€ˆXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€ˆ
@€øH€Xbfunctional_1/conv2d_14/Conv2Dh
ô
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€€
@€ĞH€°Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
˜
ávoid gemmk1_kernel<float2, 256, 5, false, false, true, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28ÿÿ	@ÿH€ Xbfunctional_1/conv2d/Conv2Dh2
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€ø	@€¸H€ÀXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€è	@€8H€PXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
õ
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€à	@€PH€ĞXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_64x32_tn*28€Ø	@€èH€ğXbfunctional_1/conv2d_6/Conv2Dh
q
ampere_cgemm_32x32_tn*28€Ğ	@€èH€èXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
´
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€Ğ	@€èH€èXbfunctional_1/conv2d_10/Conv2Dh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ğ	@€8H€PXbfunctional_1/conv2d_16/Conv2Dh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ğ	@€@H€èXbfunctional_1/conv2d_6/Conv2Dh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€È	@€ˆH€ Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€À	@€8H€PXbfunctional_1/conv2d_17/Conv2Dh
q
ampere_cgemm_64x32_tn*28€¸	@€ØH€àXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
¨
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€¸	@€ğH€øXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_64x32_tn*28€°	@€ØH€ØXbfunctional_1/conv2d_4/Conv2Dh
½
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¨	@€8H€ÀXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_64x32_tn*28€ 	@€ĞH€ĞXbfunctional_1/conv2d_8/Conv2Dh
R
ampere_sgemm_128x128_nn*28€ 	@€ĞH€ĞXbfunctional_1/conv2d_14/Conv2Dh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ 	@€8H€PXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ 	@€8H€PXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€	@€€H€ˆXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€	@€8H€HXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€	@€ H€¨Xbfunctional_1/conv2d_16/Conv2Dh
ö
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€ˆ	@€ĞH€øXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€ˆ	@€ÀH€ÈXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ˆ	@€8H€PXbfunctional_1/conv2d_16/Conv2Dh
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ˆ	@€8H€HXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ	@€8H€HXbfunctional_1/conv2d_18/Conv2Dh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ	@€8H€PXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
Ø
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€	@€8H€HXbfunctional_1/conv2d_3/Conv2Dh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28ÿÿ@ÿÿH€€Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ø@€8H€PXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ö
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€ğ@€ÈH€ğXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€ğ@€àH€èXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ğ@€8H€HXbfunctional_1/conv2d_17/Conv2Dh
„
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ğ@€8H€HXbfunctional_1/conv2d_2/Conv2Dh
Ø
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ğ@€8H€HXbfunctional_1/conv2d_2/Conv2Dh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€è@€øH€øXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€è@€0H€HXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
µ
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€è@€0H€€Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€à@€ğH€øXbfunctional_1/conv2d_21/Conv2Dh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€Ø@€ğH€øXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€Ø@€¨H€°Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
P
ampere_gcgemm_64x32_nt*28€Ğ@€¨H€¨Xbfunctional_1/conv2d_6/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€Ğ@€ğH€ğXbfunctional_1/conv2d_1/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€Ğ@€ğH€ğXbfunctional_1/conv2d_22/Conv2Dh
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€Ğ@€8H€HXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ğ@€èH€èXbfunctional_1/conv2d_6/Conv2Dh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È@€8H€HXbfunctional_1/conv2d_18/Conv2Dh
„
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È@€8H€HXbfunctional_1/conv2d_3/Conv2Dh
»
ÿvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 2, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28€È@€ H€¨Xbfunctional_1/conv2d_22/Conv2Dh
Ñ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€À@€pH€°Xbfunctional_1/conv2d_2/Conv2Dh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€À@€ H€ Xbfunctional_1/conv2d_1/Conv2Dh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€¸@€èH€èXbfunctional_1/conv2d_15/Conv2Dh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€¸@€èH€èXbfunctional_1/conv2d_5/Conv2Dh
Q
ampere_sgemm_128x128_nn*28€°@€˜H€˜Xbfunctional_1/conv2d_2/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€°@€˜H€˜Xbfunctional_1/conv2d_21/Conv2Dh
“
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€°@€ H€øXbfunctional_1/conv2d_8/Conv2Dh
»
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€°@€`H€ÀXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¨@€H€˜Xbfunctional_1/conv2d_17/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¨@€H€˜Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
š
ávoid gemmk1_kernel<float2, 256, 5, true, false, false, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28€¨@€H€˜Xbfunctional_1/conv2d/Conv2Dh
¢
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€¨@€¨H€¨Xbfunctional_1/conv2d_17/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€ @€àH€àXbfunctional_1/conv2d_14/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€H€Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€˜@€ˆH€Xbfunctional_1/conv2d_22/Conv2Dh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€˜@€€H€˜Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
r
ampere_gcgemm_64x32_nt*28€@€ˆH€ˆXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
¿
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€@€€H€ˆXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€@€€H€ˆXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
§
Évoid cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28€@€ˆH€ˆXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€ˆ@€ØH€ØXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ˆ@€€H€ˆXbfunctional_1/conv2d_1/Conv2Dh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ˆ@€€H€ˆXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€€@€øH€ˆXbfunctional_1/conv2d_16/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€€H€€Xbfunctional_1/conv2d/Conv2Dh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€€H€€Xbfunctional_1/conv2d_21/Conv2Dh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh

cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ø@€øH€€Xbfunctional_1/conv2d_1/Conv2Dh

cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ø@€øH€€Xbfunctional_1/conv2d_20/Conv2Dh
¿
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ø@€øH€€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
æ
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€ø@€øH€€Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh

cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ğ@€ğH€€Xbfunctional_1/conv2d_21/Conv2Dh
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ğ@€ğH€€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ğ@€øH€øXbfunctional_1/conv2d_20/Conv2Dh
r
ampere_cgemm_64x64_tn*28€è@€ğH€øXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€è@€ÈH€ĞXbfunctional_1/conv2d_9/Conv2Dh
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€è@€ğH€øXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€è@€ğH€øXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh

cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€è@€ğH€øXbfunctional_1/conv2d_19/Conv2Dh
™
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€è@€HH€°Xbfunctional_1/conv2d_4/Conv2Dh
r
ampere_cgemm_64x64_tn*28€à@€èH€øXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
›
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€à@€ğH€ğXbfunctional_1/conv2d/Conv2Dh
À
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€à@€èH€øXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€à@€àH€àXbfunctional_1/conv2d_20/Conv2Dh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€à@€ğH€ğXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
ì
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ø@€èH€ğXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
‘
Øvoid gemmk1_kernel<float, 256, 5, false, false, false, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>(cublasGemmk1Params<float, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float, biasType<cublasGemvTensorStridedBatched<float>::value_type, float>::type>)*28€Ø@€èH€ğXbfunctional_1/conv2d/Conv2Dh
Ó
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ğ@€H€ØXbfunctional_1/conv2d_22/Conv2Dh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ğ@€èH€èXbfunctional_1/conv2d_14/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€È@€ÀH€ÈXbfunctional_1/conv2d_17/Conv2Dh
˜
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€È@€àH€èXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€È@€àH€èXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6::Params)*28€È@€ÈH€ÈXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6::Params)*28€È@€ÈH€ÈXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
è
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6::Params)*28€È@€ÈH€ÈXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
è
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6::Params)*28€È@€ÈH€ÈXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ô
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€À@€ØH€èXbfunctional_1/conv2d/Conv2Dh
÷
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€À@€àH€àXbfunctional_1/conv2d_19/Conv2Dh
÷
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€À@€àH€àXbfunctional_1/conv2d_20/Conv2Dh
÷
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€À@€àH€àXbfunctional_1/conv2d_21/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€À@€ØH€èXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_128x64_16x6::Params)*28€À@€ÀH€ÀXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€À@€ÀH€ÀXbfunctional_1/conv2d_3/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€¸@€ØH€àXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€¸@€ØH€àXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ö
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€¸@€ØH€àXbfunctional_1/conv2d_1/Conv2Dh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€¸@€ØH€àXbfunctional_1/conv2d_10/Conv2Dh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸@€ØH€àXbfunctional_1/conv2d_13/Conv2Dh
¼
Şvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€°@€ØH€ØXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
î=
=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28€°@€°H€°Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€ØH€ØXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€ØH€ØXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
´
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€°@€¸H€ÀXbfunctional_1/conv2d_18/Conv2Dh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€¨@€ĞH€ØXbfunctional_1/conv2d_13/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€ @€°H€¸Xbfunctional_1/conv2d_11/Conv2Dh
R
ampere_sgemm_128x128_nn*28€˜@€ÈH€ĞXbfunctional_1/conv2d_11/Conv2Dh
Q
ampere_sgemm_128x128_nn*28€˜@€ÈH€ĞXbfunctional_1/conv2d_9/Conv2Dh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€˜@€ÈH€ĞXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
´
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€@€ÈH€ÈXbfunctional_1/conv2d_8/Conv2Dh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€€@€ÀH€ÀXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€ø@€¨H€¨Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28€ø@€¸H€ÀXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28€ğ@€°H€ÀXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
½
Şvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€ğ@€ğH€ğXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€ğ@€ H€¨Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€è@€ H€¨Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
u
ampere_sgemm_128x128_nt*28€è@€ H€¨Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
ò
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€è@€8H€ Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28€Ğ@€˜H€ Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28€Ğ@€˜H€ Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28€Ğ@€˜H€ Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
õ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ğ@€ĞH€ØXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€È@€ˆH€ÀXbfunctional_1/conv2d_14/Conv2Dh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€È@€ H€¨Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€È@€˜H€˜Xbfunctional_1/conv2d_6/Conv2Dh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€À@€H€˜Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
º
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28€À@€ H€ Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
¹
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28€À@€ H€ Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
ö
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€¸@€ÈH€ĞXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
¼
Şvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€°@€˜H€˜Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Ä
ivoid fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)*28€°@€ H€`Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh

t
ampere_sgemm_128x128_nt*28€ @€H€Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
³
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€ @€H€Xbfunctional_1/conv2d_2/Conv2Dh
¾
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€˜@€ˆH€ˆXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
†
)ampere_scudnn_128x64_stridedB_small_nn_v1*28€@€€H€ˆXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€@€ˆH€ˆXbfunctional_1/conv2d_18/Conv2Dh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€ˆ@€€H€ˆXbfunctional_1/conv2d_3/Conv2Dh
ˆ>
©=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<128, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<128, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<128, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<128, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<128, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<128, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<128, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 4, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<128, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28€€@€€H€€Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¢
ivoid fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)*28€ø@€XH€`Xbfunctional_1/conv2d_23/Conv2Dh
€
¤void gemv2N_kernel<int, int, float, float, float, 128, 8, 4, 4, 1, false, cublasGemvParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28€ğ@€øH€€Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€à@€ğH€ğXbfunctional_1/conv2d_15/Conv2Dh
Q
ampere_sgemm_128x128_nn*28€Ğ@€èH€èXbfunctional_1/conv2d_5/Conv2Dh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28€Ğ@€èH€èXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
³
øvoid explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€Ğ@€èH€èXbfunctional_1/conv2d_6/Conv2Dh
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€Ğ@€PH€hXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
R
ampere_sgemm_128x128_nn*28€È@€àH€èXbfunctional_1/conv2d_15/Conv2Dh
t
ampere_sgemm_128x128_nt*28€È@€àH€èXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28€À@€àH€àXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
´
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€À@€àH€àXbfunctional_1/conv2d_5/Conv2Dh
¢
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€À@€ÀH€ÀXbfunctional_1/conv2d_14/Conv2Dh
ô
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€°@€xH€èXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
µ
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€°@€ØH€ØXbfunctional_1/conv2d_16/Conv2Dh
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€°@€PH€`Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€¨@€ĞH€ØXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28€¨@€ĞH€ØXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28€¨@€¨H€¨Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€ÀH€ˆXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
´
øvoid explicit_convolve_sgemm<float, int, 128, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28ÿŸ@ÿÏH€ĞXbfunctional_1/conv2d_13/Conv2Dh
¹
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€˜@€ÈH€ĞXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€˜@€ÈH€ĞXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€HH€hXbfunctional_1/conv2d_13/Conv2Dh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€@H€hXbfunctional_1/conv2d_14/Conv2Dh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€@€ÈH€ÈXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€@€ØH€àXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
‚
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€@€ÈH€ÈXbfunctional_1/conv2d_9/Conv2Dh
¢
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)*28€@€H€Xbfunctional_1/conv2d_11/Conv2Dh
İ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28ÿÿ@€ĞH€ØXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
š
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€ø@€ĞH€ØXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28€ø@€øH€øXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€ø@€ĞH€ØXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€ğ@€ĞH€ĞXbfunctional_1/conv2d_15/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€ğ@€ĞH€ĞXbfunctional_1/conv2d_3/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€ğ@€ĞH€ĞXbfunctional_1/conv2d_5/Conv2Dh
Ú
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ğ@€ÀH€ØXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ğ@€ÀH€ØXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
Ü
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€ğ@€ĞH€ĞXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
¡
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€ğ@€ğH€ğXbfunctional_1/conv2d_3/Conv2Dh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€è@€ÈH€ĞXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€è@€°H€¸Xbfunctional_1/conv2d_5/Conv2Dh
½
Şvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28€è@€èH€èXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
¡
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28€è@€èH€èXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€è@€ÈH€ĞXbfunctional_1/conv2d_4/Conv2Dh
¢
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€è@€èH€èXbfunctional_1/conv2d_18/Conv2Dh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28ÿç@€°Hÿ·Xbfunctional_1/conv2d_11/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€à@€ÈH€ĞXbfunctional_1/conv2d_18/Conv2Dh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€à@€ÈH€ĞXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€à@€°H€°Xbfunctional_1/conv2d_15/Conv2Dh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28€à@€àH€àXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€Ø@€ÈH€ÈXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
÷
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€Ø@€¨H€°Xbfunctional_1/conv2d_16/Conv2Dh
Ú
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€Ø@€ÀH€ĞXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28€Ğ@€ÀH€ÈXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€Ğ@€¨H€¨Xbfunctional_1/conv2d_7/Conv2Dh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€Ğ@€ĞH€ĞXbfunctional_1/conv2d_19/Conv2Dh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€È@€ÀH€ÈXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
¿
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€È@€XH€ĞXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È@€H€˜Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
©
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È@€H€˜Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€À@€ÀH€ÀXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€À@€ÀH€ÀXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
É
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€À@€ H€ Xbfunctional_1/conv2d_12/Conv2Dh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€À@€ H€ Xbfunctional_1/conv2d_4/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€À@€ H€ Xbfunctional_1/conv2d_18/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€À@€ H€ Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
½
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€À@€hH€¸Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€¸@€¸H€ÀXbfunctional_1/conv2d_8/Conv2Dh
™
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€¸@€¸H€ÀXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
˜
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€¸@€¸H€ÀXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
œ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€¸@€ˆH€°Xbfunctional_1/conv2d_17/Conv2Dh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€¸@€˜H€ Xbfunctional_1/conv2d_6/Conv2Dh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¸@€˜H€ Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28€¸@€¸H€¸Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
ë
Œvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3::Params)*28€¸@€¸H€¸Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
ê
Œvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3::Params)*28€¸@€¸H€¸Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
ê
Œvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3::Params)*28€¸@€¸H€¸Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
½
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€¸@€`H€¸Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
t
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€°@€˜H€˜Xbfunctional_1/conv2d/Conv2Dh
Á
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°@€¸H€ÀXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€°@€˜H€˜Xbfunctional_1/conv2d_9/Conv2Dh
¹
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28€°@€˜H€˜Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€°@€H€ Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€°@€˜H€˜Xbfunctional_1/conv2d_3/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€°@€˜H€˜Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€°@€˜H€˜Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€¨@€H€˜Xbfunctional_1/conv2d_17/Conv2Dh
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28€¨@€¨H€¨Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
ö
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€ @€H€Xbfunctional_1/conv2d_3/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_14/Conv2Dh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_18/Conv2Dh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_2/Conv2Dh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_3/Conv2Dh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6::Params)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
é
Švoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6::Params)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
Û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ @€ˆH€ˆXbfunctional_1/conv2d_10/Conv2Dh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ @€@H€PXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
³
øvoid implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€ @€°H€¸Xbfunctional_1/conv2d_2/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€˜@€°H€¸Xbfunctional_1/conv2d_7/Conv2Dh
Q
ampere_sgemm_128x128_nn*28€˜@€ˆH€Xbfunctional_1/conv2d_4/Conv2Dh
÷
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€˜@€ˆH€Xbfunctional_1/conv2d_17/Conv2Dh
÷
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€˜@€ˆH€Xbfunctional_1/conv2d_18/Conv2Dh
ö
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€˜@€ˆH€Xbfunctional_1/conv2d_2/Conv2Dh
™
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€˜@€ˆH€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
˜
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€˜@€ˆH€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€˜@€ˆH€Xbfunctional_1/conv2d_8/Conv2Dh
ä
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€˜@€ˆH€Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28€˜@€˜H€˜Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€8H€HXbfunctional_1/conv2d_13/Conv2Dh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€8H€HXbfunctional_1/conv2d_15/Conv2Dh
„
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€8H€PXbfunctional_1/conv2d_4/Conv2Dh
„
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€8H€PXbfunctional_1/conv2d_5/Conv2Dh
§
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€@H€HXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€@H€HXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€8H€PXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€ˆH€Xbfunctional_1/conv2d_5/Conv2Dh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€˜@€ˆH€Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28ÿ—@ÿ¯H€¸Xbfunctional_1/conv2d_12/Conv2Dh
Q
ampere_sgemm_128x128_nn*28€@€ˆH€ˆXbfunctional_1/conv2d_7/Conv2Dh
î=
=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28€@€H€Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€@€8H€PXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
‡
*ampere_scudnn_128x128_stridedB_small_nn_v1*28€ˆ@€ˆH€ˆXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
R
ampere_sgemm_128x128_nn*28€ˆ@€€H€ˆXbfunctional_1/conv2d_12/Conv2Dh
›
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€ˆ@€€H€ˆXbfunctional_1/conv2d_3/Conv2Dh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ˆ@€8H€HXbfunctional_1/conv2d_14/Conv2Dh
Ù
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€8H€PXbfunctional_1/conv2d_15/Conv2Dh
û
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€8H€PXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€8H€HXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€€H€ˆXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€€H€ˆXbfunctional_1/conv2d_15/Conv2Dh
‡
*ampere_scudnn_128x128_stridedB_small_nn_v1*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
†
*ampere_scudnn_128x128_stridedB_small_nn_v1*28€€@€€H€€Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28€€@€€H€€Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
œ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€€@€€H€€Xbfunctional_1/conv2d_16/Conv2Dh
œ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€€@€€H€€Xbfunctional_1/conv2d_18/Conv2Dh
›
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€€@€€H€€Xbfunctional_1/conv2d_2/Conv2Dh
¾
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
½
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€€@€øH€ˆXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Ø
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€8H€PXbfunctional_1/conv2d_5/Conv2Dh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€€H€€Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
†
*ampere_scudnn_128x128_stridedB_small_nn_v1*28€ø@€øH€øXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28€ø@€øH€€Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28€ø@€øH€øXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
Q
ampere_sgemm_128x128_nn*28€ğ@€øH€øXbfunctional_1/conv2d_8/Conv2Dh
s
ampere_sgemm_128x128_nt*28€ğ@€øH€øXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ğ@€8H€HXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ø
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ğ@€8H€HXbfunctional_1/conv2d_4/Conv2Dh
¢
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)*28€ğ@€ğH€ğXbfunctional_1/conv2d_10/Conv2Dh
s
ampere_sgemm_128x128_nt*28€è@€ğH€øXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
ô
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ø@€XH€˜Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
å
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ø@€˜H€ Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ì
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ø@€èH€ğXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ì
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ğ@€èH€èXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
Œ
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28€È@€ÈH€ÈXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
Œ
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28€È@€ÈH€ÈXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
‹
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28€È@€ÈH€ÈXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€È@€˜H€˜Xbfunctional_1/conv2d_2/Conv2Dh
‹
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28€À@€ÀH€ÀXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
¼
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€À@€pH€pXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
È
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€¸@€ØH€àXbfunctional_1/conv2d_2/Conv2Dh
»
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€¸@€hH€xXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
Ä
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€°@€°H€°Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Ã
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€°@€°H€°Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Û
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¨@€ĞH€ØXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¨@€HH€ˆXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
Ä
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€¨@€¨H€¨Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ã
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€¨@€¨H€¨Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€ @€ˆH€Xbfunctional_1/conv2d_4/Conv2Dh
è
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€˜@€H€ˆXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
¡
ævoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28€ˆ@€ˆH€ˆXbfunctional_1/conv2d_2/Conv2Dh
´
ùvoid explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€€@€ÀH€ÀXbfunctional_1/conv2d_4/Conv2Dh
—
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28€ø@€xH€€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€ø@€xH€€Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Ü
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€ø@€xH€ˆXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
¨
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€ø@€¸H€ÀXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28€ğ@€¸H€¸Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
¸
Ûvoid cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28€ğ@€¸H€¸Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
Õ
švoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false> >, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false> >, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)*28€ğ@€ğH€ğXbfunctional_1/conv2d_9/Conv2Dh
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride::Params)*28€è@€èH€èXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
»
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28€è@€HH€hXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride::Params)*28ÿç@ÿçHÿçXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
Ù
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€à@€`H€€Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
Ú
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€à@€pH€xXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
ƒ
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€à@€°H€°Xbfunctional_1/conv2d_10/Conv2Dh
‚
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€à@€°H€°Xbfunctional_1/conv2d_8/Conv2Dh
Q
ampere_sgemm_128x128_nn*28€Ø@€¨H€°Xbfunctional_1/conv2d_6/Conv2Dh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€Ø@€pH€xXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Ú
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€Ø@€`H€€Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
Ú
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€Ø@€pH€xXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
Ù
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ø@€ H€¸Xbfunctional_1/conv2d_4/Conv2Dh
ƒ
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€Ø@€¨H€°Xbfunctional_1/conv2d_11/Conv2Dh
³
ùvoid implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28€Ø@€@H€HXbfunctional_1/conv2d_23/Conv2Dh
t
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1*28€Ğ@€pH€pXbfunctional_1/conv2d_6/Conv2Dh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€Ğ@€pH€pXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
Ö
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€Ğ@€pH€pXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
Ù
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€Ğ@€`H€xXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
Û
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€Ğ@€pH€pXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€Ğ@€PH€XXbfunctional_1/conv2d_11/Conv2Dh
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€Ğ@€PH€XXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
¹
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28€È@€ÈH€ÈXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È@€HH€XXbfunctional_1/conv2d_10/Conv2Dh
„
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€È@€PH€XXbfunctional_1/conv2d_7/Conv2Dh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€È@€H€˜Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Î
—void DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€À@€@H€`Xbfunctional_1/conv2d/Conv2Dh
é
«void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28€À@€˜H€¨b!functional_1/concatenate_3/concath
ä
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€À@€ H€ Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28€À@€ÀH€ÀXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
„
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€À@€PH€PXbfunctional_1/conv2d_6/Conv2Dh
§
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€À@€HH€XXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€À@€PH€PXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
§
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€À@€H€°Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
r
ampere_sgemm_128x128_nt*28€¸@€hH€hXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28€¸@€¸H€¸Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
…
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€¸@€HH€PXbfunctional_1/conv2d_12/Conv2Dh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸@€˜H€ Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸@€HH€XXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€¸@€˜H€ Xbfunctional_1/conv2d_16/Conv2Dh
s
ampere_sgemm_128x128_nt*28€°@€`H€hXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
˜
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€°@€˜H€˜Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28€°@€°H€°Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
‡
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28€°@€°H€°Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ı
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€˜H€˜Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€˜H€˜Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€HH€PXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
Ú
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€˜H€˜Xbfunctional_1/conv2d_17/Conv2Dh
¤
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€°@€°H€°Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
r
ampere_sgemm_128x128_nt*28€¨@€`H€hXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€¨@€H€˜Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€¨@€H€˜Xbfunctional_1/conv2d_5/Conv2Dh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€¨@€H€˜Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10>(cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10::Params)*28€¨@€¨H€¨Xbfunctional_1/conv2d_16/Conv2Dh
‚
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€¨@€¨H€¨Xbfunctional_1/conv2d_19/Conv2Dh
¥
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€¨@€¨H€¨Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_11/Conv2Dh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_2/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€H€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_9/Conv2Dh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_14/Conv2Dh
¿
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_15/Conv2Dh
¾
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xbfunctional_1/conv2d_4/Conv2Dh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
á
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
à
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€H€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€ @€H€ˆXbfunctional_1/conv2d_19/Conv2Dh
º
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€˜@€ˆH€Xbfunctional_1/conv2d_15/Conv2Dh
Ü
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€˜@€ˆH€Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€˜@€XH€`Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€˜@€XH€`Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€ˆH€Xbfunctional_1/conv2d_8/Conv2Dh
†
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€ˆH€Xbfunctional_1/conv2d_9/Conv2Dh
¨
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€˜@€ˆH€Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€˜@€H€€Xbfunctional_1/conv2d_20/Conv2Dh
¹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@€ˆH€ˆXbfunctional_1/conv2d_5/Conv2Dh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@€ˆH€ˆXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Û
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@€ˆH€ˆXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€@€@H€HXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
ş
Ÿvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€@€ˆH€ˆXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
‚
Ævoid gemv2T_kernel_val<int, int, float2, float2, float2, 128, 16, 2, 2, false, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>, float2, float2)*28€@€ˆH€ˆXbfunctional_1/conv2d_23/Conv2Dh
Ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ˆ@€€H€ˆXbfunctional_1/conv2d_9/Conv2Dh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbqgradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
™
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€€@€0H€PXbfunctional_1/conv2d/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€€@€@H€`Xbfunctional_1/conv2d_9/Conv2Dh
¦
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€€@€€H€€Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
¥
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€€@€€H€€Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€€@€€H€€bpgradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¥
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€ø@€xH€€Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
¥
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€ø@€xH€€Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ø@€øH€øbpgradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
ô
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€ğ@€8H€@Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€ğ@€PH€PXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€ğ@€xH€xXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
õ
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€è@€pH€xXbfunctional_1/conv2d_22/Conv2Dh

Ävoid cudnn::pooling_bw_kernel_max<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€è@€èH€èb<gradient_tape/functional_1/max_pooling2d/MaxPool/MaxPoolGradh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€è@€HH€PXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
£
Ævoid gemv2T_kernel_val<int, int, float2, float2, float2, 128, 16, 2, 2, false, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>, float2, float2)*28€è@€pH€xXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
r
ampere_sgemm_128x128_nt*28€à@€pH€pXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Ò
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€à@€àH€àb@gradient_tape/functional_1/leaky_re_lu_1/LeakyRelu/LeakyReluGradh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€à@€àH€àbAgradient_tape/functional_1/leaky_re_lu_21/LeakyRelu/LeakyReluGradh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€à@€HH€PXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€à@€HH€PXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€à@€HH€PXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
½
ávoid gemmk1_kernel<float2, 256, 5, true, false, false, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28€à@€pH€pXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
ç
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€à@€PH€Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
à
Švoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€à@€àH€àb9functional_1/up_sampling2d_3/resize/ResizeNearestNeighborh
•
»void DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€Ø@€hH€pXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
Ñ
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ø@€0H€8Xbfunctional_1/conv2d_23/Conv2Dh
ó
—void DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28€Ø@€0H€8Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€Ø@€ØH€Øb>gradient_tape/functional_1/leaky_re_lu/LeakyRelu/LeakyReluGradh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€Ø@€ØH€ØbAgradient_tape/functional_1/leaky_re_lu_19/LeakyRelu/LeakyReluGradh
Ó
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€Ø@€ØH€ØbAgradient_tape/functional_1/leaky_re_lu_20/LeakyRelu/LeakyReluGradh
¹
Üvoid cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28€Ø@€ØH€ØXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
à
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ø@€HH€HXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ø@€HH€HXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ø@€HH€HXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ø@€HH€HXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ø@€HH€HXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ø@€HH€HXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
È
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ø@€hH€pXbfunctional_1/conv2d_13/Conv2Dh
ç
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€Ø@€PH€ˆXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
ú
’void tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€Ø@€ØH€ØbKgradient_tape/functional_1/up_sampling2d_3/resize/ResizeNearestNeighborGradh
â
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ğ@€@H€HXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€Ğ@€@H€HXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
Í
“void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)*28€Ğ@€H€ Xbfunctional_1/conv2d_23/Conv2Dh
È
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ğ@€hH€hXbfunctional_1/conv2d_14/Conv2Dh
È
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ğ@€hH€hXbfunctional_1/conv2d_15/Conv2Dh
Ç
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ğ@€hH€hXbfunctional_1/conv2d_5/Conv2Dh
ê
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ğ@€hH€hXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
é
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€Ğ@€hH€hXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Ø
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€Ğ@€hH€hXbfunctional_1/conv2d_18/Conv2Dh
§
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€Ğ@€ĞH€ĞXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
’
ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€È@€ÈH€ÈbAddN_5h
Ù
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€È@€8H€HXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28€È@€ÈH€ÈXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10>(cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10::Params)*28€È@€ÈH€ÈXbfunctional_1/conv2d_12/Conv2Dh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10>(cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10::Params)*28€È@€ÈH€ÈXbfunctional_1/conv2d_13/Conv2Dh
Ë
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10>(cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10::Params)*28€È@€ÈH€ÈXbfunctional_1/conv2d_8/Conv2Dh
Ç
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€È@€`H€hXbfunctional_1/conv2d_4/Conv2Dh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€È@€`H€hXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€È@€`H€hXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
×
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€È@€`H€hXbfunctional_1/conv2d_3/Conv2Dh

Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€È@€`H€hXbfunctional_1/conv2d_12/Conv2Dh
ç
­void gemv2N_kernel<int, int, float2, float2, float2, 128, 1, 4, 4, 1, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>)*28€È@€H€ Xbfunctional_1/conv2d_23/Conv2Dh
§
Évoid tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28€È@€ÈH€ÈXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
÷
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€È@€ÈH€Èb%Adam/Adam/update_18/ResourceApplyAdamh
õ
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€À@€`H€`Xbfunctional_1/conv2d_23/Conv2Dh
—
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€À@€`H€`Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Ø
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€À@€@H€@Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
Û
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€À@€8H€HXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
Ú
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€À@€@H€@Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ˆ
ªvoid cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28€À@€ÀH€ÀXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
Ì
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€À@€ÀH€ÀXbfunctional_1/conv2d_15/Conv2Dh
Ë
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€À@€ÀH€ÀXbfunctional_1/conv2d_5/Conv2Dh
Ë
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10>(cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10::Params)*28€À@€ÀH€ÀXbfunctional_1/conv2d_7/Conv2Dh
ï
“void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)*28€À@€H€Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
µ
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€À@€0H€0Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
€
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€À@€`H€`Xbfunctional_1/conv2d_7/Conv2Dh
½
ávoid gemmk1_kernel<float2, 256, 5, false, false, true, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28€À@€H€Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
˜
»void DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28€¸@€XH€`Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
¢
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28€¸@€¸H€¸Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Ù
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¸@€8H€@Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
Ø
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€¸@€0H€HXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
Û
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€¸@€8H€@Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
»
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€°@€XH€XXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€°@€XH€XXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
½
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€°@€XH€XXbfunctional_1/conv2d_11/Conv2Dh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€°@€XH€XXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
Ú
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€°@€8H€@Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ø
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€XH€XXbfunctional_1/conv2d_8/Conv2Dh
ü
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€°@€XH€XXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€°@€ H€Xbfunctional_1/conv2d_16/Conv2Dh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€°@€ H€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€°@€ H€Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€°@€H€˜Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
ï
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€°@€H€ Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
ç
«void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28€¨@€PH€Xb!functional_1/concatenate_2/concath
ß
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€¨@€PH€XXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€¨@€PH€XXbfunctional_1/conv2d_6/Conv2Dh
µ
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28€¨@€ H€0Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€¨@€H€Xbfunctional_1/conv2d_17/Conv2Dh
‚
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€¨@€¨H€¨Xbfunctional_1/conv2d_16/Conv2Dh
¥
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€¨@€¨H€¨Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Ì
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€¨@€H€ Xbfunctional_1/conv2d_23/Conv2Dh
·
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€PH€PXbfunctional_1/conv2d_4/Conv2Dh
·
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€PH€PXbfunctional_1/conv2d_7/Conv2Dh
Ú
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€PH€PXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Ú
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€PH€PXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Ù
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ @€PH€PXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€ @€PH€PXbfunctional_1/conv2d_8/Conv2Dh
½
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€ @€PH€PXbfunctional_1/conv2d_22/Conv2Dh
¦
Ëvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28€ @€PH€PXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
é
void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€ @€PH€PXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€ @€PH€PXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
î
’void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28€ @€H€ Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€˜@€˜H€˜b"functional_1/leaky_re_lu/LeakyReluh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€˜@€˜H€˜b%functional_1/leaky_re_lu_19/LeakyReluh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€˜@€˜H€˜b%functional_1/leaky_re_lu_20/LeakyReluh
·
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€˜@€˜H€˜b%functional_1/leaky_re_lu_21/LeakyReluh
ş
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€˜@€˜H€˜b0gradient_tape/functional_1/concatenate_3/Slice_1h
¸
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€˜@€HH€PXbfunctional_1/conv2d_12/Conv2Dh
Ú
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€˜@€HH€PXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
Ù
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€˜@€HH€PXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€HH€PXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
×
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€HH€PXbfunctional_1/conv2d_2/Conv2Dh
Ø
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€˜@€HH€PXbfunctional_1/conv2d_20/Conv2Dh
¤
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€˜@€˜H€˜Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¶
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b$functional_1/leaky_re_lu_1/LeakyReluh
ü
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b.gradient_tape/functional_1/concatenate_3/Sliceh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€@€0H€0Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
·
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@€(H€8Xbfunctional_1/conv2d_11/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@€(H€8Xbfunctional_1/conv2d_8/Conv2Dh
Ø
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@€0H€0Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
Û
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€@€HH€HXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€@€HH€HXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
Ø
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€@€HH€HXbfunctional_1/conv2d_19/Conv2Dh
æ
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
ı
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€b8AddN_5-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
”
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bOfunctional_1/conv2d_1/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bPfunctional_1/conv2d_19/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
§
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bbgradient_tape/functional_1/concatenate_3/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€blgradient_tape/functional_1/max_pooling2d/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€ˆ@€(H€0Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Ù
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€ˆ@€(H€0Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Ø
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€ˆ@€(H€0Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
ã
†void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28€ˆ@€@H€HXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
²
øvoid explicit_convolve_sgemm<float, int, 128, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28€ˆ@€@H€HXbfunctional_1/conv2d_23/Conv2Dh
Å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ˆ@€ˆH€ˆXbfunctional_1/conv2d_19/Conv2Dh
Å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ˆ@€ˆH€ˆXbfunctional_1/conv2d_20/Conv2Dh
ç
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ˆ@€ˆH€ˆXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
¯
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€ˆ@€ˆH€ˆb7gradient_tape/functional_1/conv2d_1/BiasAdd/BiasAddGradh
“
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€ˆ@€ˆH€ˆbfunctional_1/conv2d_19/BiasAddh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbMfunctional_1/conv2d/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbPfunctional_1/conv2d_20/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
•
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbPfunctional_1/conv2d_21/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbmgradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
´
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbogradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbngradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbqgradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbqgradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
µ
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ˆ@€ˆH€ˆbpgradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€€@€(H€0Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
¶
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€€@€ H€ Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
½
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€@H€@Xbfunctional_1/conv2d_12/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€@H€@Xbfunctional_1/conv2d_7/Conv2Dh
ß
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€@H€@Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€@H€@Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€€@€@H€@Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
Ù
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€€@€(H€0Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
Û
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€€@€(H€0Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
Û
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€€@€(H€0Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
Ú
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€€@€(H€0Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
Á
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€€@€@H€@Xbfunctional_1/conv2d_9/Conv2Dh
û
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€@H€@Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
×
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€@H€@Xbfunctional_1/conv2d_1/Conv2Dh
Ø
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€€@€@H€@Xbfunctional_1/conv2d_22/Conv2Dh
æ
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€€@€0H€PXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€€@€€H€€b5gradient_tape/functional_1/conv2d/BiasAdd/BiasAddGradh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€€@€€H€€b8gradient_tape/functional_1/conv2d_19/BiasAdd/BiasAddGradh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€€@€€H€€b8gradient_tape/functional_1/conv2d_20/BiasAdd/BiasAddGradh
°
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€€@€€H€€b8gradient_tape/functional_1/conv2d_21/BiasAdd/BiasAddGradh
÷
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€€@€€H€€b%Adam/Adam/update_22/ResourceApplyAdamh
¶
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€€@€€H€€bqgradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
™
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€x@€H€ Xbfunctional_1/conv2d_23/Conv2Dh
»
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€x@€8H€@Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
Ù
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€x@€(H€(Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
ù
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€x@€8H€@Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
ú
Ÿvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€x@€8H€@Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
Ô
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€x@€8H€@Xbfunctional_1/conv2d/Conv2Dh
×
void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28€x@€8H€@Xbfunctional_1/conv2d_21/Conv2Dh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€x@€0H€HXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€x@€ H€XXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€x@€ H€XXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€x@€ H€XXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
İ
Švoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€x@€xH€xb9functional_1/up_sampling2d_2/resize/ResizeNearestNeighborh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€x@€xH€xbfunctional_1/conv2d_1/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€x@€xH€xbfunctional_1/conv2d_20/BiasAddh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€x@€xH€xbpgradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¼
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€p@€H€ Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
‘
¹void cudnn::pooling_bw_kernel_max_nchw_fully_packed_large<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28€p@€pH€pb>gradient_tape/functional_1/max_pooling2d_1/MaxPool/MaxPoolGradh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€p@€ H€(Xbfunctional_1/conv2d_12/Conv2Dh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€p@€8H€8Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¶
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€p@€8H€8Xbfunctional_1/conv2d_9/Conv2Dh
Ø
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€p@€8H€8Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€p@€8H€8Xbfunctional_1/conv2d_11/Conv2Dh
×
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€p@€ H€(Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
È
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28€p@€pH€pXbfunctional_1/conv2d_4/Conv2Dh
È
void cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10>(cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10::Params)*28€p@€pH€pXbfunctional_1/conv2d_6/Conv2Dh
À
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€p@€8H€8Xbfunctional_1/conv2d_8/Conv2Dh
â
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€p@€8H€8Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
€
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€p@€8H€8Xbfunctional_1/conv2d_13/Conv2Dh
€
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€p@€8H€8Xbfunctional_1/conv2d_14/Conv2Dh

Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€p@€8H€8Xbfunctional_1/conv2d_6/Conv2Dh
Â
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€p@€H€XXbfunctional_1/conv2d_13/Conv2Dh
Â
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€p@€ H€PXbfunctional_1/conv2d_14/Conv2Dh
Â
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€p@€ H€PXbfunctional_1/conv2d_18/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€p@€ H€PXbfunctional_1/conv2d_3/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€p@€ H€PXbfunctional_1/conv2d_9/Conv2Dh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€p@€H€XXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
÷
’void tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€p@€pH€pbKgradient_tape/functional_1/up_sampling2d_2/resize/ResizeNearestNeighborGradh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€p@€pH€pbfunctional_1/conv2d/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€p@€pH€pbfunctional_1/conv2d_21/BiasAddh
»
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€h@€H€ Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
›
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€h@€0H€8Xbfunctional_1/conv2d_22/Conv2Dh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€h@€hH€hbAgradient_tape/functional_1/leaky_re_lu_18/LeakyRelu/LeakyReluGradh
Æ
void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28€h@€0H€8Xbfunctional_1/conv2d_23/Conv2Dh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€h@€H€ Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€h@€0H€8Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€h@€ H€(Xbfunctional_1/conv2d_7/Conv2Dh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€h@€H€(Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€h@€ H€(Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
Ø
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€h@€0H€8Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
Â
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€h@€0H€8Xbfunctional_1/conv2d_10/Conv2Dh
Â
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€h@€0H€8Xbfunctional_1/conv2d_11/Conv2Dh
ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€h@€H€PXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€h@€0H€8Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€h@€hH€hXbfunctional_1/conv2d_9/Conv2Dh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€`@€`H€`bAgradient_tape/functional_1/leaky_re_lu_17/LeakyRelu/LeakyReluGradh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€`@€H€Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€`@€0H€0Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€`@€H€Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€`@€H€Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
´
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€`@€0H€0Xbfunctional_1/conv2d/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€`@€0H€0Xbfunctional_1/conv2d_12/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€`@€0H€0Xbfunctional_1/conv2d_7/Conv2Dh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€`@€0H€0Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€`@€0H€0Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€`@€0H€0Xbfunctional_1/conv2d_8/Conv2Dh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€`@€0H€0Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€`@€(H€8Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€`@€`H€`b%Adam/Adam/update_16/ResourceApplyAdamh
¢
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€`@€`H€`Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€`@€`H€`Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€`@€`H€`Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh

ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€X@€XH€XbAddN_4h
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€X@€XH€XbAgradient_tape/functional_1/leaky_re_lu_16/LeakyRelu/LeakyReluGradh
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€X@€XH€Xb@gradient_tape/functional_1/leaky_re_lu_2/LeakyRelu/LeakyReluGradh
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€X@€XH€Xb@gradient_tape/functional_1/leaky_re_lu_3/LeakyRelu/LeakyReluGradh
ù
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€X@€XH€Xb.gradient_tape/functional_1/concatenate_2/Sliceh
û
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€X@€XH€Xb0gradient_tape/functional_1/concatenate_2/Slice_1h
æ
«void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28€X@€(H€0b!functional_1/concatenate_1/concath
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€X@€H€ Xbfunctional_1/conv2d_6/Conv2Dh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€X@€H€ Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
¶
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€X@€(H€0Xbfunctional_1/conv2d_6/Conv2Dh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€X@€(H€0Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€X@€ H€8Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€X@€ H€8Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€P@€H€ Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€P@€H€ Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€P@€H€Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€P@€H€Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€P@€H€ Xbfunctional_1/conv2d_14/Conv2Dh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€P@€H€ Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€P@€H€ Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€P@€H€ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€P@€(H€(Xbfunctional_1/conv2d_6/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€P@€(H€(Xbfunctional_1/conv2d_9/Conv2Dh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€P@€(H€(Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€P@€(H€(Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
â
ˆvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28€P@€(H€(Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
€
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€P@€(H€(Xbfunctional_1/conv2d_15/Conv2Dh

Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€P@€(H€(Xbfunctional_1/conv2d_5/Conv2Dh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€P@€(H€(Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€P@€(H€(Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€P@€(H€(Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
¢
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€P@€(H€(Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
¢
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€P@€(H€(Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
Â
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€P@€ H€0Xbfunctional_1/conv2d_15/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€P@€H€8Xbfunctional_1/conv2d_5/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€P@€(H€(Xbfunctional_1/conv2d_7/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€P@€ H€0Xbfunctional_1/conv2d_8/Conv2Dh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€P@€ H€0Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€P@€ H€0Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€P@€ H€0Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ã
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€P@€ H€0Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€P@€(H€(Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
Í
‘void pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€P@€PH€Pb"functional_1/max_pooling2d/MaxPoolh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€H@€H€Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€H@€H€Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€H@€H€Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_15/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_17/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_18/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_2/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_20/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_21/Conv2Dh
¶
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_22/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xbfunctional_1/conv2d_3/Conv2Dh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
×
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€H@€H€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€H@€ H€(Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Â
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€H@€ H€(Xbfunctional_1/conv2d_12/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€H@€H€0Xbfunctional_1/conv2d_2/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€H@€ H€(Xbfunctional_1/conv2d_4/Conv2Dh
Á
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€H@€ H€(Xbfunctional_1/conv2d_6/Conv2Dh
å
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€H@€ H€(Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€H@€H€0Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
ä
‰void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€H@€ H€(Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
÷
’void tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€H@€HH€HbKgradient_tape/functional_1/up_sampling2d_1/resize/ResizeNearestNeighborGradh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€H@€HH€Hb8gradient_tape/functional_1/conv2d_16/BiasAdd/BiasAddGradh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€H@€HH€Hb8gradient_tape/functional_1/conv2d_17/BiasAdd/BiasAddGradh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€H@€HH€Hb8gradient_tape/functional_1/conv2d_18/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€H@€HH€Hb7gradient_tape/functional_1/conv2d_2/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€H@€HH€Hb7gradient_tape/functional_1/conv2d_3/BiasAdd/BiasAddGradh
ÿ
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€H@€HH€HXbfunctional_1/conv2d_13/Conv2Dh
¡
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€H@€HH€HXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
»
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Ÿ
Ävoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28€@@€@H€@Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€@@€ H€ Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@@€H€Xbfunctional_1/conv2d_1/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@@€H€Xbfunctional_1/conv2d_4/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@@€H€Xbfunctional_1/conv2d_5/Conv2Dh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@@€H€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€@@€H€Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
¶
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@@€ H€ Xbfunctional_1/conv2d_8/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€@@€ H€ Xbfunctional_1/conv2d_14/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€@@€ H€ Xbfunctional_1/conv2d_15/Conv2Dh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€@@€ H€ Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28€@@€ H€ Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
×
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
×
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
Ù
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Ù
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
 
hvoid fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)*28€@@€ H€ Xbfunctional_1/conv2d_23/Conv2Dh
¢
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
¢
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€@@€ H€ Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
İ
Švoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€@@€@H€@b9functional_1/up_sampling2d_1/resize/ResizeNearestNeighborh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@@€@H€@b%Adam/Adam/update_14/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@@€@H€@b%Adam/Adam/update_20/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@@€@H€@b%Adam/Adam/update_24/ResourceApplyAdamh
¢
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€@@€@H€@Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xbfunctional_1/conv2d_11/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xbfunctional_1/conv2d_8/Conv2Dh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@@€@H€@Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@@€@H€@bpgradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€8@€H€Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
™
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€8@€H€ Xbfunctional_1/conv2d_23/Conv2Dh
¼
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28€8@€H€ Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8b%functional_1/leaky_re_lu_16/LeakyReluh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8b%functional_1/leaky_re_lu_18/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8b$functional_1/leaky_re_lu_3/LeakyReluh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€8@€8H€8bAgradient_tape/functional_1/leaky_re_lu_15/LeakyRelu/LeakyReluGradh
°
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€8@€8H€8b<gradient_tape/functional_1/max_pooling2d/MaxPool/MaxPoolGradh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€8@€H€ Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Ø
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€8@€H€Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_1/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_17/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_18/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_4/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xbfunctional_1/conv2d_5/Conv2Dh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€8@€H€ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€8@€8H€8b8gradient_tape/functional_1/conv2d_14/BiasAdd/BiasAddGradh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€8@€8H€8b8gradient_tape/functional_1/conv2d_15/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€8@€8H€8b7gradient_tape/functional_1/conv2d_4/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€8@€8H€8b7gradient_tape/functional_1/conv2d_5/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€8@€8H€8b7gradient_tape/functional_1/conv2d_9/BiasAdd/BiasAddGradh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€8@€8H€8bfunctional_1/conv2d_17/BiasAddh
ÿ
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€8@€8H€8Xbfunctional_1/conv2d_10/Conv2Dh
ú
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€8@€8H€8b8AddN_4-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
¤
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€8@€8H€8bbgradient_tape/functional_1/concatenate_2/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€8@€8H€8bqgradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€8@€8H€8bpgradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
°
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€8@€8H€8bngradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
©
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€0@€H€Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
¨
Ncask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
®
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€0@€H€Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
­
Scask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh

ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€0@€0H€0bAddN_3h
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€0@€0H€0b%functional_1/leaky_re_lu_17/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€0@€0H€0b$functional_1/leaky_re_lu_2/LeakyReluh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€0@€0H€0bAgradient_tape/functional_1/leaky_re_lu_13/LeakyRelu/LeakyReluGradh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€0@€0H€0bAgradient_tape/functional_1/leaky_re_lu_14/LeakyRelu/LeakyReluGradh
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€0@€0H€0b@gradient_tape/functional_1/leaky_re_lu_4/LeakyRelu/LeakyReluGradh
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€0@€0H€0b@gradient_tape/functional_1/leaky_re_lu_5/LeakyRelu/LeakyReluGradh
û
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€0@€0H€0b0gradient_tape/functional_1/concatenate_1/Slice_1h
ä
«void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28€0@€H€bfunctional_1/concatenate/concath
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€0@€0H€0b8gradient_tape/functional_1/conv2d_21/BiasAdd/BiasAddGradh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€0@€H€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
´
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28€0@€H€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Œ
´void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€0@€0H€0b>gradient_tape/functional_1/max_pooling2d_2/MaxPool/MaxPoolGradh
Œ
´void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€0@€0H€0b>gradient_tape/functional_1/max_pooling2d_3/MaxPool/MaxPoolGradh
¹
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d_2/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d_20/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d_21/Conv2Dh
»
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xbfunctional_1/conv2d_3/Conv2Dh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
İ
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€0@€H€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Å
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€0@€0H€0Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh

Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28€0@€H€Xbfunctional_1/conv2d_4/Conv2Dh
Â
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€0@€0H€0Xbfunctional_1/conv2d_17/Conv2Dh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€0@€0H€0Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€0@€0H€0Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
õ
’void tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€0@€0H€0bIgradient_tape/functional_1/up_sampling2d/resize/ResizeNearestNeighborGradh
Û
Švoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28€0@€0H€0b7functional_1/up_sampling2d/resize/ResizeNearestNeighborh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€0@€0H€0b8gradient_tape/functional_1/conv2d_11/BiasAdd/BiasAddGradh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€0@€0H€0b8gradient_tape/functional_1/conv2d_12/BiasAdd/BiasAddGradh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€0@€0H€0b8gradient_tape/functional_1/conv2d_13/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€0@€0H€0b7gradient_tape/functional_1/conv2d_7/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€0@€0H€0b7gradient_tape/functional_1/conv2d_8/BiasAdd/BiasAddGradh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€0@€0H€0bfunctional_1/conv2d_16/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€0@€0H€0bfunctional_1/conv2d_18/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€0@€0H€0bfunctional_1/conv2d_2/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€0@€0H€0bfunctional_1/conv2d_3/BiasAddh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€0@€0H€0b%Adam/Adam/update_12/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€0@€0H€0b%Adam/Adam/update_28/ResourceApplyAdamh
¡
Ævoid tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28€0@€0H€0Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xbfunctional_1/conv2d_12/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xbfunctional_1/conv2d_7/Conv2Dh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€0@€0H€0Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bPfunctional_1/conv2d_17/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bPfunctional_1/conv2d_18/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bOfunctional_1/conv2d_2/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bpgradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bpgradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bpgradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bpgradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bpgradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bqgradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bogradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
°
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€0@€0H€0bngradient_tape/functional_1/max_pooling2d_1/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€(@€(H€(bAgradient_tape/functional_1/leaky_re_lu_11/LeakyRelu/LeakyReluGradh
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€(@€(H€(b@gradient_tape/functional_1/leaky_re_lu_6/LeakyRelu/LeakyReluGradh
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€(@€(H€(b@gradient_tape/functional_1/leaky_re_lu_7/LeakyRelu/LeakyReluGradh
Ê
ƒvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 3ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 3ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€(@€(H€(b-gradient_tape/huber_loss/weighted_loss/Tile_1h
ù
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€(@€(H€(b.gradient_tape/functional_1/concatenate/Slice_1h
ù
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€(@€(H€(b.gradient_tape/functional_1/concatenate_1/Sliceh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€(@€(H€(b8gradient_tape/functional_1/conv2d_20/BiasAdd/BiasAddGradh
³
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28€(@€H€Xbfunctional_1/conv2d/Conv2Dh
¼
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€(@€H€Xbfunctional_1/conv2d_22/Conv2Dh
Ş
ƒvoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28€(@€H€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Å
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€(@€(H€(Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
Â
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€(@€(H€(Xbfunctional_1/conv2d_16/Conv2Dh
Â
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€(@€(H€(Xbfunctional_1/conv2d_18/Conv2Dh
Á
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€(@€(H€(Xbfunctional_1/conv2d_2/Conv2Dh
Á
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€(@€(H€(Xbfunctional_1/conv2d_3/Conv2Dh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€(@€(H€(Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€(@€(H€(Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ã
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€(@€(H€(Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Ï
‘void pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€(@€(H€(b$functional_1/max_pooling2d_1/MaxPoolh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€(@€(H€(b8gradient_tape/functional_1/conv2d_10/BiasAdd/BiasAddGradh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€(@€(H€(b8gradient_tape/functional_1/conv2d_22/BiasAdd/BiasAddGradh
¬
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€(@€(H€(b7gradient_tape/functional_1/conv2d_6/BiasAdd/BiasAddGradh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€(@€(H€(bfunctional_1/conv2d_13/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€(@€(H€(bfunctional_1/conv2d_15/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€(@€(H€(bfunctional_1/conv2d_4/BiasAddh

,void tensorflow::SetZero<float>(int, float*)*28€(@€(H€(bKgradient_tape/functional_1/up_sampling2d_3/resize/ResizeNearestNeighborGradh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€(@€(H€(b%Adam/Adam/update_40/ResourceApplyAdamh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xbfunctional_1/conv2d_10/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xbfunctional_1/conv2d_14/Conv2Dh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€(@€(H€(Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
´
ªvoid tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bpgradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
´
ªvoid tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bpgradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
”
ªvoid tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 2, 1024, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bPfunctional_1/conv2d_22/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
µ
ªvoid tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 2, 1024, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bqgradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bPfunctional_1/conv2d_16/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bOfunctional_1/conv2d_3/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bqgradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
°
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€(@€(H€(bngradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh

ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ bAddN_2h
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b%functional_1/leaky_re_lu_13/LeakyReluh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b%functional_1/leaky_re_lu_14/LeakyReluh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b%functional_1/leaky_re_lu_15/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b$functional_1/leaky_re_lu_4/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b$functional_1/leaky_re_lu_5/LeakyReluh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ bAgradient_tape/functional_1/leaky_re_lu_10/LeakyRelu/LeakyReluGradh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ bAgradient_tape/functional_1/leaky_re_lu_12/LeakyRelu/LeakyReluGradh
Ğ
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ bAgradient_tape/functional_1/leaky_re_lu_22/LeakyRelu/LeakyReluGradh
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€ @€ H€ b@gradient_tape/functional_1/leaky_re_lu_8/LeakyRelu/LeakyReluGradh
÷
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€ @€ H€ b,gradient_tape/functional_1/concatenate/Sliceh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€ @€ H€ b8gradient_tape/functional_1/conv2d_15/BiasAdd/BiasAddGradh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€ @€ H€ b8gradient_tape/functional_1/conv2d_17/BiasAdd/BiasAddGradh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€ @€ H€ b8gradient_tape/functional_1/conv2d_18/BiasAdd/BiasAddGradh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€ @€ H€ b8gradient_tape/functional_1/conv2d_22/BiasAdd/BiasAddGradh
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€ @€ H€ b8gradient_tape/functional_1/conv2d_23/BiasAdd/BiasAddGradh
Å
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Å
évoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
Â
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xbfunctional_1/conv2d_13/Conv2Dh
Á
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xbfunctional_1/conv2d_4/Conv2Dh
Á
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xbfunctional_1/conv2d_5/Conv2Dh
Á
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xbfunctional_1/conv2d_6/Conv2Dh
Á
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xbfunctional_1/conv2d_7/Conv2Dh
Á
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xbfunctional_1/conv2d_8/Conv2Dh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
ã
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
ã
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€ @€ H€ Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
Ï
‘void pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€ @€ H€ b$functional_1/max_pooling2d_2/MaxPoolh
Ï
‘void pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€ @€ H€ b$functional_1/max_pooling2d_3/MaxPoolh
ë
«void tensorflow::(anonymous namespace)::DynamicStitchKernel<int>(int, int, tensorflow::GpuDeviceArrayStruct<int, 8>, tensorflow::GpuDeviceArrayStruct<int const*, 8>, int*)*28€ @€ H€ b&gradient_tape/huber_loss/DynamicStitchh
­
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28€ @€ H€ b8gradient_tape/functional_1/conv2d_23/BiasAdd/BiasAddGradh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€ @€ H€ bfunctional_1/conv2d_10/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€ @€ H€ bfunctional_1/conv2d_12/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€ @€ H€ bfunctional_1/conv2d_14/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€ @€ H€ bfunctional_1/conv2d_22/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€ @€ H€ bfunctional_1/conv2d_5/BiasAddh

,void tensorflow::SetZero<float>(int, float*)*28€ @€ H€ bKgradient_tape/functional_1/up_sampling2d_2/resize/ResizeNearestNeighborGradh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_10/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b$Adam/Adam/update_2/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_23/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_26/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_29/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b$Adam/Adam/update_3/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_30/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_32/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_34/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_36/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_37/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_38/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_39/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b$Adam/Adam/update_4/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_42/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_43/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_44/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b%Adam/Adam/update_46/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b$Adam/Adam/update_6/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€ @€ H€ b$Adam/Adam/update_8/ResourceApplyAdamh
Á
îvoid tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)*28€ @€ H€ b9functional_1/dropout/dropout/random_uniform/RandomUniformh
Ã
îvoid tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)*28€ @€ H€ b;functional_1/dropout_1/dropout/random_uniform/RandomUniformh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_17/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_18/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_21/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_4/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xbfunctional_1/conv2d_6/Conv2Dh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€ @€ H€ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
ú
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ b8AddN_3-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bPfunctional_1/conv2d_10/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bPfunctional_1/conv2d_13/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bPfunctional_1/conv2d_14/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bPfunctional_1/conv2d_15/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bOfunctional_1/conv2d_4/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bOfunctional_1/conv2d_5/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bOfunctional_1/conv2d_6/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bOfunctional_1/conv2d_7/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
¤
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bbgradient_tape/functional_1/concatenate_1/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bqgradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
°
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bngradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bogradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bogradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bpgradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
°
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€ @€ H€ bngradient_tape/functional_1/max_pooling2d_2/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
œ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
›
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
›
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
›
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
›
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
¸
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b)functional_1/dropout/dropout/GreaterEqualh
º
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b+functional_1/dropout_1/dropout/GreaterEqualh
«
ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::less_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::less_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b"gradient_tape/huber_loss/LessEqualh
ë
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bdiv_no_nan_2h
–
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b7gradient_tape/huber_loss/weighted_loss/value/div_no_nanh
ı
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bhuber_loss/weighted_loss/valueh
‹
ávoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bhuber_loss/Sub_1h
ş
ávoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bsubh
õ
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAdam/Powh
ø
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bMulh
—
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b"functional_1/dropout/dropout/Mul_1h
™
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b$functional_1/dropout_1/dropout/Mul_1h
¥
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b0gradient_tape/functional_1/dropout/dropout/Mul_1h
•
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b gradient_tape/huber_loss/Abs/mulh
“
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bgradient_tape/huber_loss/Mul_2h

Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bl2_normalizeh
ƒ
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bl2_normalize_1h
ú
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bmul_1h
û
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bhuber_loss/Addh
 
Ùvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_tanh_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_tanh_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b-gradient_tape/functional_1/conv2d_23/TanhGradh
Ç
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b functional_1/dropout/dropout/Mulh
É
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b"functional_1/dropout_1/dropout/Mulh
Õ
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b.gradient_tape/functional_1/dropout/dropout/Mulh
Ù
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b2gradient_tape/functional_1/dropout_1/dropout/Mul_1h
µ
‡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bl2_normalize/Maximumh
³
‡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_min_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_min_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bhuber_loss/Minimumh
¹
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bhuber_loss/Mul_1h
Ë
‘void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_quotient_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_quotient_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b gradient_tape/huber_loss/truedivh
Á
•void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bl2_normalize/Rsqrth
Ã
•void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bl2_normalize_1/Rsqrth
Ü
¡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_sign_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_sign_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b!gradient_tape/huber_loss/Abs/Signh
Ä
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bl2_normalize/Squareh
È
“void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bfunctional_1/conv2d_23/Tanhh
Ì
Õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b]functional_1/dropout/dropout/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Casth

Õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b!functional_1/dropout/dropout/Casth
’
Õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b#functional_1/dropout_1/dropout/Casth
‚
ßvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b	Adam/Casth

ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAddN_1h
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_5h
İ	
¿	void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAddNh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b%functional_1/leaky_re_lu_10/LeakyReluh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b%functional_1/leaky_re_lu_11/LeakyReluh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b%functional_1/leaky_re_lu_12/LeakyReluh
´
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b%functional_1/leaky_re_lu_22/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b$functional_1/leaky_re_lu_6/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b$functional_1/leaky_re_lu_7/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b$functional_1/leaky_re_lu_8/LeakyReluh
³
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b$functional_1/leaky_re_lu_9/LeakyReluh
Ï
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b@gradient_tape/functional_1/leaky_re_lu_9/LeakyRelu/LeakyReluGradh
æ

«
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<bool const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<bool const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b!gradient_tape/huber_loss/SelectV2h
Â
‹void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAdam/Adam/AssignAddVariableOph
Ö
„void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28€@€H€b8gradient_tape/functional_1/conv2d_14/BiasAdd/BiasAddGradh
ã
ˆvoid nchwToNhwcKernel<float, float, float, true, true, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Â
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xbfunctional_1/conv2d_12/Conv2Dh
Â
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xbfunctional_1/conv2d_15/Conv2Dh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
å
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
ã
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€@€H€bfunctional_1/conv2d_11/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€@€H€bfunctional_1/conv2d_23/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€@€H€bfunctional_1/conv2d_6/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€@€H€bfunctional_1/conv2d_7/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€@€H€bfunctional_1/conv2d_8/BiasAddh

Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28€@€H€bfunctional_1/conv2d_9/BiasAddh

,void tensorflow::SetZero<float>(int, float*)*28€@€H€bKgradient_tape/functional_1/up_sampling2d_1/resize/ResizeNearestNeighborGradh
ñ
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b"Adam/Adam/update/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b$Adam/Adam/update_1/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_11/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_13/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_15/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_17/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_19/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_21/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_25/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_27/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_31/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_33/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_35/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_41/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_45/ResourceApplyAdamh
ô
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b%Adam/Adam/update_47/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b$Adam/Adam/update_5/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b$Adam/Adam/update_7/ResourceApplyAdamh
ó
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28€@€H€b$Adam/Adam/update_9/ResourceApplyAdamh
á
Âvoid tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28€@€H€bSum_2h
á
Âvoid tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28€@€H€bSum_4h
ø
Âvoid tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28€@€H€bhuber_loss/weighted_loss/Sumh
ä
Åvoid tensorflow::functor::CleanupSegments<float*, float*, tensorflow::functor::Sum<float> >(float*, float*, int, int, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28€@€H€bSum_4h
û
Åvoid tensorflow::functor::CleanupSegments<float*, float*, tensorflow::functor::Sum<float> >(float*, float*, int, int, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28€@€H€bhuber_loss/weighted_loss/Sumh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_11/BiasAdd/BiasAddGradh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_14/BiasAdd/BiasAddGradh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_18/BiasAdd/BiasAddGradh
÷
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b7gradient_tape/functional_1/conv2d_8/BiasAdd/BiasAddGradh
÷
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b7gradient_tape/functional_1/conv2d_9/BiasAdd/BiasAddGradh
„
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_20/BiasAdd/BiasAddGradh
„
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_23/BiasAdd/BiasAddGradh
õ
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_11/BiasAdd/BiasAddGradh
õ
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_12/BiasAdd/BiasAddGradh
ô
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b7gradient_tape/functional_1/conv2d_8/BiasAdd/BiasAddGradh
ô
£void tensorflow::functor::RowReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b7gradient_tape/functional_1/conv2d_9/BiasAdd/BiasAddGradh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_1/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_13/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_15/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_16/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_19/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_2/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_20/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_22/Conv2Dh
¾
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_23/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_3/Conv2Dh
½
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d_5/Conv2Dh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
á
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ß
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
ß
«void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned char, 256, 32, 32, false>(unsigned char const*, tensorflow::functor::Dimension<3>, unsigned char*)*28€@€H€b™gradient_tape/functional_1/dropout/dropout/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_bool_Mul-1-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bPfunctional_1/conv2d_11/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
’
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bPfunctional_1/conv2d_12/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bOfunctional_1/conv2d_8/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‘
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bOfunctional_1/conv2d_9/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
¢
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€b`gradient_tape/functional_1/concatenate/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bpgradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
³
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bqgradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bogradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bogradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bogradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
²
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bpgradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bogradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bogradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bogradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¤
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bbgradient_tape/functional_1/dropout/dropout/Mul_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
°
¨void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28€@€H€bngradient_tape/functional_1/max_pooling2d_3/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh

Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28€@€H€Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
å
Ávoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_boolean_and_op, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_boolean_and_op, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b
LogicalAndh
é
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b
div_no_nanh
ë
Åvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bdiv_no_nan_1h
÷
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b
Adam/Pow_1h
¥
Ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b0gradient_tape/functional_1/dropout_1/dropout/Mulh
Ğ
“void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b#gradient_tape/huber_loss/zeros_likeh
®
‘void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_abs_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_abs_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bAbsh
Ñ
›void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_opposite_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_opposite_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bgradient_tape/huber_loss/Negh
·
‡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bl2_normalize_1/Maximumh
Å
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bgradient_tape/huber_loss/Mulh
è
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€b7huber_loss/ArithmeticOptimizer/ReplaceMulWithSquare_Mulh
Æ
—void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28€@€H€bl2_normalize_1/Squareh
ñ
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bCasth
ó
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bCast_1h
ó
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bCast_2h
Š
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bgradient_tape/huber_loss/Casth
—
Óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€b*huber_loss/weighted_loss/num_elements/Casth

ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOph
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_1h
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_2h
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_3h
’
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_4h

ûvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long, long long>, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long, long long>, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAdam/addh
º
‹void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28€@€H€bAssignAddVariableOp_6h
×
ûvoid nchwAddPaddingKernel<float, float, float, true, (cudnnKernelDataType_t)0>(int, int, int, int, int, int, int, int, float const*, float*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)*28€@€H€Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
ä
‰void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28€@€H€Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh

,void tensorflow::SetZero<float>(int, float*)*28€@€H€bIgradient_tape/functional_1/up_sampling2d/resize/ResizeNearestNeighborGradh
ä
Åvoid tensorflow::functor::CleanupSegments<float*, float*, tensorflow::functor::Sum<float> >(float*, float*, int, int, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28€@€H€bSum_2h
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_12/BiasAdd/BiasAddGradh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_15/BiasAdd/BiasAddGradh
ø
¦void tensorflow::functor::ColumnReduceKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_17/BiasAdd/BiasAddGradh
„
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_21/BiasAdd/BiasAddGradh
„
²void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28€@€H€b8gradient_tape/functional_1/conv2d_22/BiasAdd/BiasAddGradh
»
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xbfunctional_1/conv2d/Conv2Dh
Ş
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
à
…void tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28€@€H€Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh