
…
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ø¬@äà†HãË†Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
«
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28≠‡ß@á†qHá∞qXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
«
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ü®Ó@ÖòRHÖ–RXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
∆
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28†òÌ@ÖàRHÜ∞RXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
∆
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ûà÷@ÖòNHÖ¿NXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
«
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ü‡‘@ÖàNHÜòNXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
ƒ
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ûËÕ@ÖLHÖòMXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
«
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28û»…@ÖòLHÖ∏LXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
›
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28ù†¬@ÖJHÖòKXbfunctional_1/conv2d_11/Conv2Dh
«
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ö‡ë@Ñò9HÑ¿9Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
›
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28î¿¨@ÉÄ2HÑò2Xbfunctional_1/conv2d_10/Conv2Dh
∆
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ë®Ú@Éê(HÉ¯(Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
›
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28éÄ‚@Ç–%HÇ‡%Xbfunctional_1/conv2d_12/Conv2Dh
‹
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28è‡·@Ç»%HÉÿ%Xbfunctional_1/conv2d_7/Conv2Dh
‹
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28éË‘@Ç∏#HÉ¿#Xbfunctional_1/conv2d_3/Conv2Dh
›
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28é»‘@Ç∞#HÇ¿#Xbfunctional_1/conv2d_18/Conv2Dh
∆
Ávoid wgrad2d_grouped_direct_kernel<float, float, float, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28ç∏Õ@Éê"HÇ∞"Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
K
redzone_checker*28éÿº@Ä–HÄ∞Xbfunctional_1/conv2d_20/Conv2Dh2
K
redzone_checker*28ä¿ª@ÄÿHÅ¯Xbfunctional_1/conv2d_14/Conv2Dh2
J
redzone_checker*28å∏ª@ÄÿHÅ¯Xbfunctional_1/conv2d_8/Conv2Dh2
K
redzone_checker*28ä∏ª@Ä–HÄ¯Xbfunctional_1/conv2d_17/Conv2Dh2
J
redzone_checker*28à∞ª@ÄÿHÄ¯Xbfunctional_1/conv2d_4/Conv2Dh2
J
redzone_checker*28âÄª@ÄÿHÄ¯Xbfunctional_1/conv2d_9/Conv2Dh2
K
redzone_checker*28å»•@Ä–HÄ¯Xbfunctional_1/conv2d_18/Conv2Dh,
H
redzone_checker*28ã»•@ÄÿHÅ¯Xbfunctional_1/conv2d/Conv2Dh,
m
redzone_checker*28Ö∞•@Ä–HÄ¯Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh,
J
redzone_checker*28ä†•@ÄÿHÄ¯Xbfunctional_1/conv2d_3/Conv2Dh,
l
redzone_checker*28à†•@Ä–HÄ¯Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh,
l
redzone_checker*28àò•@ÄÿHÄ¯Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh,
m
redzone_checker*28èê•@ÄÿHÄ¯Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh,
K
redzone_checker*28çê•@ÄÿHÄÄXbfunctional_1/conv2d_12/Conv2Dh,
J
redzone_checker*28åê•@ÄÿHÅXbfunctional_1/conv2d_6/Conv2Dh,
l
redzone_checker*28ãê•@Ä–HÄ¯Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh,
J
redzone_checker*28áê•@Ä–HÄ¯Xbfunctional_1/conv2d_2/Conv2Dh,
m
redzone_checker*28âà•@Å–HÄ¯Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh,
J
redzone_checker*28àÄ•@ÄÿHÄ¯Xbfunctional_1/conv2d_7/Conv2Dh,
m
redzone_checker*28â¯§@ÄÿHÅXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh,
K
redzone_checker*28Ö¯§@ÄÿHÄ¯Xbfunctional_1/conv2d_11/Conv2Dh,
l
redzone_checker*28ã§@Å–HÅ¯Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh,
K
redzone_checker*28å»§@Å–HÄ¯Xbfunctional_1/conv2d_22/Conv2Dh,
m
redzone_checker*28ç‡ù@ÄÿHÅ¯Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh*
m
redzone_checker*28ë¿ù@Ä–HÅ¯Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh*
l
redzone_checker*28âÄù@ÄÿHÄ¯Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh*
l
redzone_checker*28ãú@ÄÿHÄXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh*
m
redzone_checker*28å¿ñ@ÄÿHÅ¯Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh(
l
redzone_checker*28å–ï@ÄÿHÅ¯Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh(
v
ampere_sgemm_128x128_nt*28ä∏ê@Éê0HÑò0Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28â®ê@Éà0HÉê0Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
v
ampere_sgemm_128x128_nt*28â®ê@Éà0HÉê0Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
K
redzone_checker*28âêá@ÄÿHÄ¯Xbfunctional_1/conv2d_13/Conv2Dh$
J
redzone_checker*28åË@ÄÿHÅ¯Xbfunctional_1/conv2d_16/Conv2Dh"
J
redzone_checker*28ä»@ÄÿHÅ¯Xbfunctional_1/conv2d_19/Conv2Dh"
‰
Üvoid dgrad2d_grouped_direct_kernel<float, float, float, true, 0, 0, (cudnnTensorFormat_t)0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)*28àÄ{@Ñ¿=HÑ¿=Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
J
redzone_checker*28àw@Ä–HÄ¯Xbfunctional_1/conv2d_23/Conv2Dh 
m
redzone_checker*28ä‡w@ÄÿHÅ¯Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh 
l
redzone_checker*28áÿw@ÄÿHÄ¯Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh 
l
redzone_checker*28áÿw@ÄÿHÄXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh 
l
redzone_checker*28áòw@Ä–HÄXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh 
m
redzone_checker*28àÿv@ÄÿHÅ‡Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh 
€
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28áq@Å¯HÇÄXbfunctional_1/conv2d_6/Conv2Dh
€
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28à»l@ÅàHÅêXbfunctional_1/conv2d_2/Conv2Dh
l
redzone_checker*28áòi@ÄÿHÄ¯Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
J
redzone_checker*28Üòi@ÄÿHÄ¯Xbfunctional_1/conv2d_10/Conv2Dh
j
redzone_checker*28å®h@ÄÿHÄ¯Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28Ö®h@ÄÿHÅËXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28àÄh@ÄÿHÅ‡Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28áÄh@ÄÿHÄËXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28â¯g@ÄÿHÅ‡Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28ág@ÄÿHÅ‡Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28Üg@ÄÿHÅ‡Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28Üÿg@ÄÿHÅ‡Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28Ö»g@Ä–HÅ‡Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28Ö∏g@ÄÿHÅ‡Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28áa@ÄÿHÅ¯Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
l
redzone_checker*28á∏a@ÄÿHÅ¯Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
l
redzone_checker*28Üòa@Ä–HÄXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
u
ampere_sgemm_128x128_nt*28áò`@Ñà0HÉê0Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
l
redzone_checker*28áòZ@ÄÿHÅ¯Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
m
redzone_checker*28Ñ∏Y@ÄÿHÄXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28Ü®Y@ÄÿHÄXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28ÜêY@ÄÿHÅ‡Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28áËX@ÄÿHÄ‡Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
®
…void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Ñ¯N@ÅÿHÅ‡Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
m
redzone_checker*28á¿J@ÄÿHÅ‡Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
û
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ö¯H@Å†HÇ†Xbfunctional_1/conv2d_19/Conv2Dh
û
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ö¯H@Å†HÇòXbfunctional_1/conv2d_20/Conv2Dh

ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28ÖÿC@ÄàHÅÿXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
µ
˘void explicit_convolve_sgemm<float, int, 1024, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Ö†C@Ç–!HÉ–!Xbfunctional_1/conv2d_20/Conv2Dh
À
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28ÖÿB@Çò!HÉ¿!Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
À
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ñ∞B@Ç HÇ¿!Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
À
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ñ»@@ÇHÇÿ Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
À
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ñ®@@ÇHÇ∏ Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
π
€void cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Ñ–?@Ç‡HÇXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
¸
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ÑË=@ÄòHÇ¯Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
¿
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ñ<@ÄòHÇ†Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
¿
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÉË<@ÄòHÅ†Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
ú
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ñÿ<@ÄêHÇòXbfunctional_1/conv2d_16/Conv2Dh
ú
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ñÿ<@ÄòHÇòXbfunctional_1/conv2d_17/Conv2Dh
¸
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ñ®<@ÄhHÅ»Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Ò
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ñ;@ÅÿHÅàXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
Œ
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28É–;@Ä¿HÅàXbfunctional_1/conv2d_14/Conv2Dh
Ò
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ñ»;@Ä¿HÇêXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
¸
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ñò;@ÄhHÄ®Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
Ÿ
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ñê:@ÇàHÇàXbfunctional_1/conv2d_9/Conv2Dh
¥
¯void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Ñ¿8@ÅËHÇXbfunctional_1/conv2d_17/Conv2Dh
®
…void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28É¯7@Ä¿
HÅ‡Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
®
…void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Ñ»7@ÄàHÅòXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
æ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÑË6@ÄòHÇ†Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
æ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÉË6@ÄòHÇ†Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
r
ampere_gcgemm_64x32_nt*28Ñ¯5@Ç¯HÇÄXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
P
ampere_gcgemm_64x32_nt*28Ñ5@Ç¯HÇ¯Xbfunctional_1/conv2d_9/Conv2Dh
ø
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ñ∏1@Ç†HÇòXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
ø
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28É®0@ÇêHÅòXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¡
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ñò0@ÇàHÇêXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
¡
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Éê0@ÅàHÇàXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
º
›void cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28É∞+@É∞+HÉ∞+Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Q
ampere_gcgemm_64x32_nt*28Çê+@ÅòHÅÿXbfunctional_1/conv2d_10/Conv2Dh
⁄
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Éÿ*@ÅòHÅ†Xbfunctional_1/conv2d_10/Conv2Dh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Éÿ*@Å†HÇ∏Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ç»*@Å†HÅ®Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
®
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ç®*@ÅêHÅòXbfunctional_1/conv2d_19/Conv2Dh
®
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Çê*@ÅÄHÅêXbfunctional_1/conv2d_20/Conv2Dh
O
ampere_gcgemm_32x32_nt*28Ö∏)@Ä`HÄxXbfunctional_1/conv2d_19/Conv2Dh2
O
ampere_gcgemm_32x32_nt*28É†)@Ä`HÅpXbfunctional_1/conv2d_20/Conv2Dh2
”
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Éÿ'@ÅHÅ¯Xbfunctional_1/conv2d_20/Conv2Dh
s
ampere_cgemm_32x32_tn*28É–'@ÅòHÅ†Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
”
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28É–'@ÅHÅ¯Xbfunctional_1/conv2d_19/Conv2Dh
¥
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28É&@Å¯HÅÄXbfunctional_1/conv2d_20/Conv2Dh
ö
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Çê&@ÅàHÅàXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
ö
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Çê&@ÅàHÅàXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28Çà%@Ä®HÅ∞Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
ö
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Çà%@Å¿HÅ»Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
u
ampere_sgemm_128x128_nt*28É¯$@Å®HÅ®Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28Ç¯$@Ä®HÅ®Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28Ç¯$@Ä®HÅ®Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
ö
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ç¯$@Å∏HÅ¿Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¡
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ç$@ÄòHÅ†Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
¡
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÅË$@ÄòHÅ†Xb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
P
ampere_cgemm_32x32_tn*28Ç¿$@Å†HÅ†Xbfunctional_1/conv2d_22/Conv2Dh
π
€void cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28É∏$@ÅòHÇ†Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
…
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28ÇÄ$@ÅHÅêXbfunctional_1/conv2d_20/Conv2Dh
µ
˘void explicit_convolve_sgemm<float, int, 1024, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Çÿ#@ÅËHÅXbfunctional_1/conv2d_17/Conv2Dh
ı
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ç∏#@ÄàHÅ®Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28Ç†#@Ä®HÅ¿Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28Éê#@Ä®HÅ¿Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
¥
¯void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28ÇÄ#@ÄÿHÅXbfunctional_1/conv2d_16/Conv2Dh
q
ampere_gcgemm_32x32_nt*28Ç–"@ÄHHÄhXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh2
r
ampere_cgemm_64x32_tn*28Ç∏"@ÅòHÅ†Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Q
ampere_gcgemm_64x32_nt*28Çÿ!@ÄêHÄ®Xbfunctional_1/conv2d_14/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28Ç–!@ÄàHÅ®Xbfunctional_1/conv2d_13/Conv2Dh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ç»!@Å‡HÅËXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
º
›void cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28É†!@É†!HÉ†!Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
q
ampere_gcgemm_32x32_nt*28Åò!@ÄHHÄ`Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh2
€
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ç¯ @ÄòHÅ¯Xbfunctional_1/conv2d_11/Conv2Dh
π
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28É– @Å®HÇ®Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
P
ampere_cgemm_64x32_tn*28Ç» @Å†HÅ®Xbfunctional_1/conv2d_11/Conv2Dh
®
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ç» @Å†HÅ®Xbfunctional_1/conv2d_17/Conv2Dh
®
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28É∏ @ÅòHÇ†Xbfunctional_1/conv2d_16/Conv2Dh
”
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ç∏ @ÅòHÅÄXbfunctional_1/conv2d_16/Conv2Dh
”
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ç∏ @ÄòHÄàXbfunctional_1/conv2d_17/Conv2Dh
P
ampere_cgemm_64x32_tn*28É∞ @ÅàHÇ®Xbfunctional_1/conv2d_14/Conv2Dh
P
ampere_cgemm_64x32_tn*28Ç† @ÅàHÅòXbfunctional_1/conv2d_10/Conv2Dh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ç† @ÅàHÅòXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ı
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Çò @ÄêHÅÄXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
À
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Çê @ÅHÅ†Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
®
…void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Å¯@Ä¯HÅÄXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
Q
ampere_gcgemm_32x32_nt*28ÇË@Å»HÄXbfunctional_1/conv2d_16/Conv2Dh
Q
ampere_gcgemm_32x32_nt*28Ç¿@Ä»HÄXbfunctional_1/conv2d_17/Conv2Dh
π
€void cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Ç¿@Å»HÅ¯Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1*28Å¿@Å∞
HÄ»
Xbfunctional_1/conv2d_20/Conv2Dh
t
ampere_sgemm_128x128_nt*28Ç†@Å–HÅ–Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x32_tn*28ÇÄ@Å∏HÅ»Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x32_tn*28ÇË@Å∞HÅ∏Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
ú
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÇË@ÄòHÅòXbfunctional_1/conv2d_18/Conv2Dh
õ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÇË@ÅòHÅòXbfunctional_1/conv2d_3/Conv2Dh
æ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÇË@ÄòHÅòXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
µ
˘void explicit_convolve_sgemm<float, int, 1024, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28ÇË@Å∞HÅ∏Xbfunctional_1/conv2d_19/Conv2Dh
Ω
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ç‡@ÄòHÅòXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ª
ˇvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 4, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28Çÿ@Å®HÅ∞Xbfunctional_1/conv2d_20/Conv2Dh
s
ampere_cgemm_64x64_tn*28Ç∏@ÅòHÅ†Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
‹
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28Ç∏@ÄàHÄêXbfunctional_1/conv2d_22/Conv2Dh
¸
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ç∏@ÄòHÅÄXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
s
ampere_cgemm_64x64_tn*28Ç®@ÅêHÅòXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Çê@Å¯HÅòXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
À
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ç‡@ÅHÅXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
Ÿ
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ç®@Å–HÅÿXbfunctional_1/conv2d_8/Conv2Dh
s
ampere_cgemm_64x64_tn*28Çê@Å»HÅ»Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
s
ampere_cgemm_64x64_tn*28Çê@Å»HÅ»Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ı
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Çà@Ä†HÅ®Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
⁄
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Çà@Å¿HÅ»Xbfunctional_1/conv2d_11/Conv2Dh
P
ampere_gcgemm_64x32_nt*28Åà@Ä¿HÅ»Xbfunctional_1/conv2d_8/Conv2Dh
s
ampere_gcgemm_64x32_nt*28Ç¯@Å∏HÅ¿Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28Ç¯@Å∏HÅ¿Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
õ
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ç¯@ÄêHÅ∞Xbfunctional_1/conv2d_14/Conv2Dh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28ÅË@Ä∞HÅ∏Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
ı
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ç‡@Ä†HÅêXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
O
ampere_gcgemm_32x32_nt*28Éÿ@ÄHHÄPXbfunctional_1/conv2d_22/Conv2Dh2
õ
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Çÿ@ÄêHÅòXbfunctional_1/conv2d_13/Conv2Dh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Çÿ@Å®HÅ∞Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Q
ampere_gcgemm_64x32_nt*28Ç®@ÅêHÅòXbfunctional_1/conv2d_11/Conv2Dh
r
ampere_gcgemm_64x32_nt*28Ç†@ÅàHÅòXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
®
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Å†@ÄàHÅòXbfunctional_1/conv2d_13/Conv2Dh
Ω
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ç‡@ÄêHÅ‡Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
Ÿ
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äÿ@Ä8HÄPXbfunctional_1/conv2d_19/Conv2Dh2
€
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ç∏@ÅÿHÅ‡Xbfunctional_1/conv2d_10/Conv2Dh
Ω
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Å∞@ÄêHÄ»Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28Éò@Ä∏HÅ»Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
s
ampere_gcgemm_64x32_nt*28Çà@Ä∏HÄ»Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Ÿ
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ÇÄ@Ä8HÄPXbfunctional_1/conv2d_20/Conv2Dh2
ß
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Å–@Ä8HÄPXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh2
™
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Å¿@Ä†HÅ†Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
™
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Çê@ÅàHÅàXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
ß
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ÇÄ@Ä8HÄPXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh2

ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ç¯@ÄxHÅ†Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh	
˚
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å¯@Ä8HÄPXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh2
˚
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ç@Ä8HÅHXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh2
Ì
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Å∞@ÄÿHÅÿXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
Ì
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Ç†@Å–HÅ–Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Éê@Ä8HÅHXbfunctional_1/conv2d_19/Conv2Dh2
Ÿ
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Çà@Ä8HÄPXbfunctional_1/conv2d_22/Conv2Dh2
¿
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÇË@ÄòHÅ†Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
¥
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Ç‡@ÄòHÅòXbfunctional_1/conv2d_19/Conv2Dh
¡
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Åÿ@ÄêHÅòXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
˚
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äÿ@Ä8HÄHXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh2
q
ampere_gcgemm_32x32_nt*28Ç–@Ä8HÅ@Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh2
¥
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Å–@ÄòHÄ†Xbfunctional_1/conv2d_9/Conv2Dh
ˆ
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ç∞@ÄêHÅàXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
æ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ç∞@ÅòHÅòXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
¿
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Å®@ÄêHÅòXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Å®@Ä8HÄHXbfunctional_1/conv2d_20/Conv2Dh2
ø
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ä®@ÄêHÄòXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
ˆ
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ç†@ÅàHÄàXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
¿
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Çò@ÅàHÅêXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
¿
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Çò@ÅàHÅêXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
¡
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Çò@ÅàHÅêXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
ß
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ÇÄ@Ä8HÄHXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh2
t
ampere_sgemm_128x128_nt*28Ç@Å¯HÅ¯Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Ç
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ÅË@Ä0HÄHXbfunctional_1/conv2d/Conv2Dh2
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Åÿ@Ä0HÄHXbfunctional_1/conv2d_22/Conv2Dh2
à>
©=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28Åÿ@ÅÿHÅÿXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
¥
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Å–@ÄòHÄ†Xbfunctional_1/conv2d_14/Conv2Dh
¿
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Åò@ÄhHÅ†Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
ô
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ç@Å∏
HÅ∏
Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
ô
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Å@Ä∏
HÅ∏
Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
Ÿ
†void cudnn::cnn::conv2d_grouped_direct_kernel<float, float, float, float, float, float, true, false, 0, 0, 0>(cudnnTensorStruct, float const*, cudnnFilterStruct, float const*, cudnnConvolutionStruct, cudnnTensorStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int, float const*, float const*, cudnnActivationStruct)*28Ç¿@Ä∞HÅ∏Xbfunctional_1/conv2d/Conv2Dh
r
ampere_gcgemm_64x32_nt*28ÄË@Ä∞HÄ»Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
ô
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ç‡@Å	HÅ	Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ö
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ç‡@Å	HÅ	Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
s
ampere_gcgemm_64x32_nt*28Åÿ@Ä∞HÄ»Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ÿ
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä®@ÄhHÄXbfunctional_1/conv2d_7/Conv2Dh
ö
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ç†@Å–	HÅ–	Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
r
ampere_gcgemm_32x32_nt*28Ä†@ÄÄHÄêXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
r
ampere_gcgemm_32x32_nt*28Äò@ÄxHÄêXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ô
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Äò@Ä»	HÄ–	Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
O
ampere_gcgemm_32x32_nt*28ÄÄ@ÄxHÄêXbfunctional_1/conv2d_3/Conv2Dh
P
ampere_gcgemm_32x32_nt*28Ä¯@ÄxHÄêXbfunctional_1/conv2d_18/Conv2Dh
®
…void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Å@Ä‡HÅËXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
π
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Ç‡@Å∞	HÅ∞	Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Ω
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Çÿ@ÄêHÅòXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ø
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ç–@ÄêHÅ†Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
ø
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ç–@ÄêHÅ†Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
π
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Å»@Å†	HÄ®	Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ß
…void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Ç∏@Ä»HÅ–Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
¢
∆void gemv2T_kernel_val<int, int, float2, float2, float2, 128, 16, 2, 2, false, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>, float2, float2)*28Ç®@Åê	HÅò	Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
ß
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Åò@Åà	HÄê	Xbfunctional_1/conv2d_3/Conv2Dh
®
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Çê@Åà	HÅà	Xbfunctional_1/conv2d_18/Conv2Dh
˚
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Åê@Ä`HÅ‡Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Åê@Äà	HÅà	Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
O
ampere_cgemm_64x32_tn*28Çà@ÅÿHÅ∞	Xbfunctional_1/conv2d_7/Conv2Dh
…
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Åà@Å¯HÄê	Xbfunctional_1/conv2d_19/Conv2Dh
…
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28ÅÄ@ÄÄ	HÅÄ	Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
º
›void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28ÅË@ÅËHÅËXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
q
ampere_cgemm_64x32_tn*28Çÿ@ÅËHÅXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
⁄
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Çÿ@ÄhHÅ†Xbfunctional_1/conv2d_12/Conv2Dh
∫
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Å»@Å‡HÄËXbfunctional_1/conv2d_20/Conv2Dh
Ô
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ç¿@ÄhHÅ®Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
º
ﬁvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28Å∏@Å∏HÅ∏Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_64x32_tn*28Å∞@ÄÿHÅÿXbfunctional_1/conv2d_9/Conv2Dh
P
ampere_cgemm_64x32_tn*28Ä∞@Ä»HÄËXbfunctional_1/conv2d_12/Conv2Dh
ı
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Çê@Ä†HÅ®Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
Ù
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Çê@Ä†HÅ®Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
π
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Åê@Ä»HÅ»Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
∏
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Åê@Å¿HÄ–Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
º
›void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28Åà@ÅàHÅàXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Õ
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Åà@ÄXHÅòXbfunctional_1/conv2d_22/Conv2Dh
”
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ÄÄ@Ä†HÄ†Xbfunctional_1/conv2d_18/Conv2Dh
Ã
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ç¯@ÄHHÄ∞Xbfunctional_1/conv2d_4/Conv2Dh
“
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ç@ÄòHÄ†Xbfunctional_1/conv2d_3/Conv2Dh
ì
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ç@Ä0HÅ∏Xbfunctional_1/conv2d_9/Conv2Dh
…
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Åÿ@Ä®HÅ∞Xbfunctional_1/conv2d_17/Conv2Dh
R
ampere_sgemm_128x128_nn*28Ç¿@Å†HÅ†Xbfunctional_1/conv2d_17/Conv2Dh
·
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Å¿@Ä†HÅ†Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
µ
˘void explicit_convolve_sgemm<float, int, 1024, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Ç∏@ÅòHÅ†Xbfunctional_1/conv2d_16/Conv2Dh
µ
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ä∏@Ä8HÄ‡Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
ˆ
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Å∞@ÄàHÄêXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
ı
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Å®@ÄàHÄêXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ô
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ç†@ÅêHÄXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
÷
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Åê@Ä HÄ0Xbfunctional_1/conv2d/Conv2Dh2
û
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Å–@Ä–HÅòXbfunctional_1/conv2d_22/Conv2Dh
∫
‹void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28Ä–@ÄËHÄËXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
õ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Å»@Ä–HÅêXbfunctional_1/conv2d_2/Conv2Dh
Q
ampere_gcgemm_64x32_nt*28Ç¿@Å‡HÅ‡Xbfunctional_1/conv2d_12/Conv2Dh
P
ampere_gcgemm_64x32_nt*28Å∏@ÅÿHÄ‡Xbfunctional_1/conv2d_7/Conv2Dh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ä∞@Ä¿HÄXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ω
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ç®@ÄêHÅ¿Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
º
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Å®@ÄêHÄ»Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x64_tn*28Äê@Ä»HÄ»Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
p
ampere_gcgemm_32x32_nt*28Åà@Ä`HÄpXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
€
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÅÄ@Ä¯HÄàXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
…
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28ÅÄ@Ä¿HÅ¿Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Ì
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ä¯@ÄHHÄòXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
Ê
àvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28ÇË@Å∞HÅ∏Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
Ÿ
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ÇË@Å∞HÅ∏Xbfunctional_1/conv2d_7/Conv2Dh
⁄
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28ÄË@Ä∞HÄ∏Xbfunctional_1/conv2d_12/Conv2Dh
ı
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Å‡@Ä`HÄòXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
≥
¯void explicit_convolve_sgemm<float, int, 128, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Äÿ@Ä®HÄ∞Xbfunctional_1/conv2d_9/Conv2Dh
à>
©=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<256, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<256, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 128>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<128, 16>, 256, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 3, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<256, 128, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<128, 8, 4, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 8, 1, 1, 8>, 256, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28Å¿@Å¿HÅ¿Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
µ
˘void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Å¿@ÄòHÅ®Xbfunctional_1/conv2d_14/Conv2Dh
r
ampere_gcgemm_32x32_nt*28Å∏@Ä‡HÄXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Å∞@ÄòHÅòXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28ÅÄ@ÄÄHÅÄXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ˆ
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ÅË@Å®HÄ–Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
¢
ƒvoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28Ä»@Ä¿HÄ»Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
Ù
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ç¿@Å–HÅXbfunctional_1/conv2d/Conv2Dh
Ω
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ç∏@ÄHHÅòXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Äò@Ä∞HÄ∏Xbfunctional_1/conv2d_22/Conv2Dh
õ
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Äê@Ä†HÄXbfunctional_1/conv2d/Conv2Dh
π
€void cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Å¯@Ä∏HÅ¿Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
ˆ
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ÄË@ÄêHÄ†Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
ø
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ç‡@ÄòHÅòXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
æ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ä–@ÄêHÄòXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
æ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Å®@ÅêHÄòXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
æ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Å®@ÄêHÅòXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
û
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ç†@ÅêHÅêXbfunctional_1/conv2d_19/Conv2Dh
æ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Å†@ÅàHÄòXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
¿
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Å†@ÄêHÅêXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
û
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Åò@ÅàHÄêXbfunctional_1/conv2d_20/Conv2Dh
≥
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Åò@ÄàHÅàXbfunctional_1/conv2d_8/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28Äò@ÄàHÄàXbfunctional_1/conv2d_17/Conv2Dh
Ã
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28Åê@ÅêHÅêXbfunctional_1/conv2d_20/Conv2Dh
P
ampere_gcgemm_64x32_nt*28Äê@Ä¿HÄ»Xbfunctional_1/conv2d_4/Conv2Dh
N
ampere_gcgemm_32x32_nt*28Äà@ÄHHÄ`Xbfunctional_1/conv2d_2/Conv2Dh
ß
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Ç@Ä@HÅ`Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Ó=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28Å»@Å»HÅ»Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
ß
…void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Å∏@ÄËHÅXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
π
€void cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Å∏@ÄÿHÅ‡Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28Å®@Ä–HÅÿXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Ù
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ä®@Ä†HÄ∞Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ß
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Å†@Ä8HÄ`Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
˜
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ä†@Ä–HÄ–Xbfunctional_1/conv2d_19/Conv2Dh
˜
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Äò@Ä»HÄ–Xbfunctional_1/conv2d_20/Conv2Dh
ô
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Äò@Ä»HÄ–Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28Åê@Ä»HÅ»Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
º
ﬁvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28Åê@Ä»HÅ»Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
ô
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Äê@Ä»HÄ»Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
R
ampere_sgemm_128x128_nn*28Åà@Ä¿HÅ»Xbfunctional_1/conv2d_18/Conv2Dh
ô
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Åà@Å¿HÄ»Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Q
ampere_sgemm_128x128_nn*28Äà@Ä¿HÄ»Xbfunctional_1/conv2d_3/Conv2Dh
ô
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28ÄÄ@Ä–HÄÿXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
¢
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28ÄÄ@ÄÄHÄÄXbfunctional_1/conv2d_17/Conv2Dh
Ÿ
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä¯
@Ä8HÄ`Xbfunctional_1/conv2d_16/Conv2Dh
Ω
ﬁvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28Å
@Å
HÅ
Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ß
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ä
@Ä∏HÄ∏Xbfunctional_1/conv2d_2/Conv2Dh
s
ampere_sgemm_128x128_nt*28Ä»
@Ä†HÄ®Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
…
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ä»
@Ä†HÄ®Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
Ÿ
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å¿
@Ä8HÄ`Xbfunctional_1/conv2d_17/Conv2Dh
O
ampere_cgemm_64x32_tn*28Å∞
@ÄàHÅ®Xbfunctional_1/conv2d_6/Conv2Dh
”
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Å∞
@ÄêHÅàXbfunctional_1/conv2d_22/Conv2Dh
¥
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Ä®
@Ä∏HÄ∏Xbfunctional_1/conv2d_13/Conv2Dh
u
ampere_sgemm_128x128_nt*28É†
@Å∞HÅ∏Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
ô
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Å†
@ÄêHÅêXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
ß
…void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Å†
@Ä»HÅ»Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_64x32_tn*28Ä†
@ÄàHÄòXbfunctional_1/conv2d_4/Conv2Dh
…
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Ä†
@ÄêHÄêXbfunctional_1/conv2d_16/Conv2Dh
q
ampere_cgemm_64x32_tn*28Äò
@ÄàHÄêXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28Åê
@Ä∞HÅ∞Xbfunctional_1/conv2d_14/Conv2Dh
ò
·void gemmk1_kernel<float2, 256, 5, false, false, true, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28Çà
@ÄHÅ Xbfunctional_1/conv2d/Conv2Dh2
t
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Åà
@Ä®HÅ∞Xbfunctional_1/conv2d/Conv2Dh
π
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Åà
@ÅÄHÄàXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
∏
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28ÅÄ
@Ä¯HÅàXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
ô
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28ÄÄ
@Ä®HÄ∞Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28ÄÄ
@Ä®HÄ∞Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ÿ
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä	@ÄHHÄËXbfunctional_1/conv2d_6/Conv2Dh
q
ampere_cgemm_64x32_tn*28ÅË	@ÅHÄ¯Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
æ
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ä‡	@ÄÿHÄòXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
®
…void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)*28Å–	@ÄHÅ¯Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
º
ﬁvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 6, 7, 3, 3, 5, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28Å–	@ÄËHÅËXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
O
ampere_cgemm_64x32_tn*28Ä»	@Ä‡HÄËXbfunctional_1/conv2d_8/Conv2Dh
∏
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Å¿	@Ä‡HÅ‡Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
˙
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å¿	@Ä8HÄPXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
˙
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä¿	@Ä8HÄPXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Ÿ
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å∏	@Ä8HÄXXbfunctional_1/conv2d_18/Conv2Dh
˚
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä∏	@Ä8HÄPXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
˚
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä∏	@Ä8HÄPXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
˚
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä∏	@Ä8HÄPXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ÿ
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å∞	@Ä8HÄPXbfunctional_1/conv2d_3/Conv2Dh
“
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ä®	@Ä†HÄ∞Xbfunctional_1/conv2d_2/Conv2Dh
R
ampere_sgemm_128x128_nn*28Å†	@Ä–HÅ–Xbfunctional_1/conv2d_14/Conv2Dh
ÿ
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Åò	@Ä8HÅHXbfunctional_1/conv2d_2/Conv2Dh
Ú
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Äò	@Ä8HÄêXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
Ñ
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Éê	@Ä8HÄPXbfunctional_1/conv2d_2/Conv2Dh
ß
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Çê	@Ä8HÄPXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
Ü
)ampere_scudnn_128x64_stridedB_small_nn_v1*28Äê	@Ä‡HÄòXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äê	@Ä8HÄHXbfunctional_1/conv2d_17/Conv2Dh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Éà	@Ä8HÄPXbfunctional_1/conv2d_18/Conv2Dh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Åà	@Ä8HÄHXbfunctional_1/conv2d_16/Conv2Dh
…
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Äà	@Ä¿HÄ»Xbfunctional_1/conv2d_14/Conv2Dh
ı
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ÇÄ	@Ä†HÅ†Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
‹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÅÄ	@Ä¿HÅ¿Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
ˆ
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28ÄÄ	@ÄòHÄ®Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
∫
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÄÄ	@Ä∏HÄ»Xbfunctional_1/conv2d_17/Conv2Dh
º
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28ÄÄ	@ÄêHÄ∞Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
∫
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Å¯@Å∏HÄ¿Xbfunctional_1/conv2d_22/Conv2Dh
ô
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä¯@Ä¯HÄÄXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
¶
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Ä@Ä8HÄHXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Ñ
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ÅË@Ä8HÄPXbfunctional_1/conv2d_3/Conv2Dh
r
ampere_cgemm_64x32_tn*28ÄË@Ä∞HÄ∏Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
P
ampere_gcgemm_64x32_nt*28ÄË@Ä∞HÄ∏Xbfunctional_1/conv2d_6/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28ÄË@Ä¯HÄ¯Xbfunctional_1/conv2d_11/Conv2Dh
¥
¯void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Å‡@Ä∞HÅ∞Xbfunctional_1/conv2d_13/Conv2Dh
¶
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Å‡@Ä8HÄHXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
µ
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28Å‡@Ä8HÅ¯Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
Ä
§void gemv2N_kernel<int, int, float, float, float, 128, 8, 4, 4, 1, false, cublasGemvParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float> >(cublasGemvParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28Äÿ@ÄHÄ¯Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
ª
ˇvoid gemmSN_NN_kernel<float, 128, 2, 4, 8, 2, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)*28Å–@Ä®HÅ®Xbfunctional_1/conv2d_22/Conv2Dh
r
ampere_gcgemm_64x32_nt*28Ä–@Ä®HÄ®Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
à
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28Ä–@Ä®HÄ®Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
 
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Å»@Ä†HÅ®Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
·
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Å¿@Ä†HÅ†Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
·
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä¿@Ä†HÄ†Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
ì
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ç∞@Ä(HÅXbfunctional_1/conv2d_8/Conv2Dh
…
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Å∞@ÄòHÅòXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Q
ampere_sgemm_128x128_nn*28Ä∞@ÄòHÄòXbfunctional_1/conv2d_2/Conv2Dh
º
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä∞@ÄòHÄòXbfunctional_1/conv2d/Conv2Dh
ø
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Å®@ÄêHÅòXbfunctional_1/conv2d_20/Conv2Dh
ô
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä†@Ä‡HÄ‡Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
•
mvoid pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)*28Ä†@ÄÿHÄ»Xbfunctional_1/conv2d/Conv2Dh
¢
ƒvoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28Åò@ÅòHÅòXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
r
ampere_cgemm_64x64_tn*28Äò@ÄàHÄêXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
r
ampere_cgemm_64x64_tn*28Äà@ÄÄHÄàXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
ò
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28Äà@Ä–HÄ‡Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile244t_nt_v1*28ÄÄ@Ä–HÄÿXbfunctional_1/conv2d_9/Conv2Dh
ô
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ç¯@ÄPHÅ®Xbfunctional_1/conv2d_4/Conv2Dh
Ê
àvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Å@Ä¯HÅ¯Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
›
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28ÅË@Ä»HÅÿXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
‹
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28ÄË@Ä»HÄÿXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
…
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Å‡@ÄHÅXbfunctional_1/conv2d_13/Conv2Dh
€
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Å‡@Ä¿HÅ–Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
©
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Å‡@ÄHÅXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
¢
ƒvoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28Ä‡@Ä‡HÄ‡Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
Ï
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Ä‡@ÄHÄXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ω
ﬁvoid cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)*28Åÿ@ÅÿHÅÿXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
⁄
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Åÿ@Å¿HÄ–Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
›
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Åÿ@Ä»HÅ»Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
⁄
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Å–@Ä∏HÅ–Xb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
€
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Å»@Å∞HÄ–Xb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
⁄
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å»@Ä‡HÅËXbfunctional_1/conv2d_13/Conv2Dh
Ÿ
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å»@Å‡HÄËXbfunctional_1/conv2d_6/Conv2Dh
ë
ÿvoid gemmk1_kernel<float, 256, 5, false, false, false, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>(cublasGemmk1Params<float, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float, biasType<cublasGemvTensorStridedBatched<float>::value_type, float>::type>)*28Ä»@Ä‡HÄËXbfunctional_1/conv2d/Conv2Dh
⁄
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä¿@Ä‡HÄ‡Xbfunctional_1/conv2d_14/Conv2Dh
˝
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å∏@ÅÿHÄ‡Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
˝
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä∏@ÄÿHÄ‡Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
R
ampere_sgemm_128x128_nn*28Ç†@Å–HÅ–Xbfunctional_1/conv2d_11/Conv2Dh
Q
ampere_sgemm_128x128_nn*28Ä†@Ä–HÄ–Xbfunctional_1/conv2d_9/Conv2Dh
¢
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28Ä†@Ä†HÄ†Xbfunctional_1/conv2d_14/Conv2Dh
¥
˘void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Åò@Å»HÄ–Xbfunctional_1/conv2d_8/Conv2Dh
®
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Åê@ÄhHÄÄXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
Ã
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_128x64_16x6::Params)*28Åà@ÅàHÅàXbfunctional_1/conv2d_19/Conv2Dh
s
ampere_sgemm_128x128_nt*28ÄÄ@Ä¿HÄ¿Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
ß
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ÄÄ@ÄhHÄxXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ı
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Å¯@Ä®HÄòXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
à
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28Å¯@Å¯HÅ¯Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
⁄
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä¯@Ä`HÄêXbfunctional_1/conv2d_13/Conv2Dh
t
ampere_sgemm_128x128_nt*28Ä@Ä∏HÄ∏Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
⁄
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å‡@ÄXHÅàXbfunctional_1/conv2d_14/Conv2Dh
∏
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Ä‡@Ä∞HÄ∞Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
à
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28Å»@Å»HÅ»Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Í
åvoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3>(cutlass_tensorop_s1688wgrad_analytic_tf32_256x128_16x3::Params)*28Å»@Å»HÅ»Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6::Params)*28Å¿@Å¿HÅ¿Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
π
‹void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28Ä¿@Ä†HÄ†Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
È
ävoid cutlass::Kernel<cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6>(cutlass_tensorop_s1688wgrad_analytic_tf32_64x128_16x6::Params)*28Ä¿@Ä¿HÄ¿Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ƒ
ivoid fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)*28Ä¿@Ä HÄhXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh

æ
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ç∏@ÄêHÅêXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
Á
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ç∏@ÅòHÅ†Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
∏
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Å∏@ÄêHÅòXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
Ó=
è=void cutlass::Kernel<cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2> >(cutlass::conv::kernel::ImplicitGemmConvolution<cutlass::conv::threadblock::ImplicitGemmMultistage<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::conv::threadblock::Conv2dWgradOutputGradientTileAccessIteratorAnalytic<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<64, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, 1, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::conv::threadblock::Conv2dWgradActivationTileAccessIteratorAnalytic<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4> >, cutlass::transform::threadblock::RegularTileAccessIterator<cutlass::MatrixShape<16, 64>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, 0, cutlass::transform::PitchLinearWarpRakedThreadMap<cutlass::layout::PitchLinearShape<64, 16>, 128, cutlass::layout::PitchLinearShape<8, 4>, 4>, 16>, (cutlass::arch::CacheOperation::Kind)0, cutlass::gemm::threadblock::MmaPolicy<cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, cutlass::MatrixShape<0, 0>, cutlass::MatrixShape<0, 0>, 1>, 10, bool>, cutlass::epilogue::threadblock::Epilogue<cutlass::gemm::GemmShape<64, 64, 16>, cutlass::gemm::warp::MmaTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::tfloat32_t, cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous<32, 32>, cutlass::tfloat32_t, cutlass::layout::RowMajorTensorOpMultiplicandCongruous<32, 32>, float, cutlass::layout::RowMajor, cutlass::gemm::warp::MmaTensorOpPolicy<cutlass::arch::Mma<cutlass::gemm::GemmShape<16, 8, 8>, 32, cutlass::tfloat32_t, cutlass::layout::RowMajor, cutlass::tfloat32_t, cutlass::layout::ColumnMajor, float, cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>, cutlass::MatrixShape<1, 1> >, 1, false, bool>, 1, cutlass::epilogue::threadblock::PredicatedTileIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>, float>, cutlass::epilogue::warp::FragmentIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::Array<float, 4, true>, cutlass::layout::RowMajor>, cutlass::epilogue::warp::TileIteratorTensorOp<cutlass::gemm::GemmShape<32, 32, 16>, cutlass::gemm::GemmShape<16, 8, 8>, float, cutlass::layout::RowMajor>, cutlass::epilogue::threadblock::SharedLoadIterator<cutlass::epilogue::threadblock::OutputTileOptimalThreadMap<cutlass::epilogue::threadblock::OutputTileShape<64, 8, 2, 1, 1>, cutlass::epilogue::threadblock::OutputTileShape<1, 4, 1, 1, 4>, 128, 4, 32>::CompactedThreadMap, float, 16>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::MatrixShape<0, 8> >, cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<4>, (cutlass::conv::Operator)2>::Params)*28Ä∏@Ä∏HÄ∏Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
æ
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ä∏@ÄêHÄêXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
ú
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ä®@ÄÄHÄ®Xbfunctional_1/conv2d_16/Conv2Dh
‰
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä®@ÄàHÄêXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
ˆ
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Å†@ÄêHÅêXbfunctional_1/conv2d_3/Conv2Dh
˜
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ä†@ÄêHÄêXbfunctional_1/conv2d_18/Conv2Dh
ò
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ä†@ÄêHÄêXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ˆ
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Äò@ÄàHÄêXbfunctional_1/conv2d_2/Conv2Dh
€
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äò@ÄòHÄ†Xbfunctional_1/conv2d_10/Conv2Dh
≥
¯void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Äò@ÄàHÄàXbfunctional_1/conv2d_4/Conv2Dh
ô
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Åê@ÄàHÅàXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
õ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Åê@ÅÄHÄêXbfunctional_1/conv2d_2/Conv2Dh
t
ampere_sgemm_128x128_nt*28Äê@ÄàHÄàXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
˜
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Äê@ÄàHÄàXbfunctional_1/conv2d_17/Conv2Dh
u
ampere_sgemm_128x128_nt*28Åà@ÄÄHÄàXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ú
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Åà@ÄÄHÅàXbfunctional_1/conv2d_17/Conv2Dh
˜
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Äà@ÄÄHÄàXbfunctional_1/conv2d_16/Conv2Dh
ú
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Äà@ÄÄHÄàXbfunctional_1/conv2d_18/Conv2Dh
æ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Äà@ÄÄHÄàXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
¢
ivoid fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)*28Äà@ÄXHÄhXbfunctional_1/conv2d_23/Conv2Dh
ò
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28ÇÄ@ÄÄHÅÄXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28ÅÄ@ÄÄHÅÄXbfunctional_1/conv2d_3/Conv2Dh
Ω
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÅÄ@ÄÄHÅÄXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28ÄÄ@ÄÄHÄÄXbfunctional_1/conv2d_18/Conv2Dh
õ
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÄÄ@Ä¯HÄàXbfunctional_1/conv2d_3/Conv2Dh
ô
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Å¯@Ä¯HÅÄXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ò
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä¯@Ä¯HÄÄXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
∏
€void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Ä@Ä¯HÄ¯Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
¢
ƒvoid cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28ÅË@ÅËHÅËXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
t
ampere_sgemm_128x128_nt*28Ä»@Ä‡HÄËXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28Å¿@Ä‡HÅ‡Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
ò
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28Ä¿@Ä‡HÄ‡Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
Ã
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_64x128_16x6>(cutlass_tensorop_s1688fprop_precomputed_tf32_64x128_16x6::Params)*28Ä¿@Ä¿HÄ¿Xbfunctional_1/conv2d_16/Conv2Dh
©
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Å∏@Ä®HÄ∏Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
©
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Ä∏@Ä®HÄ∞Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28Ä†@Ä‡HÄ‡Xbfunctional_1/conv2d_7/Conv2Dh
s
ampere_sgemm_128x128_nt*28Ä†@Ä–HÄ–Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
€
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä†@Ä–HÄ–Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
å
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28Äò@ÄòHÄòXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28Äò@ÄÿHÄ‡Xbfunctional_1/conv2d_12/Conv2Dh
Ç
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Äê@Ä»HÄ»Xbfunctional_1/conv2d_9/Conv2Dh
Ï
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Å¯@Ä∏HÅ¿Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
ã
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28Ä¯@Ä¯HÄ¯Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ã
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28Ä¯@Ä¯HÄ¯Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ö
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ä¯@Ä–HÄÿXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
Ñ
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Ä¯@Ä@HÄXXbfunctional_1/conv2d_4/Conv2Dh
ò
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Å@Ä–HÅ–Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Ï
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Å@Ä∏HÅ∏Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
å
/ampere_scudnn_128x64_stridedB_xregs_large_nn_v1*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ô
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä@Ä–HÄ–Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
ø
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ä@ÄhHÄ–Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Ë
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä@ÄÿHÄòXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
¶
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ÅË@Ä@HÄXXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
‹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÄË@Ä∞HÄ∏Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
»
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Ä‡@Ä∞HÄ∞Xbfunctional_1/conv2d_4/Conv2Dh
∫
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Äÿ@Ä®HÄ∞Xbfunctional_1/conv2d_14/Conv2Dh
∫
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Äÿ@Ä®HÄ∞Xbfunctional_1/conv2d_18/Conv2Dh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äÿ@Ä8HÄXXbfunctional_1/conv2d_13/Conv2Dh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äÿ@Ä8HÄXXbfunctional_1/conv2d_14/Conv2Dh
»
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Å–@Ä®HÅ®Xbfunctional_1/conv2d_9/Conv2Dh
ß
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Å–@Ä8HÅPXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
˙
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å–@Ä@HÄXXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä–@Ä¿HÄ»Xbfunctional_1/conv2d_8/Conv2Dh
‹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä–@Ä®HÄ®Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
€
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä–@Ä®HÄ®Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
€
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä–@Ä®HÄ®Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
˚
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä–@Ä@HÄXXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
æ
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Å»@Ä†HÅ®Xbfunctional_1/conv2d_3/Conv2Dh
¸
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å»@ÄÄHÅ»Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
π
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä»@Ä†HÄ®Xbfunctional_1/conv2d_3/Conv2Dh
ò
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Å¿@Ä¿HÅ¿Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
æ
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Å¿@Ä†HÅ†Xbfunctional_1/conv2d_2/Conv2Dh
ö
ﬁvoid precomputed_convolve_sgemm<float, 512, 6, 7, 4, 3, 5, 1, false>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, int*)*28Å¿@Å¿HÅ¿Xbfunctional_1/conv2d_13/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä¿@Ä¿HÄ¿Xbfunctional_1/conv2d_21/Conv2Dh
t
ampere_sgemm_128x128_nt*28Ä¿@Ä¿HÄ¿Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
∏
€void cudnn::detail::dgrad_engine<float, 128, 6, 7, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Ä¿@Ä†HÄ†Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
·
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä¿@Ä†HÄ†Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
‡
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä¿@Ä†HÄ†Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
˚
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä¿@Ä@HÄXXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Å∏@Å∏HÅ∏Xbfunctional_1/conv2d_1/Conv2Dh
ò
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä∏@Ä∏HÄ∏Xb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
ô
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä∏@Ä∏HÄ∏Xb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
ø
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä∏@ÄòHÄ†Xbfunctional_1/conv2d_17/Conv2Dh
·
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä∏@ÄòHÄ†Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
à
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28Ä∏@ÄòHÄ†Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
˚
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä∏@Ä8HÄXXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
»
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Ä∞@ÄòHÄòXbfunctional_1/conv2d_8/Conv2Dh
ø
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä∞@ÄòHÄòXbfunctional_1/conv2d_18/Conv2Dh
‹
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä∞@Ä∞HÄ–Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
∏
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Ä®@Ä∏HÄ∏Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
˙
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä®@Ä8HÄXXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
á
*ampere_scudnn_128x128_stridedB_small_nn_v1*28Ä†@Ä†HÄ†Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
¡
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ä†@Ä∞HÄ¿Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
∏
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Çò@Å∞HÄ∏Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28Äò@Ä∞HÄ∏Xbfunctional_1/conv2d_4/Conv2Dh
R
ampere_sgemm_128x128_nn*28Äò@ÄàHÄêXbfunctional_1/conv2d_12/Conv2Dh
Q
ampere_sgemm_128x128_nn*28Äò@ÄàHÄêXbfunctional_1/conv2d_4/Conv2Dh
˝
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Åê@ÄhHÅ†Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
á
*ampere_scudnn_128x128_stridedB_small_nn_v1*28Äê@ÄêHÄêXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
⁄
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Äê@ÄòHÄ–Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
›
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Äê@Ä∞HÄ∞Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
ÿ
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äê@Ä8HÄPXbfunctional_1/conv2d_4/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Çà@Å®HÅ∞Xbfunctional_1/conv2d_2/Conv2Dh
¥
˘void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Çà@ÅÄHÅàXbfunctional_1/conv2d_4/Conv2Dh
Ü
*ampere_scudnn_128x128_stridedB_small_nn_v1*28Äà@ÄàHÄàXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ü
*ampere_scudnn_128x128_stridedB_small_nn_v1*28Äà@ÄàHÄàXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Q
ampere_sgemm_128x128_nn*28Äà@ÄÄHÄàXbfunctional_1/conv2d_7/Conv2Dh
˝
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äà@ÄÄHÄàXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ÅÄ@Ä`HÄpXbfunctional_1/conv2d_10/Conv2Dh
€
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÄÄ@ÄòHÄ∏Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
›
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28ÄÄ@Ä®HÄ∞Xb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
¶
Àvoid fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28ÄÄ@Ä8HÄHXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Q
ampere_sgemm_128x128_nn*28Ä¯@Ä¯HÄÄXbfunctional_1/conv2d_8/Conv2Dh
‹
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä¯@Ä†HÄ∞Xb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
π
€void cudnn::detail::dgrad_engine<float, 128, 6, 8, 3, 3, 5, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)*28Å@Ä†HÅ®Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28Ä@Ä¯HÄ¯Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
Ù
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ä@Ä`HÄòXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
€
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä@ÄêHÄ∞Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
π
‹void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28ÅË@ÅËHÅËXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
s
ampere_sgemm_128x128_nt*28ÄË@ÄHÄ¯Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
ÿ
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÄË@Ä†HÄ®Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
È
´void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28Ä‡@ÄËHÄ¯b!functional_1/concatenate_3/concath
‰
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä‡@Ä†HÄ†Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
º
`void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)*28Åÿ@ÄXHÄòXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
≥
˘void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)*28Åÿ@ÄXHÅ`Xbfunctional_1/conv2d_23/Conv2Dh
Ç
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Å–@Å–HÅ–Xbfunctional_1/conv2d_19/Conv2Dh
•
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Ä–@Ä–HÄ–Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
Ê
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä»@ÄHÄÿXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
§
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Ä»@Ä»HÄ»Xb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
ƒ
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28Ä»@Ä»HÄ»Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ò
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Å¿@Ä‡HÅ‡Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
à
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28Ä∏@Ä∏HÄ∏Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ƒ
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä∏@Ä HÄòXbfunctional_1/conv2d_20/Conv2Dh
ƒ
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28Ä∏@Ä∏HÄ∏Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
u
ampere_sgemm_128x128_nt*28Ä∞@Ä∞HÄ∞Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28Ä∞@Ä∞HÄ∞Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
 
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Ä∞@ÄÿHÄÿXbfunctional_1/conv2d_14/Conv2Dh
ƒ
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä∞@ÄHÄòXbfunctional_1/conv2d_19/Conv2Dh
√
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28Ä∞@Ä∞HÄ∞Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
à
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28Å®@Å®HÅ®Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
√
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::dgrad::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::dgrad::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::dgrad::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::dgrad::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28Å®@Å®HÅ®Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Â
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä®@ÄàHÄêXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
…
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Ä®@Ä–HÄÿXbfunctional_1/conv2d_4/Conv2Dh
t
ampere_sgemm_128x128_nt*28Å†@ÄàHÅêXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28Ä†@ÄàHÄêXbfunctional_1/conv2d_6/Conv2Dh
á
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28Ä†@Ä†HÄ†Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
á
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_128x64_16x6_unity_stride::Params)*28Ä†@Ä†HÄ†Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äò@Ä`HÄhXbfunctional_1/conv2d_11/Conv2Dh
®
…void tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28Äò@Ä»HÄ–Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
Ö
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äê@Ä`HÄhXbfunctional_1/conv2d_12/Conv2Dh
Ñ
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äê@Ä`HÄhXbfunctional_1/conv2d_7/Conv2Dh
Á
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Äê@ÄêHÄêXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äê@ÄêHÄêbpgradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
∂
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äê@ÄêHÄêbqgradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
 
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Åà@Å¿HÄ»Xbfunctional_1/conv2d_13/Conv2Dh
Î
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Åà@Å¿HÄ»Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Ñ
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äà@Ä`HÄhXbfunctional_1/conv2d_6/Conv2Dh
ò
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28ÅÄ@ÄÄHÅÄXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
Ï
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28ÄÄ@Ä∏HÄ»Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄÄ@ÄÄHÄÄbpgradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
’
övoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false> >, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4> >(xmma_new::implicit_gemm::fprop_indexed::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, false, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop_indexed::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false> >, xmma_new::implicit_gemm::Input_related<0, 0, 0, false>, 4>::Params)*28ÄÄ@ÄÄHÄÄXbfunctional_1/conv2d_9/Conv2Dh
•
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Å@Ä∏HÅ∏Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
”
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAgradient_tape/functional_1/leaky_re_lu_21/LeakyRelu/LeakyReluGradh
¶
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Ä@Ä∏HÄ∏Xb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
¶
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Ä@Ä∏HÄ∏Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
Ω
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÄË@Ä∞HÄ∏Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
á
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride::Params)*28ÄË@ÄËHÄËXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
á
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_64x64_16x10_unity_stride::Params)*28ÄË@ÄËHÄËXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
Q
ampere_sgemm_128x128_nn*28Ä‡@Ä∞HÄ∞Xbfunctional_1/conv2d_6/Conv2Dh
ô
cvoid DSE::vector_fft<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ä‡@Ä@HÄxXbfunctional_1/conv2d/Conv2Dh
Ç
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Ä‡@Ä∞HÄ∞Xbfunctional_1/conv2d_8/Conv2Dh
Ÿ
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Åÿ@Ä†HÅ∏Xbfunctional_1/conv2d_4/Conv2Dh
r
ampere_sgemm_128x128_nt*28Äÿ@ÄpHÄxXb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
ù
ƒvoid cudnn::pooling_bw_kernel_max<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28Äÿ@ÄÿHÄÿb<gradient_tape/functional_1/max_pooling2d/MaxPool/MaxPoolGradh
Ü
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äÿ@Ä®HÄ∞Xbfunctional_1/conv2d_9/Conv2Dh
®
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äÿ@Ä®HÄ∞Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
É
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Äÿ@Ä®HÄ∞Xbfunctional_1/conv2d_10/Conv2Dh
É
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Äÿ@Ä®HÄ∞Xbfunctional_1/conv2d_11/Conv2Dh
Á
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Äÿ@ÄxHÄ‡Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Œ
óvoid DSE::regular_fft_pad<0, 1, 256, 16, 16, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ç–@Ä@HÅhXbfunctional_1/conv2d/Conv2Dh
–
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Å–@Å–HÅ–b>gradient_tape/functional_1/leaky_re_lu/LeakyRelu/LeakyReluGradh
“
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Å–@Å–HÅ–b@gradient_tape/functional_1/leaky_re_lu_1/LeakyRelu/LeakyReluGradh
”
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä–@Ä–HÄ–bAgradient_tape/functional_1/leaky_re_lu_19/LeakyRelu/LeakyReluGradh
”
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä–@Ä–HÄ–bAgradient_tape/functional_1/leaky_re_lu_20/LeakyRelu/LeakyReluGradh
˚
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä–@Ä@HÄhXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
Á
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä–@ÄxHÄÿXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
ß
…void tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28Ä–@ÄàHÄ»Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
‡
ävoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28Ä–@Ä–HÄ–b9functional_1/up_sampling2d_3/resize/ResizeNearestNeighborh
Ü
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Å»@Ä†HÅ®Xbfunctional_1/conv2d_8/Conv2Dh
˙
ívoid tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28Ä»@Ä»HÄ»bKgradient_tape/functional_1/up_sampling2d_3/resize/ResizeNearestNeighborGradh
˛
üvoid fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä¿@Ä†HÄ†Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
⁄
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä¿@Ä†HÄ†Xbfunctional_1/conv2d_9/Conv2Dh
‹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Å∏@ÅòHÄ†Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
˝
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä∏@ÄòHÄ†Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
˝
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä∏@ÄòHÄ†Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
¸
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å∞@ÄòHÅòXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
⁄
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Å∞@ÄòHÅòXbfunctional_1/conv2d_17/Conv2Dh
í
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä∞@Ä∞HÄ∞bAddN_5h
π
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä∞@ÄòHÄòXbfunctional_1/conv2d_2/Conv2Dh
‹
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä∞@ÄòHÄòXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
€
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä∞@ÄòHÄòXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
€
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä∞@ÄòHÄòXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
æ
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä∞@ÄòHÄòXbfunctional_1/conv2d_9/Conv2Dh
ø
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä∞@ÄòHÄòXbfunctional_1/conv2d_14/Conv2Dh
·
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä∞@ÄòHÄòXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
⁄
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä∞@ÄòHÄòXbfunctional_1/conv2d_16/Conv2Dh
‡
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Å®@ÄêHÅòXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
æ
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä®@ÄêHÄòXbfunctional_1/conv2d_4/Conv2Dh
·
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä®@ÄêHÄòXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
à
™void cutlass::Kernel<cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride>(cutlass_tensorop_s1688dgrad_precomputed_tf32_256x64_16x4_unity_stride::Params)*28Ä®@Ä®HÄ®Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
°
Êvoid xmma_new::gemm::kernel<xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4> >(xmma_new::implicit_gemm::fprop::Kernel_traits<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::fprop::Gmem_tile_a_t<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, false, xmma_new::implicit_gemm::fprop::Gmem_tile_base_a<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 16, xmma_new::Row, 16, 128> >, xmma_new::implicit_gemm::fprop::Gmem_tile_c_n<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, 16, xmma_new::Fragment_c<xmma_new::Ampere_hmma_tf32_traits<unsigned int, float>, xmma_new::Cta_tile<xmma_new::Ampere, 128, 128, 16, 2, 2, 1, 1, 1>, false>, false>, xmma_new::implicit_gemm::Input_related<1, 3, 3, false>, 4>::Params)*28Ä®@Ä®HÄ®Xbfunctional_1/conv2d_4/Conv2Dh
π
‹void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)*28Ä†@Ä†HÄ†Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
∫
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä†@ÄêHÄêXbfunctional_1/conv2d_11/Conv2Dh
‡
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä†@ÄêHÄêXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
‡
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä†@ÄêHÄêXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
€
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä†@Ä`HÄ`Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
⁄
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä†@Ä`HÄ`Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ç
∆void gemv2T_kernel_val<int, int, float2, float2, float2, 128, 16, 2, 2, false, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>, float2, float2)*28Ä†@ÄêHÄêXbfunctional_1/conv2d_23/Conv2Dh
¶
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Äò@Ä@HÄHXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
ÿ
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Åê@ÄHHÅhXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
¢
ƒvoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28Äê@ÄêHÄêXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
∂
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Äê@ÄXHÄ`Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÇÄ@Ä@HÅ`Xbfunctional_1/conv2d_9/Conv2Dh
v
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28ÄÄ@ÄÄHÄÄXbfunctional_1/conv2d_5/Conv2Dh
ƒ
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28ÄÄ@Ä HÄ‡Xbfunctional_1/conv2d_16/Conv2Dh
•
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28ÄÄ@ÄÄHÄÄXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Ç
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Å¯@Å¯HÅ¯Xbfunctional_1/conv2d_16/Conv2Dh
w
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile442t_nt_v1*28Ä¯@Ä¯HÄ¯Xbfunctional_1/conv2d_15/Conv2Dh
Ÿ
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä¯@Ä@HÄ`Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
§
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Ä¯@Ä¯HÄ¯Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
Á
´void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28Å@ÄxHÅxb!functional_1/concatenate_2/concath
ƒ
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Å@ÄHÅÿXbfunctional_1/conv2d_17/Conv2Dh
ı
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ä@ÄxHÄxXbfunctional_1/conv2d_22/Conv2Dh
—
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ä@Ä0HÄHXbfunctional_1/conv2d_23/Conv2Dh
Ù
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ä@Ä8HÄ@Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
‚
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä@ÄPHÄPXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
Ω
·void gemmk1_kernel<float2, 256, 5, true, false, false, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28Ä@ÄxHÄxXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Ê
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä@Ä HÄ–Xb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbpgradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28ÄË@ÄËHÄËb"functional_1/leaky_re_lu/LeakyReluh
∂
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28ÄË@ÄËHÄËb$functional_1/leaky_re_lu_1/LeakyReluh
∑
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28ÄË@ÄËHÄËb%functional_1/leaky_re_lu_19/LeakyReluh
∑
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28ÄË@ÄËHÄËb%functional_1/leaky_re_lu_20/LeakyReluh
∑
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28ÄË@ÄËHÄËb%functional_1/leaky_re_lu_21/LeakyReluh
¸
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28ÄË@ÄËHÄËb.gradient_tape/functional_1/concatenate_3/Sliceh
˛
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28ÄË@ÄËHÄËb0gradient_tape/functional_1/concatenate_3/Slice_1h
ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄË@Ä8HÄXXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
£
∆void gemv2T_kernel_val<int, int, float2, float2, float2, 128, 16, 2, 2, false, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>, float2, float2)*28ÄË@ÄpHÄxXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
ß
…void tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28ÄË@ÄËHÄËXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
ì
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Å‡@Å‡HÅ‡bfunctional_1/conv2d_19/BiasAddh
∂
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Å‡@Å‡HÅ‡bqgradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
Û
óvoid DSE::regular_fft_pad<0, 1, 128, 16, 32, 1, float, float, float2>(float2*, float*, int, int3, int3, int, int3, int3, int, int, int, int, int, bool)*28Ä‡@Ä0HÄ@Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
„
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä‡@ÄHHÄPXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
¸
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä‡@ÄpHÄpXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
ß
…void tensorTransformGeneric<float, float, float, true, false, false, (cudnnKernelDataType_t)2>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, float const*, float*, float, float)*28Ä‡@Ä‡HÄ‡Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
˝
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä‡@Ä‡HÄ‡b8AddN_5-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä‡@Ä‡HÄ‡bMfunctional_1/conv2d/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ï
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä‡@Ä‡HÄ‡bPfunctional_1/conv2d_20/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ï
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä‡@Ä‡HÄ‡bPfunctional_1/conv2d_21/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ß
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä‡@Ä‡HÄ‡bbgradient_tape/functional_1/concatenate_3/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
Ô
ìvoid fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)*28Åÿ@ÄHÄ Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
ï
ªvoid DSE::regular_fft_clip<1, 2, 256, 16, 16, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Äÿ@ÄhHÄpXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
„
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Äÿ@ÄHHÄHXb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
„
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Äÿ@ÄHHÄHXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
‚
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Äÿ@ÄHHÄHXb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
‚
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Äÿ@ÄHHÄHXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
Ã
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10>(cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10::Params)*28Äÿ@ÄÿHÄÿXbfunctional_1/conv2d_13/Conv2Dh
Á
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Äÿ@ÄÿHÄÿXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
˜
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Äÿ@ÄÿHÄÿb%Adam/Adam/update_18/ResourceApplyAdamh
î
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äÿ@ÄÿHÄÿbOfunctional_1/conv2d_1/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ï
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äÿ@ÄÿHÄÿbPfunctional_1/conv2d_19/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äÿ@ÄÿHÄÿbmgradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äÿ@ÄÿHÄÿbpgradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äÿ@ÄÿHÄÿbpgradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
Á
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Å–@Å–HÅ–Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
∂
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Å–@Å–HÅ–bqgradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Å–@Å–HÅ–bpgradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
€
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä–@ÄhHÄhXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
‡
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä–@Ä@HÄHXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
‚
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä–@Ä@HÄHXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
„
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä–@Ä@HÄHXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
ÿ
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä–@ÄhHÄhXbfunctional_1/conv2d_8/Conv2Dh
˚
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä–@ÄhHÄhXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
≈
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä–@Ä–HÄ–Xbfunctional_1/conv2d_19/Conv2Dh
≈
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä–@Ä–HÄ–Xbfunctional_1/conv2d_20/Conv2Dh
¥
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä–@Ä–HÄ–bogradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≥
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä–@Ä–HÄ–bngradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä–@Ä–HÄ–bpgradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä–@Ä–HÄ–bpgradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä–@Ä–HÄ–bpgradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
∂
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä–@Ä–HÄ–bqgradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä–@Ä–HÄ–blgradient_tape/functional_1/max_pooling2d/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
Ä
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Å»@Å`HÄhXbfunctional_1/conv2d_7/Conv2Dh
ô
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä»@Ä»HÄ»Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
ò
<ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1*28Ä»@Ä»HÄ»Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
ó
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ä»@Ä`HÄhXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
‚
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä»@Ä@HÄHXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
„
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28Ä»@Ä@HÄHXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
À
êvoid cutlass::Kernel<cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10>(cutlass_tensorop_s1688fprop_precomputed_tf32_64x64_16x10::Params)*28Ä»@Ä»HÄ»Xbfunctional_1/conv2d_8/Conv2Dh
Õ
ìvoid fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)*28Ä»@ÄHÄ Xbfunctional_1/conv2d_23/Conv2Dh
¶
Àvoid fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)*28Ä»@Ä`HÄhXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
µ
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ä»@Ä(HÄ8Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
µ
Zvoid fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)*28Ä»@Ä0HÄ8Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
˙
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä»@Ä`HÄhXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
◊
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä»@Ä`HÄhXbfunctional_1/conv2d_3/Conv2Dh
Ω
·void gemmk1_kernel<float2, 256, 5, false, false, true, false, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>(cublasGemmk1Params<float2, cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2, biasType<cublasGemvTensorStridedBatched<float2>::value_type, float2>::type>)*28Ä»@ÄHÄ Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
Á
≠void gemv2N_kernel<int, int, float2, float2, float2, 128, 1, 4, 4, 1, false, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2> >(cublasGemvParams<cublasGemvTensorStridedBatched<float2 const>, cublasGemvTensorStridedBatched<float2>, float2>)*28Ä»@ÄHÄ Xbfunctional_1/conv2d_23/Conv2Dh
í
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä»@Ä»HÄ»bfunctional_1/conv2d_1/BiasAddh
ì
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä»@Ä»HÄ»bfunctional_1/conv2d_20/BiasAddh
ì
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä»@Ä»HÄ»bfunctional_1/conv2d_21/BiasAddh
µ
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä»@Ä»HÄ»bpgradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ı
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ä¿@Ä`HÄ`Xbfunctional_1/conv2d_23/Conv2Dh
∂
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Ä¿@Ä`HÄ`Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
ÿ
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Ä¿@Ä`HÄ`Xbfunctional_1/conv2d_18/Conv2Dh
Å
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Ä¿@Ä`HÄ`Xbfunctional_1/conv2d_12/Conv2Dh
Â
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä¿@Ä`HÄ`Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä¿@Ä¿HÄ¿bfunctional_1/conv2d/BiasAddh
“
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä∏@Ä∏HÄ∏b@gradient_tape/functional_1/leaky_re_lu_2/LeakyRelu/LeakyReluGradh
≤
¯void explicit_convolve_sgemm<float, int, 128, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)*28Ä∏@ÄXHÄ`Xbfunctional_1/conv2d_23/Conv2Dh
ò
ªvoid DSE::regular_fft_clip<1, 2, 128, 16, 32, 1, float, float, float2>(float*, float2*, int, int3, int3, int, int3, int3, int, int, int, int, int, float, float, bool, int, float*, float*)*28Ä∞@ÄXHÄXXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
”
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä∞@Ä∞HÄ∞bAgradient_tape/functional_1/leaky_re_lu_16/LeakyRelu/LeakyReluGradh
”
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä∞@Ä∞HÄ∞bAgradient_tape/functional_1/leaky_re_lu_17/LeakyRelu/LeakyReluGradh
∂
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Ä∞@ÄXHÄXXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
º
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä∞@ÄXHÄXXbfunctional_1/conv2d_6/Conv2Dh
È
évoid fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Ä∞@ÄXHÄXXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
˙
ívoid tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28Ä∞@Ä∞HÄ∞bKgradient_tape/functional_1/up_sampling2d_2/resize/ResizeNearestNeighborGradh
‡
ävoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28Ä∞@Ä∞HÄ∞b9functional_1/up_sampling2d_2/resize/ResizeNearestNeighborh
“
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Å®@Å®HÅ®b@gradient_tape/functional_1/leaky_re_lu_3/LeakyRelu/LeakyReluGradh
”
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä®@Ä®HÄ®bAgradient_tape/functional_1/leaky_re_lu_18/LeakyRelu/LeakyReluGradh
î
πvoid cudnn::pooling_bw_kernel_max_nchw_fully_packed_large<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, int)*28Ä®@Ä®HÄ®b>gradient_tape/functional_1/max_pooling2d_1/MaxPool/MaxPoolGradh
∑
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä®@ÄPHÄXXbfunctional_1/conv2d_4/Conv2Dh
∑
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä®@ÄPHÄXXbfunctional_1/conv2d_7/Conv2Dh
Ÿ
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä®@ÄPHÄXXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
Ω
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä®@ÄPHÄXXbfunctional_1/conv2d_11/Conv2Dh
ﬁ
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä®@ÄPHÄXXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
Â
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä®@ÄHÄ@Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
Ô
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ä®@ÄHÄ Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
∏
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä†@ÄPHÄPXbfunctional_1/conv2d_12/Conv2Dh
⁄
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä†@ÄPHÄPXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
⁄
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä†@ÄPHÄPXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
º
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä†@ÄPHÄPXbfunctional_1/conv2d_8/Conv2Dh
ﬂ
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä†@ÄPHÄPXb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Ω
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä†@ÄPHÄPXbfunctional_1/conv2d_22/Conv2Dh
ÿ
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä†@Ä0HÄ8Xb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
€
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä†@Ä0HÄ8Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
ƒ
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä†@Ä HÄÄXbfunctional_1/conv2d_13/Conv2Dh
Ã
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ä†@ÄHÄ Xbfunctional_1/conv2d_23/Conv2Dh
Ó
ívoid transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)*28Ä†@ÄHÄ Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
ÿ
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Åò@ÅHHÄPXbfunctional_1/conv2d_20/Conv2Dh
∑
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Äò@Ä(HÄ8Xbfunctional_1/conv2d_11/Conv2Dh
˚
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äò@ÄHHÄPXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
˙
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äò@ÄHHÄPXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
√
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Äò@Ä HÄxXbfunctional_1/conv2d_14/Conv2Dh
Ê
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Äò@ÄHÄÄXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
¡
àvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Åê@ÄHHÅHXbfunctional_1/conv2d_9/Conv2Dh
u
ampere_sgemm_128x128_nt*28Äê@ÄêHÄêXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
t
ampere_sgemm_128x128_nt*28Äê@ÄêHÄêXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
í
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Äê@ÄêHÄêbAddN_4h
Á
´void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28Äê@ÄHHÄHb!functional_1/concatenate_1/concath
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Äê@Ä(HÄ8Xbfunctional_1/conv2d_8/Conv2Dh
˚
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äê@ÄHHÄHXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
ÿ
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äê@ÄHHÄHXbfunctional_1/conv2d_19/Conv2Dh
◊
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äê@ÄHHÄHXbfunctional_1/conv2d_2/Conv2Dh
Â
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Äê@ÄHÄxXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
‰
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Äê@ÄHÄxXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
‰
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Äê@ÄHÄxXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
–
ëvoid pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28Äê@ÄêHÄêb"functional_1/max_pooling2d/MaxPoolh
•
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Äê@ÄêHÄêXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
Ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Äà@Ä(HÄ0Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
Ω
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Äà@Ä@HÄHXbfunctional_1/conv2d_12/Conv2Dh
ﬁ
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Äà@Ä@HÄHXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
⁄
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Äà@Ä(HÄ0Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
Ç
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Äà@ÄàHÄàXbfunctional_1/conv2d_13/Conv2Dh
§
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Äà@ÄàHÄàXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
ÿ
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÅÄ@Ä(HÅ0Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
„
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28ÅÄ@Ä@HÅ@Xb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
º
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÄÄ@Ä@HÄ@Xb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
¸
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28ÄÄ@ÄÄHÄÄb.gradient_tape/functional_1/concatenate_2/Sliceh
º
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28ÄÄ@Ä@HÄ@Xbfunctional_1/conv2d_7/Conv2Dh
„
àvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28ÄÄ@Ä@HÄ@Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
Ä
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28ÄÄ@Ä@HÄ@Xbfunctional_1/conv2d_6/Conv2Dh
Ê
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28ÄÄ@Ä0HÄPXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
˜
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28ÄÄ@ÄÄHÄÄb%Adam/Adam/update_22/ResourceApplyAdamh
º
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Åx@ÄHÅ Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
ô
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Äx@ÄHÄ Xbfunctional_1/conv2d_23/Conv2Dh
õ
cvoid DSE::vector_fft<1, 2, 256, 16, 16, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Äx@Ä8HÄ@Xbfunctional_1/conv2d_22/Conv2Dh
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Äx@ÄxHÄxb%functional_1/leaky_re_lu_16/LeakyReluh
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Äx@ÄxHÄxb%functional_1/leaky_re_lu_17/LeakyReluh
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Äx@ÄxHÄxb%functional_1/leaky_re_lu_18/LeakyReluh
≥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Äx@ÄxHÄxb$functional_1/leaky_re_lu_2/LeakyReluh
≥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Äx@ÄxHÄxb$functional_1/leaky_re_lu_3/LeakyReluh
˚
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Äx@ÄxHÄxb0gradient_tape/functional_1/concatenate_2/Slice_1h
’
Ñvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28Äx@ÄxHÄxb7gradient_tape/functional_1/conv2d_1/BiasAdd/BiasAddGradh
∆
çvoid cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)*28Äx@Ä8HÄ@Xbfunctional_1/conv2d_23/Conv2Dh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Äx@ÄHÄ(Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Äx@Ä(HÄ(Xb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
¿
àvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28Äx@Ä8HÄ@Xbfunctional_1/conv2d_8/Conv2Dh
˙
üvoid fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äx@Ä8HÄ@Xb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
‘
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äx@Ä8HÄ@Xbfunctional_1/conv2d/Conv2Dh
◊
ûvoid fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)*28Äx@Ä8HÄ@Xbfunctional_1/conv2d_22/Conv2Dh
Ä
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Äx@Ä8HÄ@Xbfunctional_1/conv2d_14/Conv2Dh
¡
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Äx@Ä(HÄPXbfunctional_1/conv2d_9/Conv2Dh
Â
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Äx@Ä0HÄHXb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
„
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Äx@Ä(HÄPXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
”
Ñvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28Äp@ÄpHÄpb5gradient_tape/functional_1/conv2d/BiasAdd/BiasAddGradh
÷
Ñvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28Äp@ÄpHÄpb8gradient_tape/functional_1/conv2d_19/BiasAdd/BiasAddGradh
÷
Ñvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28Äp@ÄpHÄpb8gradient_tape/functional_1/conv2d_20/BiasAdd/BiasAddGradh
÷
Ñvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28Äp@ÄpHÄpb8gradient_tape/functional_1/conv2d_21/BiasAdd/BiasAddGradh
ÿ
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Äp@Ä8HÄ8Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
º
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Äp@Ä8HÄ8Xbfunctional_1/conv2d_11/Conv2Dh
◊
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Äp@Ä HÄ(Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
◊
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Äp@Ä HÄ(Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Ä
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Äp@Ä8HÄ8Xbfunctional_1/conv2d_13/Conv2Dh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Åh@ÅhHÅhbpgradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
ª
avoid DSE::vector_fft<0, 1, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Äh@ÄHÄ Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Äh@Ä HÄ(Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Äh@ÄHÄ(Xbfunctional_1/conv2d_7/Conv2Dh
◊
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Äh@Ä0HÄ8Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
∂
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Äh@Ä0HÄ8Xbfunctional_1/conv2d_9/Conv2Dh
Ÿ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Äh@Ä HÄ(Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
Ÿ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Äh@Ä HÄ(Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
˜
ívoid tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28Äh@ÄhHÄhbKgradient_tape/functional_1/up_sampling2d_1/resize/ResizeNearestNeighborGradh
›
ävoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28Äh@ÄhHÄhb9functional_1/up_sampling2d_1/resize/ResizeNearestNeighborh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Äh@ÄhHÄhb8gradient_tape/functional_1/conv2d_17/BiasAdd/BiasAddGradh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Äh@ÄhHÄhb8gradient_tape/functional_1/conv2d_18/BiasAdd/BiasAddGradh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Äh@ÄhHÄhbfunctional_1/conv2d_16/BiasAddh
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Äh@ÄhHÄhXbfunctional_1/conv2d_9/Conv2Dh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Äh@ÄhHÄhXb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äh@ÄhHÄhbpgradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äh@ÄhHÄhbogradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
∞
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Äh@ÄhHÄhbngradient_tape/functional_1/max_pooling2d_1/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
„
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Å`@Ä(HÅ8Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¨
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Å`@Å`HÅ`b7gradient_tape/functional_1/conv2d_3/BiasAdd/BiasAddGradh
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Å`@Å`HÅ`Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
∞
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Ä`@Ä`HÄ`b<gradient_tape/functional_1/max_pooling2d/MaxPool/MaxPoolGradh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Ä`@ÄHÄXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä`@Ä HÄ Xbfunctional_1/conv2d_12/Conv2Dh
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä`@Ä HÄ Xbfunctional_1/conv2d_14/Conv2Dh
∂
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä`@Ä0HÄ0Xbfunctional_1/conv2d_6/Conv2Dh
ÿ
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä`@Ä0HÄ0Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
ª
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä`@Ä0HÄ0Xbfunctional_1/conv2d_7/Conv2Dh
ª
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä`@Ä0HÄ0Xbfunctional_1/conv2d_8/Conv2Dh
ÿ
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä`@Ä`HÄ`Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
⁄
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä`@Ä`HÄ`Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
Ÿ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä`@Ä`HÄ`Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Ä`@Ä0HÄ0Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
¢
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Ä`@Ä0HÄ0Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
‰
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä`@Ä HÄ@Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä`@Ä`HÄ`b8gradient_tape/functional_1/conv2d_16/BiasAdd/BiasAddGradh
¨
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä`@Ä`HÄ`b7gradient_tape/functional_1/conv2d_2/BiasAdd/BiasAddGradh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä`@Ä`HÄ`bfunctional_1/conv2d_17/BiasAddh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä`@Ä`HÄ`b%Adam/Adam/update_16/ResourceApplyAdamh
§
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä`@Ä`HÄ`bbgradient_tape/functional_1/concatenate_2/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
≥
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä`@Ä`HÄ`bqgradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä`@Ä`HÄ`bpgradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä`@Ä`HÄ`bpgradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≥
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä`@Ä`HÄ`bqgradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
∞
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä`@Ä`HÄ`bngradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
∞
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä`@Ä`HÄ`bngradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
›
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28ÅX@Ä(HÅ0Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
ü
ƒvoid cudnn::detail::dgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)*28ÄX@ÄXHÄXXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
◊
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄX@ÄHÄ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
¥
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÄX@Ä(HÄ0Xbfunctional_1/conv2d/Conv2Dh
º
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28ÄX@Ä(HÄ0Xbfunctional_1/conv2d_12/Conv2Dh
◊
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÄX@ÄXHÄXXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
‚
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28ÄX@ÄXHÄXXb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
·
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28ÄX@ÄXHÄXXb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
£
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28ÄX@Ä(HÄ0Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
¡
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28ÄX@Ä HÄ8Xbfunctional_1/conv2d_8/Conv2Dh
‰
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28ÄX@Ä HÄ8Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
„
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28ÄX@ÄHÄ@Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
„
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28ÄX@ÄHÄ@Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
‰
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28ÄX@Ä(HÄ0Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
¬
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28ÄX@ÄXHÄXXbfunctional_1/conv2d_16/Conv2Dh
„
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28ÄX@ÄXHÄXXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28ÄX@ÄXHÄXbfunctional_1/conv2d_18/BiasAddh
è
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28ÄX@ÄXHÄXbfunctional_1/conv2d_2/BiasAddh
è
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28ÄX@ÄXHÄXbfunctional_1/conv2d_3/BiasAddh
˙
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄX@ÄXHÄXb8AddN_4-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄX@ÄXHÄXbPfunctional_1/conv2d_18/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄX@ÄXHÄXbpgradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÅP@ÄHÅ Xbfunctional_1/conv2d_17/Conv2Dh
–
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28ÄP@ÄPHÄPbAgradient_tape/functional_1/leaky_re_lu_15/LeakyRelu/LeakyReluGradh
˚
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28ÄP@ÄPHÄPb0gradient_tape/functional_1/concatenate_1/Slice_1h
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28ÄP@Ä(HÄ(Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28ÄP@Ä(HÄ(Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
¥
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28ÄP@Ä(HÄ(Xb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
¥
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28ÄP@ÄHÄXb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
å
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)*28ÄP@ÄPHÄPb>gradient_tape/functional_1/max_pooling2d_2/MaxPool/MaxPoolGradh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄP@ÄHÄ Xbfunctional_1/conv2d_3/Conv2Dh
ª
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28ÄP@Ä(HÄ(Xbfunctional_1/conv2d_9/Conv2Dh
›
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28ÄP@Ä(HÄ(Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
‚
àvoid fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)*28ÄP@Ä(HÄ(Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
‰
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28ÄP@ÄPHÄPXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
¢
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28ÄP@ÄPHÄPXb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄP@ÄPHÄPbPfunctional_1/conv2d_16/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄP@ÄPHÄPbPfunctional_1/conv2d_17/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ë
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄP@ÄPHÄPbOfunctional_1/conv2d_2/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ë
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄP@ÄPHÄPbOfunctional_1/conv2d_3/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄP@ÄPHÄPbpgradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
‰
´void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, 2ul> const, Eigen::array<int, 2ul> const, Eigen::TensorMap<Eigen::Tensor<float, 2, 1, int>, 16, Eigen::MakePointer> >, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, int>, 16, Eigen::MakePointer> const> const, Eigen::GpuDevice>, int)*28ÅH@ÅHÄ0bfunctional_1/concatenate/concath
ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÅH@ÄHÅXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ú
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28ÄH@ÄHÄXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
ª
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28ÄH@Ä HÄ(Xb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh
è
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28ÄH@ÄHHÄHbAddN_3h
œ
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28ÄH@ÄHHÄHb@gradient_tape/functional_1/leaky_re_lu_4/LeakyRelu/LeakyReluGradh
¥
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28ÄH@ÄHÄXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¥
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28ÄH@ÄHÄXb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄH@ÄHÄXbfunctional_1/conv2d_18/Conv2Dh
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄH@ÄHÄXbfunctional_1/conv2d_20/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄH@ÄHÄXbfunctional_1/conv2d_6/Conv2Dh
ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄH@ÄHÄXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄH@ÄHÄXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄH@ÄHÄXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
◊
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄH@ÄHÄXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
◊
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄH@ÄHÄXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
◊
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28ÄH@ÄHÄXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
∂
void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28ÄH@Ä HÄ(Xbfunctional_1/conv2d_8/Conv2Dh
‚
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28ÄH@ÄHHÄHXb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
·
Üvoid cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)*28ÄH@ÄHHÄHXb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
¢
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28ÄH@Ä HÄ(Xb?gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilterh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28ÄH@ÄHHÄHb%Adam/Adam/update_14/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28ÄH@ÄHHÄHb%Adam/Adam/update_20/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28ÄH@ÄHHÄHb%Adam/Adam/update_24/ResourceApplyAdamh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28ÄH@ÄHHÄHXbfunctional_1/conv2d_11/Conv2Dh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28ÄH@ÄHHÄHbpgradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¨
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Å@@Å@HÅ@b7gradient_tape/functional_1/conv2d_5/BiasAdd/BiasAddGradh
–
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä@@Ä@HÄ@bAgradient_tape/functional_1/leaky_re_lu_13/LeakyRelu/LeakyReluGradh
–
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä@@Ä@HÄ@bAgradient_tape/functional_1/leaky_re_lu_14/LeakyRelu/LeakyReluGradh
œ
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä@@Ä@HÄ@b@gradient_tape/functional_1/leaky_re_lu_5/LeakyRelu/LeakyReluGradh
˘
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@@Ä@HÄ@b.gradient_tape/functional_1/concatenate_1/Sliceh
µ
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Ä@@Ä HÄ Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
å
¥void cudnn::pooling_bw_kernel_max_nchw_fully_packed_small<float, float, 2, (cudnnNanPropagation_t)0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)*28Ä@@Ä@HÄ@b>gradient_tape/functional_1/max_pooling2d_3/MaxPool/MaxPoolGradh
≥
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@@ÄHÄXbfunctional_1/conv2d/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@@ÄHÄXbfunctional_1/conv2d_2/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@@ÄHÄXbfunctional_1/conv2d_4/Conv2Dh
◊
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@@ÄHÄXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
º
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä@@Ä HÄ Xbfunctional_1/conv2d_14/Conv2Dh
ª
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä@@Ä HÄ Xbfunctional_1/conv2d_2/Conv2Dh
ª
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä@@Ä HÄ Xbfunctional_1/conv2d_4/Conv2Dh
ª
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä@@Ä HÄ Xbfunctional_1/conv2d_6/Conv2Dh
ﬁ
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä@@Ä HÄ Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
›
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä@@Ä HÄ Xb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
›
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä@@Ä HÄ Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
›
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä@@Ä HÄ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
›
Évoid cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)*28Ä@@Ä HÄ Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
¢
Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Ä@@Ä HÄ Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
¡
âvoid nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä@@ÄHÄ(Xbfunctional_1/conv2d_4/Conv2Dh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä@@Ä@HÄ@b8gradient_tape/functional_1/conv2d_13/BiasAdd/BiasAddGradh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä@@Ä@HÄ@b8gradient_tape/functional_1/conv2d_14/BiasAdd/BiasAddGradh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä@@Ä@HÄ@b8gradient_tape/functional_1/conv2d_15/BiasAdd/BiasAddGradh
¨
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä@@Ä@HÄ@b7gradient_tape/functional_1/conv2d_4/BiasAdd/BiasAddGradh
¨
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä@@Ä@HÄ@b7gradient_tape/functional_1/conv2d_8/BiasAdd/BiasAddGradh
ê
,void tensorflow::SetZero<float>(int, float*)*28Ä@@Ä@HÄ@bKgradient_tape/functional_1/up_sampling2d_3/resize/ResizeNearestNeighborGradh
ˇ
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Ä@@Ä@HÄ@Xbfunctional_1/conv2d_10/Conv2Dh
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@@Ä@HÄ@Xbfunctional_1/conv2d_8/Conv2Dh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@@Ä@HÄ@Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@@Ä@HÄ@Xb?gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropInputh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@@Ä@HÄ@Xb?gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilterh
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@@Ä@HÄ@Xb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28Ä8@ÄHÄXb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
¥
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Ä8@ÄHÄ Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
¥
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Ä8@ÄHÄ Xb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä8@ÄHÄXbfunctional_1/conv2d_22/Conv2Dh
ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä8@ÄHÄXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
º
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä8@ÄHÄ Xbfunctional_1/conv2d_18/Conv2Dh
ﬁ
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä8@ÄHÄ Xb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
ÿ
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä8@Ä8HÄ8Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28Ä8@Ä8HÄ8Xb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
†
hvoid fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)*28Ä8@ÄHÄ Xbfunctional_1/conv2d_23/Conv2Dh
ı
ívoid tensorflow::(anonymous namespace)::ResizeNearestNeighborBackwardNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28Ä8@Ä8HÄ8bIgradient_tape/functional_1/up_sampling2d/resize/ResizeNearestNeighborGradh
€
ävoid tensorflow::(anonymous namespace)::ResizeNearestNeighborNHWC<float>(int, float const*, int, int, int, int, int, float, float, float*)*28Ä8@Ä8HÄ8b7functional_1/up_sampling2d/resize/ResizeNearestNeighborh
¨
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä8@Ä8HÄ8b7gradient_tape/functional_1/conv2d_6/BiasAdd/BiasAddGradh
¨
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä8@Ä8HÄ8b7gradient_tape/functional_1/conv2d_9/BiasAdd/BiasAddGradh
°
∆void tensorflow::functor::PadInputCustomKernelNCHW<float, 4>(int, float const*, tensorflow::functor::Dimension<4>, float*, tensorflow::functor::Dimension<4>, tensorflow::functor::Dimension<(4)-(2)>)*28Ä8@Ä8HÄ8Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
≥
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä8@Ä8HÄ8bqgradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ô
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ä0@ÄHÄXbfunctional_1/conv2d_23/Conv2Dh
º
avoid DSE::vector_fft<1, 2, 128, 8, 8, 1, float, float, float2>(float2*, float2*, int, int3, int3)*28Ä0@ÄHÄXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
–
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä0@Ä0HÄ0bAgradient_tape/functional_1/leaky_re_lu_11/LeakyRelu/LeakyReluGradh
œ
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä0@Ä0HÄ0b@gradient_tape/functional_1/leaky_re_lu_6/LeakyRelu/LeakyReluGradh
˜
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä0@Ä0HÄ0b,gradient_tape/functional_1/concatenate/Sliceh
˘
±void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, 4> const, Eigen::DSizes<int, 4> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä0@Ä0HÄ0b.gradient_tape/functional_1/concatenate/Slice_1h
¥
[void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)*28Ä0@ÄHÄXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä0@ÄHÄXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
π
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä0@ÄHÄXbfunctional_1/conv2d/Conv2Dh
º
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä0@ÄHÄXbfunctional_1/conv2d_17/Conv2Dh
º
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä0@ÄHÄXbfunctional_1/conv2d_20/Conv2Dh
ª
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä0@ÄHÄXbfunctional_1/conv2d_3/Conv2Dh
ﬁ
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä0@ÄHÄXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
ﬁ
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä0@ÄHÄXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
›
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä0@ÄHÄXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ﬁ
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä0@ÄHÄXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
›
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä0@ÄHÄXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
◊
}void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)*28Ä0@Ä0HÄ0Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28Ä0@Ä0HÄ0Xb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh

Hvoid flip_filter<float, float>(float*, float const*, int, int, int, int)*28Ä0@ÄHÄXbfunctional_1/conv2d_4/Conv2Dh
œ
ëvoid pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28Ä0@Ä0HÄ0b$functional_1/max_pooling2d_1/MaxPoolh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä0@Ä0HÄ0b8gradient_tape/functional_1/conv2d_11/BiasAdd/BiasAddGradh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä0@Ä0HÄ0b8gradient_tape/functional_1/conv2d_12/BiasAdd/BiasAddGradh
¨
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä0@Ä0HÄ0b7gradient_tape/functional_1/conv2d_7/BiasAdd/BiasAddGradh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä0@Ä0HÄ0bfunctional_1/conv2d_14/BiasAddh
è
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä0@Ä0HÄ0bfunctional_1/conv2d_5/BiasAddh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä0@Ä0HÄ0b%Adam/Adam/update_28/ResourceApplyAdamh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä0@Ä0HÄ0Xbfunctional_1/conv2d_12/Conv2Dh
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä0@Ä0HÄ0Xbfunctional_1/conv2d_7/Conv2Dh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä0@Ä0HÄ0Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä0@Ä0HÄ0Xb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä0@Ä0HÄ0Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä0@Ä0HÄ0Xb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
≥
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä0@Ä0HÄ0bqgradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
–
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Å(@Å(HÅ(bAgradient_tape/functional_1/leaky_re_lu_10/LeakyRelu/LeakyReluGradh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Å(@Å(HÅ(b8gradient_tape/functional_1/conv2d_10/BiasAdd/BiasAddGradh
è
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä(@Ä(HÄ(bAddN_2h
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä(@Ä(HÄ(b%functional_1/leaky_re_lu_13/LeakyReluh
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä(@Ä(HÄ(b%functional_1/leaky_re_lu_14/LeakyReluh
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä(@Ä(HÄ(b%functional_1/leaky_re_lu_15/LeakyReluh
≥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä(@Ä(HÄ(b$functional_1/leaky_re_lu_4/LeakyReluh
≥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä(@Ä(HÄ(b$functional_1/leaky_re_lu_5/LeakyReluh
–
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä(@Ä(HÄ(bAgradient_tape/functional_1/leaky_re_lu_12/LeakyRelu/LeakyReluGradh
–
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä(@Ä(HÄ(bAgradient_tape/functional_1/leaky_re_lu_22/LeakyRelu/LeakyReluGradh
œ
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä(@Ä(HÄ(b@gradient_tape/functional_1/leaky_re_lu_7/LeakyRelu/LeakyReluGradh
 
Évoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 3ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorBroadcastingOp<Eigen::array<int, 3ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä(@Ä(HÄ(b-gradient_tape/huber_loss/weighted_loss/Tile_1h
º
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä(@ÄHÄXbfunctional_1/conv2d_22/Conv2Dh
ﬁ
Évoid cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)*28Ä(@ÄHÄXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
Ÿ
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä(@Ä(HÄ(Xb?gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilterh
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28Ä(@Ä(HÄ(Xb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Â
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä(@Ä(HÄ(Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
Â
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä(@Ä(HÄ(Xb@gradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilterh
„
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä(@Ä(HÄ(Xb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä(@Ä(HÄ(b8gradient_tape/functional_1/conv2d_22/BiasAdd/BiasAddGradh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä(@Ä(HÄ(bfunctional_1/conv2d_13/BiasAddh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä(@Ä(HÄ(bfunctional_1/conv2d_15/BiasAddh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä(@Ä(HÄ(bfunctional_1/conv2d_22/BiasAddh
è
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä(@Ä(HÄ(bfunctional_1/conv2d_4/BiasAddh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä(@Ä(HÄ(b%Adam/Adam/update_10/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä(@Ä(HÄ(b%Adam/Adam/update_12/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä(@Ä(HÄ(b%Adam/Adam/update_26/ResourceApplyAdamh
·
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28Ä(@Ä(HÄ(bSum_4h
¡
Óvoid tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)*28Ä(@Ä(HÄ(b9functional_1/dropout/dropout/random_uniform/RandomUniformh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä(@Ä(HÄ(Xbfunctional_1/conv2d_10/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä(@Ä(HÄ(Xbfunctional_1/conv2d_14/Conv2Dh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä(@Ä(HÄ(Xb?gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropInputh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä(@Ä(HÄ(Xb@gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä(@Ä(HÄ(Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä(@Ä(HÄ(Xb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
¥
™void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bpgradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¥
™void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 1024, 2, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bpgradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
î
™void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 2, 1024, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bPfunctional_1/conv2d_22/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
µ
™void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 1024, 2, 1024, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bqgradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
˙
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(b8AddN_3-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bPfunctional_1/conv2d_13/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bPfunctional_1/conv2d_14/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ë
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bOfunctional_1/conv2d_4/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ë
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bOfunctional_1/conv2d_5/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
§
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bbgradient_tape/functional_1/concatenate_1/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bpgradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bpgradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bpgradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bpgradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bpgradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
∞
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bngradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bogradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bogradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bpgradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bpgradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
∞
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä(@Ä(HÄ(bngradient_tape/functional_1/max_pooling2d_2/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
¬
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Å @Å HÅ Xbfunctional_1/conv2d_13/Conv2Dh
Î
´void tensorflow::(anonymous namespace)::DynamicStitchKernel<int>(int, int, tensorflow::GpuDeviceArrayStruct<int, 8>, tensorflow::GpuDeviceArrayStruct<int const*, 8>, int*)*28Å @Å HÅ b&gradient_tape/huber_loss/DynamicStitchh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Å @Å HÅ b%Adam/Adam/update_42/ResourceApplyAdamh
ú
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28Ä @Ä HÄ Xb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
ú
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28Ä @Ä HÄ Xb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ó
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b"functional_1/dropout/dropout/Mul_1h
•
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b0gradient_tape/functional_1/dropout/dropout/Mul_1h
•
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b0gradient_tape/functional_1/dropout_1/dropout/Mulh
˙
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ bmul_1h
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b%functional_1/leaky_re_lu_10/LeakyReluh
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b%functional_1/leaky_re_lu_11/LeakyReluh
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b%functional_1/leaky_re_lu_12/LeakyReluh
¥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b%functional_1/leaky_re_lu_22/LeakyReluh
≥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b$functional_1/leaky_re_lu_6/LeakyReluh
≥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b$functional_1/leaky_re_lu_7/LeakyReluh
≥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b$functional_1/leaky_re_lu_9/LeakyReluh
œ
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b@gradient_tape/functional_1/leaky_re_lu_8/LeakyRelu/LeakyReluGradh
œ
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b@gradient_tape/functional_1/leaky_re_lu_9/LeakyRelu/LeakyReluGradh
Ê

´
void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<bool const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<bool const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorBroadcastingOp<Eigen::array<long, 4ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä @Ä HÄ b!gradient_tape/huber_loss/SelectV2h
÷
Ñvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28Ä @Ä HÄ b8gradient_tape/functional_1/conv2d_22/BiasAdd/BiasAddGradh
⁄
void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)*28Ä @Ä HÄ Xb@gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilterh
≈
Èvoid cutlass::Kernel<cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4> >(cutlass::reduction::kernel::ReduceSplitK<cutlass::MatrixShape<4, 128>, cutlass::epilogue::thread::LinearCombination<float, 4, float, float, (cutlass::FloatRoundStyle)2>, cutlass::reduction::thread::ReduceAdd<float, float, 4>, 4>::Params)*28Ä @Ä HÄ Xb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
„
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä @Ä HÄ Xb>gradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInputh
œ
ëvoid pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28Ä @Ä HÄ b$functional_1/max_pooling2d_2/MaxPoolh
≠
\void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const*, float*, int, int, int, int)*28Ä @Ä HÄ b8gradient_tape/functional_1/conv2d_23/BiasAdd/BiasAddGradh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä @Ä HÄ bfunctional_1/conv2d_10/BiasAddh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä @Ä HÄ bfunctional_1/conv2d_11/BiasAddh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä @Ä HÄ bfunctional_1/conv2d_12/BiasAddh
è
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä @Ä HÄ bfunctional_1/conv2d_6/BiasAddh
è
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä @Ä HÄ bfunctional_1/conv2d_7/BiasAddh
ê
,void tensorflow::SetZero<float>(int, float*)*28Ä @Ä HÄ bKgradient_tape/functional_1/up_sampling2d_2/resize/ResizeNearestNeighborGradh
Û
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b$Adam/Adam/update_1/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_19/ResourceApplyAdamh
Û
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b$Adam/Adam/update_2/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_23/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_27/ResourceApplyAdamh
Û
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b$Adam/Adam/update_3/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_30/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_32/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_33/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_34/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_36/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_38/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_39/ResourceApplyAdamh
Û
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b$Adam/Adam/update_4/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_40/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_44/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b%Adam/Adam/update_45/ResourceApplyAdamh
Û
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b$Adam/Adam/update_6/ResourceApplyAdamh
Û
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b$Adam/Adam/update_8/ResourceApplyAdamh
Û
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä @Ä HÄ b$Adam/Adam/update_9/ResourceApplyAdamh
·
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28Ä @Ä HÄ bSum_2h
¯
¬void tensorflow::functor::BlockReduceKernel<float*, float*, 256, tensorflow::functor::Sum<float> >(float*, float*, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28Ä @Ä HÄ bhuber_loss/weighted_loss/Sumh
√
Óvoid tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float> >(tensorflow::random::PhiloxRandom, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>::ResultElementType*, long long, tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>)*28Ä @Ä HÄ b;functional_1/dropout_1/dropout/random_uniform/RandomUniformh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xbfunctional_1/conv2d_13/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xbfunctional_1/conv2d_15/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xbfunctional_1/conv2d_16/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xbfunctional_1/conv2d_18/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xbfunctional_1/conv2d_21/Conv2Dh
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xbfunctional_1/conv2d_3/Conv2Dh
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xbfunctional_1/conv2d_5/Conv2Dh
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xbfunctional_1/conv2d_6/Conv2Dh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xb@gradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilterh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xb@gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xb?gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropInputh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xb?gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xb?gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropFilterh
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä @Ä HÄ Xb>gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropInputh
ﬂ
´void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned char, 256, 32, 32, false>(unsigned char const*, tensorflow::functor::Dimension<3>, unsigned char*)*28Ä @Ä HÄ bôgradient_tape/functional_1/dropout/dropout/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_bool_Mul-1-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bPfunctional_1/conv2d_10/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bPfunctional_1/conv2d_12/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bPfunctional_1/conv2d_15/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ë
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bOfunctional_1/conv2d_6/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ë
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bOfunctional_1/conv2d_7/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ë
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bOfunctional_1/conv2d_9/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
¢
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ b`gradient_tape/functional_1/concatenate/Slice_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bpgradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bpgradient_tape/functional_1/conv2d_10/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bpgradient_tape/functional_1/conv2d_11/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bpgradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≥
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bqgradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bogradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bpgradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropInput-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
∞
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä @Ä HÄ bngradient_tape/functional_1/max_pooling2d_3/MaxPool/MaxPoolGrad-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
ù
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
ù
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ú
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
ú
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
õ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
õ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
õ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
õ
Bcask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
∏
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb)functional_1/dropout/dropout/GreaterEqualh
∫
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::greater_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb+functional_1/dropout_1/dropout/GreaterEqualh
´
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::less_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<bool, float, Eigen::internal::less_equal<float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb"gradient_tape/huber_loss/LessEqualh
Î
≈void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbdiv_no_nan_1h
ñ
≈void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb7gradient_tape/huber_loss/weighted_loss/value/div_no_nanh
˛
·void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbsubh
ı
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAdam/Powh
ô
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb$functional_1/dropout_1/dropout/Mul_1h
ï
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb gradient_tape/huber_loss/Abs/mulh
ì
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbgradient_tape/huber_loss/Mul_2h
Å
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbl2_normalizeh
É
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbl2_normalize_1h
˚
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbhuber_loss/Addh
†
Ÿvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_tanh_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_tanh_gradient_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb-gradient_tape/functional_1/conv2d_23/TanhGradh
–
ìvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb#gradient_tape/huber_loss/zeros_likeh
Æ
ëvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_abs_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_abs_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbAbsh
«
çvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb functional_1/dropout/dropout/Mulh
’
çvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb.gradient_tape/functional_1/dropout/dropout/Mulh
—
õvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_opposite_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_opposite_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbgradient_tape/huber_loss/Negh
µ
ávoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbl2_normalize/Maximumh
≥
ávoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_min_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_min_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbhuber_loss/Minimumh
À
ëvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_quotient_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_quotient_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb gradient_tape/huber_loss/truedivh
¡
ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbl2_normalize/Rsqrth
√
ïvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_rsqrt_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbl2_normalize_1/Rsqrth
‹
°void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_sign_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_sign_op<float, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb!gradient_tape/huber_loss/Abs/Signh
ƒ
óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbl2_normalize/Squareh
»
ìvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbfunctional_1/conv2d_23/Tanhh
Ã
’void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb]functional_1/dropout/dropout/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Casth
ê
’void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb!functional_1/dropout/dropout/Casth
Û
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbCast_2h
Ç
ﬂvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb	Adam/Casth
è
Ôvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAddN_1h
ê
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAssignAddVariableOph
í
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAssignAddVariableOp_2h
›	
ø	void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAddNh
≥
ıvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const, float const, (Eigen::internal::ComparisonName)5>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::bind2nd_op<Eigen::internal::scalar_product_op<float const, float const> >, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb$functional_1/leaky_re_lu_8/LeakyReluh
÷
Ñvoid cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(float const*, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float)*28Ä@ÄHÄb8gradient_tape/functional_1/conv2d_23/BiasAdd/BiasAddGradh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@ÄHÄXbfunctional_1/conv2d_5/Conv2Dh
◊
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropInputh
◊
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropInputh
„
àvoid nchwToNhwcKernel<float, float, float, true, true, (cudnnKernelDataType_t)2>(int, int, int, int, float const*, float*, float, float)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
¡
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä@ÄHÄXbfunctional_1/conv2d_8/Conv2Dh
Â
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
Â
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
Â
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
‰
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilterh
„
âvoid nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropInputh
œ
ëvoid pooling_fw_4d_kernel<float, float, cudnn::maxpooling_func<float, (cudnnNanPropagation_t)0>, (cudnnPoolingMode_t)0, false>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, int, cudnn::reduced_divisor, cudnn::reduced_divisor)*28Ä@ÄHÄb$functional_1/max_pooling2d_3/MaxPoolh
ê
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä@ÄHÄbfunctional_1/conv2d_23/BiasAddh
è
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä@ÄHÄbfunctional_1/conv2d_8/BiasAddh
è
Yvoid tensorflow::BiasNCHWKernel<float>(int, float const*, float const*, float*, int, int)*28Ä@ÄHÄbfunctional_1/conv2d_9/BiasAddh
é
,void tensorflow::SetZero<float>(int, float*)*28Ä@ÄHÄbIgradient_tape/functional_1/up_sampling2d/resize/ResizeNearestNeighborGradh
ê
,void tensorflow::SetZero<float>(int, float*)*28Ä@ÄHÄbKgradient_tape/functional_1/up_sampling2d_1/resize/ResizeNearestNeighborGradh
Ò
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb"Adam/Adam/update/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_11/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_13/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_15/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_17/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_21/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_25/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_29/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_31/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_35/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_37/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_41/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_43/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_46/ResourceApplyAdamh
Ù
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb%Adam/Adam/update_47/ResourceApplyAdamh
Û
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb$Adam/Adam/update_5/ResourceApplyAdamh
Û
µvoid tensorflow::functor::ApplyAdamKernel<float>(int, float*, float*, float*, float const*, float const*, float const*, float const*, float const*, float const*, float const*, bool)*28Ä@ÄHÄb$Adam/Adam/update_7/ResourceApplyAdamh
‰
≈void tensorflow::functor::CleanupSegments<float*, float*, tensorflow::functor::Sum<float> >(float*, float*, int, int, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28Ä@ÄHÄbSum_2h
˚
≈void tensorflow::functor::CleanupSegments<float*, float*, tensorflow::functor::Sum<float> >(float*, float*, int, int, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28Ä@ÄHÄbhuber_loss/weighted_loss/Sumh
Å
≤void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28Ä@ÄHÄb5gradient_tape/functional_1/conv2d/BiasAdd/BiasAddGradh
Ñ
≤void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28Ä@ÄHÄb8gradient_tape/functional_1/conv2d_19/BiasAdd/BiasAddGradh
Ñ
≤void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28Ä@ÄHÄb8gradient_tape/functional_1/conv2d_20/BiasAdd/BiasAddGradh
Ñ
≤void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28Ä@ÄHÄb8gradient_tape/functional_1/conv2d_21/BiasAdd/BiasAddGradh
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXbfunctional_1/conv2d_1/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXbfunctional_1/conv2d_17/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXbfunctional_1/conv2d_19/Conv2Dh
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXbfunctional_1/conv2d_2/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXbfunctional_1/conv2d_20/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXbfunctional_1/conv2d_22/Conv2Dh
æ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXbfunctional_1/conv2d_23/Conv2Dh
Ω
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXbfunctional_1/conv2d_4/Conv2Dh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropFilterh
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_1/Conv2D/Conv2DBackpropInputh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_13/Conv2D/Conv2DBackpropInputh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_16/Conv2D/Conv2DBackpropFilterh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropFilterh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_19/Conv2D/Conv2DBackpropInputh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropFilterh
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_20/Conv2D/Conv2DBackpropInputh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_3/Conv2D/Conv2DBackpropInputh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropFilterh
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_4/Conv2D/Conv2DBackpropInputh
ﬂ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
í
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbPfunctional_1/conv2d_11/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
ë
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbOfunctional_1/conv2d_8/BiasAdd-0-1-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
≤
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbpgradient_tape/functional_1/conv2d_12/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbogradient_tape/functional_1/conv2d_6/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbogradient_tape/functional_1/conv2d_7/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbogradient_tape/functional_1/conv2d_8/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbogradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
±
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbogradient_tape/functional_1/conv2d_9/Conv2D/Conv2DBackpropFilter-2-TransposeNHWCToNCHW-LayoutOptimizer:Transposeh
§
®void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, 256, 32, 32, false>(unsigned int const*, tensorflow::functor::Dimension<3>, unsigned int*)*28Ä@ÄHÄbbgradient_tape/functional_1/dropout/dropout/Mul_1-0-0-TransposeNCHWToNHWC-LayoutOptimizer:Transposeh
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_14/Conv2D/Conv2DBackpropInputh
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_15/Conv2D/Conv2DBackpropInputh
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_17/Conv2D/Conv2DBackpropInputh
û
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_18/Conv2D/Conv2DBackpropInputh
ù
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_2/Conv2D/Conv2DBackpropInputh
ù
Dcask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)*28Ä@ÄHÄXb>gradient_tape/functional_1/conv2d_5/Conv2D/Conv2DBackpropInputh
Â
¡void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_boolean_and_op, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<bool, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_boolean_and_op, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb
LogicalAndh
È
≈void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb
div_no_nanh
Î
≈void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbdiv_no_nan_2h
˝
≈void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::div_no_nan_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbhuber_loss/weighted_loss/valueh
ã
·void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbhuber_loss/Sub_1h
˜
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_pow_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb
Adam/Pow_1h
¯
€void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbMulh
…
çvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb"functional_1/dropout_1/dropout/Mulh
Ÿ
çvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb2gradient_tape/functional_1/dropout_1/dropout/Mul_1h
∑
ávoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_max_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbl2_normalize_1/Maximumh
≈
èvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbgradient_tape/huber_loss/Mulh
π
èvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>, false>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbhuber_loss/Mul_1h
Ë
óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄb7huber_loss/ArithmeticOptimizer/ReplaceMulWithSquare_Mulh
∆
óvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, int>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, int)*28Ä@ÄHÄbl2_normalize_1/Squareh
í
’void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<bool const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb#functional_1/dropout_1/dropout/Casth
Ò
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbCasth
Û
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbCast_1h
ä
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbgradient_tape/huber_loss/Casth
ó
”void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorConversionOp<float, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄb*huber_loss/weighted_loss/num_elements/Casth
í
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAssignAddVariableOp_1h
í
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAssignAddVariableOp_3h
í
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAssignAddVariableOp_4h
í
„void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAssignAddVariableOp_5h
ù
˚void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long, long long>, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, int>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long, long long>, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, int>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAdam/addh
¬
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAdam/Adam/AssignAddVariableOph
∫
ãvoid Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long>(Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<long long const, long long const>, Eigen::TensorMap<Eigen::Tensor<long long, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<long long const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::GpuDevice>, long)*28Ä@ÄHÄbAssignAddVariableOp_6h
ã
Svoid cudnn::cnn::kern_precompute_indices<false>(int*, int, int, int, int, int, int)*28Ä@ÄHÄXbfunctional_1/conv2d_13/Conv2Dh
µ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@ÄHÄXbfunctional_1/conv2d_1/Conv2Dh
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@ÄHÄXbfunctional_1/conv2d_15/Conv2Dh
∂
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@ÄHÄXbfunctional_1/conv2d_21/Conv2Dh
ÿ
~void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_21/Conv2D/Conv2DBackpropInputh
◊
˚void nchwAddPaddingKernel<float, float, float, true, (cudnnKernelDataType_t)0>(int, int, int, int, int, int, int, int, float const*, float*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
‰
≈void tensorflow::functor::CleanupSegments<float*, float*, tensorflow::functor::Sum<float> >(float*, float*, int, int, int, tensorflow::functor::Sum<float>, std::iterator_traits<float*>::value_type)*28Ä@ÄHÄbSum_4h
É
≤void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28Ä@ÄHÄb7gradient_tape/functional_1/conv2d_1/BiasAdd/BiasAddGradh
Ñ
≤void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28Ä@ÄHÄb8gradient_tape/functional_1/conv2d_22/BiasAdd/BiasAddGradh
Ñ
≤void tensorflow::functor::ColumnReduceMax16ColumnsKernel<float const*, float*, cub::Sum>(float const*, float*, int, int, cub::Sum, std::iterator_traits<float const*>::value_type)*28Ä@ÄHÄb8gradient_tape/functional_1/conv2d_23/BiasAdd/BiasAddGradh
ª
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXbfunctional_1/conv2d/Conv2Dh
ﬁ
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb=gradient_tape/functional_1/conv2d/Conv2D/Conv2DBackpropFilterh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_22/Conv2D/Conv2DBackpropInputh
·
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb@gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropFilterh
‡
Övoid tensorflow::functor::ShuffleInTensor3Simple<float, 2, 1, 0, false>(int, float const*, tensorflow::functor::Dimension<3>, float*)*28Ä@ÄHÄXb?gradient_tape/functional_1/conv2d_23/Conv2D/Conv2DBackpropInputh